{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook evaluates the models performance on different levels. This is necessary to see if we can hold the performance or even \n",
    "outperform the reconstruction via stitching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "# Import the model definition \n",
    "#TODO: Add all models here\n",
    "from models.definitions.vae import VAE\n",
    "\n",
    "# Import the dataset\n",
    "from utils.dataloaders.dataloader_mnist_single import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation\n",
    "transformations_vae= [transforms.ToTensor(), \n",
    "                                # Normalize between -1 and 1\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                                # Flatten the Image to a vector\n",
    "                                transforms.Lambda(lambda x: x.view(-1) )\n",
    "                                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Performance\n",
    "The performance is meassured for models for different seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')\n",
    "# Load model\n",
    "model = VAE(in_dim=784, dims=[256, 128, 64, 32], distribution_dim=16).to(device)\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load('../models/checkpoints/VAE/MNIST/MNIST_VAE_3_10.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# Load data\n",
    "dataloader = DataLoaderMNIST(128, transformations_vae)\n",
    "train_loader = dataloader.get_train_loader()\n",
    "test_loader = dataloader.get_test_loader()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reconstruction Loss:  108.470461831164\n"
     ]
    }
   ],
   "source": [
    "# Average Reconstruction Loss \n",
    "\n",
    "def average_reconstruction_loss(model, dataloader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            # Reconstruction loss\n",
    "            loss += model.loss_function(recon_batch, data, mu, logvar).item()\n",
    "    return loss/ (len(dataloader ) * dataloader.batch_size)\n",
    "\n",
    "# Print the average reconstruction loss\n",
    "print(\"Average Reconstruction Loss: \", average_reconstruction_loss(model, train_loader))\n",
    "\n",
    "\n",
    "\n",
    "# Show Reconstruction \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_reconstruction(model, dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, _, _ = model(data)\n",
    "            for j in range(5):\n",
    "                plt.subplot(2, 5, j+1)\n",
    "                plt.imshow(data[j].cpu().view(28, 28).numpy(), cmap='gray')\n",
    "                plt.title('Original')\n",
    "                plt.subplot(2, 5, j+6)\n",
    "                plt.imshow(recon_batch[j].cpu().view(28, 28).numpy(), cmap='gray')\n",
    "                plt.title('Reconstr.')\n",
    "            plt.show()\n",
    "            break\n",
    "#show_reconstruction(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:  {3: 6131, 6: 5918, 0: 5923, 2: 5958, 5: 5421, 8: 5851, 1: 6742, 9: 5949, 7: 6265, 4: 5842}\n"
     ]
    }
   ],
   "source": [
    "# Performance for each class \n",
    "\n",
    "# Get from train loader the class distribution\n",
    "def get_class_distribution(dataloader):\n",
    "    class_distribution = {}\n",
    "    for i, (data, labels) in enumerate(dataloader):\n",
    "        for j in range(len(labels)):\n",
    "            label = labels[j].item()\n",
    "            if label in class_distribution:\n",
    "                class_distribution[label] += 1\n",
    "            else:\n",
    "                class_distribution[label] = 1\n",
    "    return class_distribution\n",
    "\n",
    "# Get the class distribution\n",
    "class_distribution = get_class_distribution(train_loader)\n",
    "\n",
    "print(\"Class Distribution: \", class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per class:  {3: 108.53947883149263, 6: 108.52035177217299, 0: 108.53713575778892, 2: 108.75738364428072, 5: 108.65342977552304, 8: 108.68657753826552, 1: 108.00412598154163, 9: 108.44291598778008, 7: 108.44660001421393, 4: 108.47926303010736}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Reconstruction Loss per class\n",
    "def average_loss_per_class(model, dataloader):\n",
    "    model.eval()\n",
    "    class_distribution = get_class_distribution(dataloader)\n",
    "    loss_per_class = {}\n",
    "    with torch.no_grad():\n",
    "        for i, (data, labels) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            # Reconstruction loss\n",
    "            loss = model.loss_function(recon_batch, data, mu, logvar).item()\n",
    "            for j in range(len(labels)):\n",
    "                label = labels[j].item()\n",
    "                if label in loss_per_class:\n",
    "                    loss_per_class[label] += loss\n",
    "                else:\n",
    "                    loss_per_class[label] = loss\n",
    "    for key in loss_per_class:\n",
    "        loss_per_class[key] /= class_distribution[key] * dataloader.batch_size\n",
    "    print(\"Loss per class: \", loss_per_class)\n",
    "\n",
    "    return loss_per_class\n",
    "average_per_class = average_loss_per_class(model, train_loader)\n",
    "\n",
    "# Histogram of the reconstruction loss per class\n",
    "plt.bar(average_per_class.keys(), average_per_class.values())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Loss:  15287.771484375  Label:  4\n"
     ]
    }
   ],
   "source": [
    "# Labels with higehst and lowest reconstruction loss\n",
    "\n",
    "def highest_lowest_reconstruction_loss(model, dataloader):\n",
    "    model.eval()\n",
    "    highest_loss = 0\n",
    "    highest_label = 0\n",
    "    lowest_loss = 100000\n",
    "    lowest_label = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, labels) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            # Reconstruction loss\n",
    "            loss = model.loss_function(recon_batch, data, mu, logvar).item()\n",
    "            for j in range(len(labels)):\n",
    "                label = labels[j].item()\n",
    "                if loss > highest_loss:\n",
    "                    highest_loss = loss\n",
    "                    highest_label = label\n",
    "                if loss < lowest_loss:\n",
    "                    lowest_loss = loss\n",
    "                    lowest_label = label\n",
    "    return highest_label, highest_loss, lowest_label, lowest_loss\n",
    "\n",
    "highest_label, highest_loss, lowest_label, lowest_loss = highest_lowest_reconstruction_loss(model, train_loader)\n",
    "print(\"Highest Loss: \", highest_loss, \" Label: \", highest_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relreps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
