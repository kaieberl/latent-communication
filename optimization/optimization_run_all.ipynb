{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "os.chdir('/Users/federicoferoggio/Documents/vs_code/latent-communication')\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "from models.definitions.smallae import PocketAutoencoder\n",
    "from utils.dataloaders.full_dataloaders import DataLoaderMNIST, DataLoaderFashionMNIST, DataLoaderCIFAR10, DataLoaderCIFAR100\n",
    "from utils.visualization import (\n",
    "    visualize_mapping_error,\n",
    "    visualize_latent_space_pca,\n",
    "    plot_latent_space,\n",
    "    highlight_cluster,\n",
    ")\n",
    "from utils.sampler import *\n",
    "from optimization.fit_mapping import create_mapping\n",
    "from utils.metrics import calculate_MSE_ssim_psnr\n",
    "from utils.model import load_model, get_transformations\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clear GPU memory\n",
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def define_dataloader(file, file2, use_test_set=False):\n",
    "    if file.strip(\"_\")[0] != file2.strip(\"_\")[0]:\n",
    "        logging.error(\"The datasets are different\")\n",
    "    # Define the dataloaders\n",
    "    name_dataset, name_model, size_of_the_latent, seed = file.strip(\".pth\").split(\"_\")\n",
    "    augumentation = get_transformations(name_model)\n",
    "    if name_dataset.lower() == \"mnist\":\n",
    "        dataloader = DataLoaderMNIST(transformation=augumentation, batch_size=64, seed=int(seed))\n",
    "    if name_dataset.lower() == \"fmnist\":\n",
    "        dataloader = DataLoaderFashionMNIST(transformation=augumentation,batch_size=64, seed=int(seed))\n",
    "    if name_dataset.lower() == \"cifar10\":\n",
    "        dataloader = DataLoaderCIFAR10(transformation=augumentation,batch_size=64, seed=int(seed))\n",
    "    if name_dataset.lower() == \"cifar100\":\n",
    "        dataloader = DataLoaderCIFAR100(transformation=augumentation,batch_size=64, seed=int(seed))\n",
    "    if use_test_set:\n",
    "        full_dataset_images, full_dataset_labels = dataloader.get_full_test_dataset()\n",
    "    else:\n",
    "        full_dataset_images, full_dataset_labels = dataloader.get_full_train_dataset()\n",
    "    return full_dataset_images, full_dataset_labels, len(np.unique(full_dataset_labels.numpy()))\n",
    "\n",
    "\n",
    "def calculate_and_save_mapping(model1, model2, sampling_strategy, sampled_images, parameters, file1, file2, transformations_database, num_samples, lamda, DEVICE):\n",
    "\n",
    "    name_dataset1, name_model1, size_of_the_latent1, seed1 = file1.strip(\".pth\").split(\"_\")\n",
    "    name_dataset2, name_model2, size_of_the_latent2, seed2 = file2.strip(\".pth\").split(\"_\")\n",
    "\n",
    "    # Set the model to evaluation and sends them to the DEVICE \n",
    "    model1.to(torch.float32).to(DEVICE).eval()\n",
    "    model2.to(torch.float32).to(DEVICE).eval()\n",
    "    # Get latent of the sampled images\n",
    "    latent_left_sampled_equally = model1.get_latent_space(sampled_images)\n",
    "    latent_right_sampled_equally = model2.get_latent_space(sampled_images)\n",
    "    latent_left_sampled_equally = latent_left_sampled_equally.to(torch.float32).cpu().detach().numpy()\n",
    "    latent_right_sampled_equally = latent_right_sampled_equally.to(torch.float32).cpu().detach().numpy()\n",
    "    # Create mapping and visualize\n",
    "    cfg = Config(**parameters)\n",
    "    mapping = create_mapping(cfg, latent_left_sampled_equally, latent_right_sampled_equally, do_print=False)\n",
    "    mapping.fit()\n",
    "    storage_path = f'../results/transformations/mapping_files/{name_model2}/'\n",
    "    Path(storage_path).mkdir(parents=True, exist_ok=True)\n",
    "    filename = f\"{file1.strip('.pth')}>{file2.strip('.pth')}>{cfg.mapping}_{num_samples}_{lamda}_{sampling_strategy}\"\n",
    "    mapping.save_results(storage_path +  filename)\n",
    "    transformations_database = pd.concat([transformations_database, pd.DataFrame({\"model1\": [file1], \"model2\": [file2], \"mapping\": [storage_path]})], ignore_index=True)\n",
    "    return transformations_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2160 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m model1 \u001b[38;5;241m=\u001b[39m load_model(model_name\u001b[38;5;241m=\u001b[39mname_model1, name_dataset\u001b[38;5;241m=\u001b[39mname_dataset1, latent_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(size_of_the_latent1), seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(seed1), model_path \u001b[38;5;241m=\u001b[39m folder1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m file1)\n\u001b[1;32m     39\u001b[0m model2 \u001b[38;5;241m=\u001b[39m load_model(model_name\u001b[38;5;241m=\u001b[39mname_model2, name_dataset\u001b[38;5;241m=\u001b[39mname_dataset2, latent_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(size_of_the_latent2), seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(seed2), model_path \u001b[38;5;241m=\u001b[39m folder1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m file2)\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recalculate \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmapping\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_samples\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlamda\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mequally\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresults/transformations/mapping_files/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname_model2\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     41\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampling equally per class\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m     images_sampled_equally, labels_sampled_equally \u001b[38;5;241m=\u001b[39m sample_equally_per_class_images(num_samples, images, labels)\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_save_mappings = pd.read_csv(\"/results/transformations/mapping_files/transfomations_index.csv\")\n",
    "except:\n",
    "    df_save_mappings = pd.DataFrame(columns=[\"model1\", \"model2\", \"mapping\"])\n",
    "\n",
    "## Here is the part that you have to modify however you want\n",
    "## Define directories where you want to ieratively create the mapping, and then write down the parameters you want to use\n",
    "import os \n",
    "# Set the directories where the models are stored\n",
    "\n",
    "folder1 = \"models/checkpoints/SMALLAE/FMNIST\"\n",
    "folder2 = \"models/checkpoints/SMALLAE/FMNIST\"\n",
    "number_samples = [10,50,100,200, 300]    #[10,50,100,200,300]\n",
    "mapping_list = [\"Linear\", \"Affine\"]\n",
    "lamda_list = [0,0.1,0.01]    #[0,0.1, 0.01]\n",
    "use_test_set = False\n",
    "filter1 = '_' #write here if you want that the processed files contain this string (example \"_50_\" to only process the files with latent size 50)\n",
    "filter2 = '_' #write here if you want that the processed files contain this string (example \"_50_\" to only process the files with latent size 50)\n",
    "recalculate = False #If you want to recalculate the mappings, set this to True\n",
    "use_same_sampling = True #If you want to use the same sampling points wherever possible for all the models, set this to True\n",
    "\n",
    "## this autiomatically creates all teh possible setups with the paramenters and the files you speicified, and sets up the correct dataset\n",
    "files1 = [f for f in os.listdir(folder1) if f.endswith(\".pth\") and filter1 in f]\n",
    "files2 = [f for f in os.listdir(folder2) if f.endswith(\".pth\") and filter2 in f]\n",
    "list_of_files = [(f1, f2) for f1, f2 in itertools.product(files1, files2) if f1 != f2]\n",
    "combinations_parameters = list(itertools.product(number_samples, mapping_list, lamda_list))\n",
    "pbar = tqdm(list(itertools.product(list_of_files, combinations_parameters)))\n",
    "images, labels, n_classes = define_dataloader(files1[0], files2[0], use_test_set)\n",
    "images = images.type(torch.float32)\n",
    "labels = labels.type(torch.float32)\n",
    "\n",
    "# Loop through combinations\n",
    "for (file1, file2), (num_samples, mapping, lamda) in pbar:\n",
    "    parameters = {\"num_samples\": num_samples, \"mapping\": mapping, \"lamda\": lamda} #This is done to go around some hydra stuff (<3 kai)\n",
    "    name_dataset1, name_model1, size_of_the_latent1, seed1 = file1.strip(\".pth\").split(\"_\")\n",
    "    name_dataset2, name_model2, size_of_the_latent2, seed2 = file2.strip(\".pth\").split(\"_\")\n",
    "\n",
    "    model1 = load_model(model_name=name_model1, name_dataset=name_dataset1, latent_size=int(size_of_the_latent1), seed=int(seed1), model_path = folder1 + '/' + file1)\n",
    "    model2 = load_model(model_name=name_model2, name_dataset=name_dataset2, latent_size=int(size_of_the_latent2), seed=int(seed2), model_path = folder1 + '/' + file2)\n",
    "    if recalculate or str(f\"{file1.strip('.pth')}>{file2.strip('.pth')}>{mapping}_{num_samples}_{lamda}_{'equally'}\") not in os.chdir(f'results/transformations/mapping_files/{name_model2}'):\n",
    "        pbar.set_description(\"Sampling equally per class\")\n",
    "        images_sampled_equally, labels_sampled_equally = sample_equally_per_class_images(num_samples, images, labels)\n",
    "        df_save_mappings = calculate_and_save_mapping(model1, model2, \"equally\", images_sampled_equally, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    if recalculate or not str(f\"{file1.strip('.pth')}>{file2.strip('.pth')}>{mapping}_{num_samples}_{lamda}_{'outliers'}\") not in os.chdir(f'results/transformations/mapping_files/{name_model2}'):\n",
    "        pbar.set_description(\"Sampling removing outliers\")\n",
    "        images_sampled_drop_outliers, labels_sampled_drop_outliers = sample_removing_outliers(num_samples, images, labels, model2)\n",
    "        df_save_mappings = calculate_and_save_mapping(model1, model2, \"outliers\", images_sampled_drop_outliers, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    if recalculate or not str(f\"{file1.strip('.pth')}>{file2.strip('.pth')}>{mapping}_{num_samples}_{lamda}_{'worst_classes'}\") not in os.chdir(f'results/transformations/mapping_files/{name_model2}'):\n",
    "        pbar.set_description(\"Sampling worst classes\")\n",
    "        images_sampled_worst_classes, labels_sampled_worst_classes = sample_with_half_worst_classes_images(num_samples, images, labels, model2)\n",
    "        df_save_mappings = calculate_and_save_mapping(model1, model2, \"worst_classes\", images_sampled_worst_classes, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    if recalculate or not str(f\"{file1.strip('.pth')}>{file2.strip('.pth')}>{mapping}_{num_samples}_{lamda}_{'best_classes'}\") not in os.chdir(f'results/transformations/mapping_files/{name_model2}'):\n",
    "        pbar.set_description(\"Sampling convex hull\")\n",
    "        images_sampled_best_classes, labels_sampled_convex_hull = sample_convex_hulls_images(num_samples, images, labels, model1)\n",
    "        df_save_mappings = calculate_and_save_mapping(model1, model2, \"convex_hull\", images_sampled_best_classes, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "\n",
    "    pbar.set_description(\"Processing %s and %s\" % (file1, file2))\n",
    "    pbar.set_description(\"Processed %s and %s\" % (file1, file2))\n",
    "df_save_mappings.to_csv(\"results/transformations/mapping_files/transfomations_index.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".zeroshot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
