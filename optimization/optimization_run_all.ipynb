{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "os.chdir('/Users/federicoferoggio/Documents/vs_code/latent-communication')\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "from models.definitions.PCKTAE import PocketAutoencoder\n",
    "from utils.dataloaders.full_dataloaders import DataLoaderMNIST, DataLoaderFashionMNIST, DataLoaderCIFAR10, DataLoaderCIFAR100\n",
    "from utils.visualization import (\n",
    "    visualize_mapping_error,\n",
    "    visualize_latent_space_pca,\n",
    "    plot_latent_space,\n",
    "    highlight_cluster,\n",
    ")\n",
    "from utils.sampler import *\n",
    "from optimization.fit_mapping import create_mapping\n",
    "from utils.metrics import calculate_MSE_ssim_psnr\n",
    "from utils.model import load_model, get_transformations\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clear GPU memory\n",
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def define_dataloader(file, file2, use_test_set=False):\n",
    "    if file.strip(\"_\")[0] != file2.strip(\"_\")[0]:\n",
    "        logging.error(\"The datasets are different\")\n",
    "    # Define the dataloaders\n",
    "    name_dataset, name_model, size_of_the_latent, seed = file.strip(\".pth\").split(\"_\")\n",
    "    augumentation = get_transformations(name_model)\n",
    "    if name_dataset.lower() == \"mnist\":\n",
    "        dataloader = DataLoaderMNIST(transformation=augumentation, batch_size=64, seed=int(seed))\n",
    "    if name_dataset.lower() == \"fmnist\":\n",
    "        dataloader = DataLoaderFashionMNIST(transformation=augumentation,batch_size=64, seed=int(seed))\n",
    "    if name_dataset.lower() == \"cifar10\":\n",
    "        dataloader = DataLoaderCIFAR10(transformation=augumentation,batch_size=64, seed=int(seed))\n",
    "    if name_dataset.lower() == \"cifar100\":\n",
    "        dataloader = DataLoaderCIFAR100(transformation=augumentation,batch_size=64, seed=int(seed))\n",
    "    if use_test_set:\n",
    "        full_dataset_images, full_dataset_labels = dataloader.get_full_test_dataset()\n",
    "    else:\n",
    "        full_dataset_images, full_dataset_labels = dataloader.get_full_train_dataset()\n",
    "    return full_dataset_images, full_dataset_labels, len(np.unique(full_dataset_labels.numpy()))\n",
    "\n",
    "\n",
    "def calculate_and_save_mapping(model1, model2, sampling_strategy, sampled_images, parameters, file1, file2, transformations_database, num_samples, lamda, DEVICE):\n",
    "\n",
    "    name_dataset1, name_model1, size_of_the_latent1, seed1 = file1.strip(\".pth\").split(\"_\")\n",
    "    name_dataset2, name_model2, size_of_the_latent2, seed2 = file2.strip(\".pth\").split(\"_\")\n",
    "\n",
    "    # Set the model to evaluation and sends them to the DEVICE \n",
    "    model1.to(torch.float32).to(DEVICE).eval()\n",
    "    model2.to(torch.float32).to(DEVICE).eval()\n",
    "    # Get latent of the sampled images\n",
    "    latent_left_sampled_equally = model1.get_latent_space(sampled_images)\n",
    "    latent_right_sampled_equally = model2.get_latent_space(sampled_images)\n",
    "    latent_left_sampled_equally = latent_left_sampled_equally.to(torch.float32).cpu().detach().numpy()\n",
    "    latent_right_sampled_equally = latent_right_sampled_equally.to(torch.float32).cpu().detach().numpy()\n",
    "    # Create mapping and visualize\n",
    "    cfg = Config(**parameters)\n",
    "    mapping = create_mapping(cfg, latent_left_sampled_equally, latent_right_sampled_equally, do_print=False)\n",
    "    mapping.fit()\n",
    "    storage_path = f'results/transformations/mapping_files/{name_model2}/'\n",
    "    Path(storage_path).mkdir(parents=True, exist_ok=True)\n",
    "    filename = f\"{file1.strip('.pth')}>{file2.strip('.pth')}>{cfg.mapping}_{num_samples}_{lamda}_{sampling_strategy}\"\n",
    "    mapping.save_results(storage_path +  filename)\n",
    "    transformations_database = pd.concat([transformations_database, pd.DataFrame({\"model1\": [file1], \"model2\": [file2], \"mapping\": [storage_path]})], ignore_index=True)\n",
    "    return transformations_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2160 [00:00<?, ?it/s]/Users/federicoferoggio/Documents/vs_code/latent-communication/utils/dataloaders/full_dataloaders.py:117: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:277.)\n",
      "  return torch.tensor(train_data), torch.tensor(train_labels)\n",
      "  0%|          | 0/2160 [00:52<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 8, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m model2 \u001b[38;5;241m=\u001b[39m load_model(model_name\u001b[38;5;241m=\u001b[39mname_model2, name_dataset\u001b[38;5;241m=\u001b[39mname_dataset2, latent_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(size_of_the_latent2), seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(seed2), model_path \u001b[38;5;241m=\u001b[39m folder1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m file2)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m init:\n\u001b[0;32m---> 53\u001b[0m     images_sampled_equally, labels_sampled_equally, images_sampled_drop_outliers, labels_sampled_drop_outliers, images_sampled_worst_classes, labels_sampled_worst_classes, images_sampled_best_classes, labels_sampled_convex_hull \u001b[38;5;241m=\u001b[39m sample_equally_per_class_images(num_samples, images, labels), sample_removing_outliers(num_samples, images, labels, model2), sample_with_half_worst_classes_images(num_samples, images, labels, model2), sample_convex_hulls_images(num_samples, images, labels, model1)\n\u001b[1;32m     54\u001b[0m     init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (recalculate) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile1\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile2\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlamda\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mequally\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/transformations/mapping_files/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname_model2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 8, got 4)"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_save_mappings = pd.read_csv(\"/results/transformations/mapping_files/transfomations_index.csv\")\n",
    "except:\n",
    "    df_save_mappings = pd.DataFrame(columns=[\"model1\", \"model2\", \"mapping\"])\n",
    "\n",
    "## Here is the part that you have to modify however you want\n",
    "## Define directories where you want to ieratively create the mapping, and then write down the parameters you want to use\n",
    "import os \n",
    "# Set the directories where the models are stored\n",
    "\n",
    "folder1 = \"models/checkpoints/PCKTAE/FMNIST\"\n",
    "folder2 = \"models/checkpoints/PCKTAE/FMNIST\"\n",
    "number_samples = [10,50,100,200, 300]    #[10,50,100,200,300]\n",
    "mapping_list = [\"Linear\", \"Affine\"]\n",
    "lamda_list = [0,0.1,0.01]    #[0,0.1, 0.01]\n",
    "use_test_set = False\n",
    "filter1 = '_' #write here if you want that the processed files contain this string (example \"_50_\" to only process the files with latent size 50)\n",
    "filter2 = '_' #write here if you want that the processed files contain this string (example \"_50_\" to only process the files with latent size 50)\n",
    "recalculate = False #If you want to recalculate the mappings, set this to True\n",
    "use_same_sampling = True #If you want to use the same sampling points wherever possible for all the models, set this to True\n",
    "\n",
    "\n",
    "## this autiomatically creates all teh possible setups with the paramenters and the files you speicified, and sets up the correct dataset\n",
    "files1 = [f for f in os.listdir(folder1) if f.endswith(\".pth\") and filter1 in f]\n",
    "files2 = [f for f in os.listdir(folder2) if f.endswith(\".pth\") and filter2 in f]\n",
    "list_of_files = [(f1, f2) for f1, f2 in itertools.product(files1, files2) if f1 != f2]\n",
    "combinations_parameters = list(itertools.product(number_samples, mapping_list, lamda_list))\n",
    "combinations = list(itertools.product(list_of_files, combinations_parameters))\n",
    "flattened_combinations = [(file1, file2, param1, param2, param3) for ((file1, file2), (param1, param2, param3)) in combinations]\n",
    "\n",
    "# Sort the flattened list by all elements\n",
    "sorted_combinations = sorted(flattened_combinations, key=lambda x: (x[2], x[1], x[0], x[3], x[4]))\n",
    "pbar = tqdm(sorted_combinations)\n",
    "\n",
    "images, labels, n_classes = define_dataloader(files1[0], files2[0], use_test_set)\n",
    "images = images.type(torch.float32)\n",
    "labels = labels.type(torch.float32)\n",
    "\n",
    "images_sampled_equally_old, labels_sampled_equally_old, images_sampled_drop_outliers_old, labels_sampled_drop_outliers_old, images_sampled_worst_classes_old, labels_sampled_worst_classes_old, images_sampled_best_classes_old, labels_sampled_convex_hull_old = None, None, None, None, None, None, None, None\n",
    "past_num_samples, past_file1, past_file2 = None, None, None\n",
    "init = True\n",
    "\n",
    "# Loop through combinations\n",
    "for file1, file2, num_samples, mapping, lamda in pbar:\n",
    "    parameters = {\"num_samples\": num_samples, \"mapping\": mapping, \"lamda\": lamda} #This is done to go around some hydra stuff (<3 kai)\n",
    "    name_dataset1, name_model1, size_of_the_latent1, seed1 = file1.strip(\".pth\").split(\"_\")\n",
    "    name_dataset2, name_model2, size_of_the_latent2, seed2 = file2.strip(\".pth\").split(\"_\")\n",
    "    model_folder = os.listdir(f'results/transformations/mapping_files/{name_model2}')\n",
    "    model1 = load_model(model_name=name_model1, name_dataset=name_dataset1, latent_size=int(size_of_the_latent1), seed=int(seed1), model_path = folder1 + '/' + file1)\n",
    "    model2 = load_model(model_name=name_model2, name_dataset=name_dataset2, latent_size=int(size_of_the_latent2), seed=int(seed2), model_path = folder1 + '/' + file2)\n",
    "\n",
    "    if init:\n",
    "        images_sampled_equally, labels_sampled_equally = sample_equally_per_class_images(num_samples, images, labels)        \n",
    "        images_sampled_drop_outliers, labels_sampled_drop_outliers = sample_removing_outliers(num_samples, images, labels, model2)\n",
    "        images_sampled_worst_classes, labels_sampled_worst_classes = sample_with_half_worst_classes_images(num_samples, images, labels, model2)\n",
    "        images_sampled_best_classes, labels_sampled_convex_hull = sample_convex_hulls_images(num_samples, images, labels, model1)\n",
    "        init = False\n",
    "    if (recalculate) or (not any(str(f\"{file1.strip('.pth')}>{file2.strip('.pth')}>{mapping}_{num_samples}_{lamda}_{'equally'}{ext}\") in os.listdir(f'results/transformations/mapping_files/{name_model2}') for ext in ['.npz', '.npy'])):\n",
    "        if (past_num_samples != num_samples) or (not use_same_sampling):\n",
    "            pbar.set_description(\"Sampling equally per class\")\n",
    "            images_sampled_equally, labels_sampled_equally = sample_equally_per_class_images(num_samples, images, labels)        \n",
    "        df_save_mappings = calculate_and_save_mapping(model1, model2, \"equally\", images_sampled_equally, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    if (recalculate) or (not any(str(f\"{file1.strip('.pth')}>{file2.strip('.pth')}>{mapping}_{num_samples}_{lamda}_{'outliers'}{ext}\") in os.listdir(f'results/transformations/mapping_files/{name_model2}') for ext in ['.npz', '.npy'])):\n",
    "        if (past_num_samples != num_samples) or (not use_same_sampling) or (past_file2 != file2):    \n",
    "            pbar.set_description(\"Sampling removing outliers\")\n",
    "            images_sampled_drop_outliers, labels_sampled_drop_outliers = sample_removing_outliers(num_samples, images, labels, model2)\n",
    "        df_save_mappings = calculate_and_save_mapping(model1, model2, \"outliers\", images_sampled_drop_outliers, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    if (recalculate) or (not any(str(f\"{file1.strip('.pth')}>{file2.strip('.pth')}>{mapping}_{num_samples}_{lamda}_{'worst_classes'}{ext}\") in os.listdir(f'results/transformations/mapping_files/{name_model2}') for ext in ['.npz', '.npy'])):\n",
    "        if (past_num_samples != num_samples) or (not use_same_sampling) or (past_file2 != file2):\n",
    "            pbar.set_description(\"Sampling worst classes\")\n",
    "            images_sampled_worst_classes, labels_sampled_worst_classes = sample_with_half_worst_classes_images(num_samples, images, labels, model2)\n",
    "        df_save_mappings = calculate_and_save_mapping(model1, model2, \"worst_classes\", images_sampled_worst_classes, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    if (recalculate) or (not any(str(f\"{file1.strip('.pth')}>{file2.strip('.pth')}>{mapping}_{num_samples}_{lamda}_{'best_classes'}{ext}\") in os.listdir(f'results/transformations/mapping_files/{name_model2}') for ext in ['.npz', '.npy'])):\n",
    "        if (past_num_samples != num_samples) or (not use_same_sampling) or (past_file1 != file1):\n",
    "            pbar.set_description(\"Sampling convex hull\")\n",
    "            images_sampled_best_classes, labels_sampled_convex_hull = sample_convex_hulls_images(num_samples, images, labels, model1)\n",
    "        df_save_mappings = calculate_and_save_mapping(model1, model2, \"convex_hull\", images_sampled_best_classes, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    past_num_samples, past_file1, past_file2 = num_samples, file1, file2\n",
    "    images_sampled_equally_old, labels_sampled_equally_old, images_sampled_drop_outliers_old, labels_sampled_drop_outliers_old, images_sampled_worst_classes_old, labels_sampled_worst_classes_old, images_sampled_best_classes_old, labels_sampled_convex_hull_old = images_sampled_equally, labels_sampled_equally, images_sampled_drop_outliers, labels_sampled_drop_outliers, images_sampled_worst_classes, labels_sampled_worst_classes, images_sampled_best_classes, labels_sampled_convex_hull\n",
    "df_save_mappings.to_csv(\"results/transformations/mapping_files/transfomations_index.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".zeroshot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
