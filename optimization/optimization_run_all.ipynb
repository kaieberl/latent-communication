{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory /mnt/c/Users/Hillary Hauger/Documents/Studium/SoSe2024/Case Study Non Linear Optimization/Code/latent-communication\n",
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "os.chdir(\"../\")\n",
    "print(f\"Current working directory {os.getcwd()}\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "#from skimage.metrics import structural_similarity as ssim\n",
    "#from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "from models.definitions.smallae import PocketAutoencoder\n",
    "from utils.dataloaders.full_dataloaders import DataLoaderMNIST, DataLoaderFashionMNIST, DataLoaderCIFAR10, DataLoaderCIFAR100\n",
    "from utils.visualization import (\n",
    "    visualize_mapping_error,\n",
    "    visualize_latent_space_pca,\n",
    "    plot_latent_space,\n",
    "    highlight_cluster,\n",
    ")\n",
    "from utils.sampler import *\n",
    "from optimization.fit_mapping import create_mapping\n",
    "from utils.metrics import calculate_MSE_ssim_psnr\n",
    "from utils.model import load_model, get_transformations\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "print(f\"Using device {DEVICE}\")\n",
    "class Config:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clear GPU memory\n",
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def define_dataloader(file, file2, use_test_set=False):\n",
    "    if file.strip(\"_\")[0] != file2.strip(\"_\")[0]:\n",
    "        logging.error(\"The datasets are different\")\n",
    "    # Define the dataloaders\n",
    "    name_dataset, name_model, size_of_the_latent, seed = file.strip(\".pth\").split(\"_\")\n",
    "    augumentation = get_transformations(name_model)\n",
    "    if name_dataset.lower() == \"mnist\":\n",
    "        dataloader = DataLoaderMNIST(transformation=augumentation, batch_size=64, seed=int(seed))\n",
    "    if name_dataset.lower() == \"fmnist\":\n",
    "        dataloader = DataLoaderFashionMNIST(transformation=augumentation,batch_size=64, seed=int(seed))\n",
    "    if name_dataset.lower() == \"cifar10\":\n",
    "        dataloader = DataLoaderCIFAR10(transformation=augumentation,batch_size=64, seed=int(seed))\n",
    "    if name_dataset.lower() == \"cifar100\":\n",
    "        dataloader = DataLoaderCIFAR100(transformation=augumentation,batch_size=64, seed=int(seed))\n",
    "    if use_test_set:\n",
    "        full_dataset_images, full_dataset_labels = dataloader.get_full_test_dataset()\n",
    "    else:\n",
    "        full_dataset_images, full_dataset_labels = dataloader.get_full_train_dataset()\n",
    "    return full_dataset_images, full_dataset_labels, len(np.unique(full_dataset_labels.numpy()))\n",
    "\n",
    "\n",
    "def calculate_and_save_mapping(model1, model2, sampling_strategy, sampled_images, parameters, file1, file2, transformations_database, num_samples, lamda, DEVICE):\n",
    "\n",
    "    name_dataset1, name_model1, size_of_the_latent1, seed1 = file1.strip(\".pth\").split(\"_\")\n",
    "    name_dataset2, name_model2, size_of_the_latent2, seed2 = file2.strip(\".pth\").split(\"_\")\n",
    "\n",
    "    # Set the model to evaluation and sends them to the DEVICE \n",
    "    model1.to(torch.float32).to(DEVICE).eval()\n",
    "    model2.to(torch.float32).to(DEVICE).eval()\n",
    "    # Get latent of the sampled images\n",
    "    latent_left_sampled_equally = model1.get_latent_space(sampled_images)\n",
    "    latent_right_sampled_equally = model2.get_latent_space(sampled_images)\n",
    "    latent_left_sampled_equally = latent_left_sampled_equally.to(torch.float32).cpu().detach().numpy()\n",
    "    latent_right_sampled_equally = latent_right_sampled_equally.to(torch.float32).cpu().detach().numpy()\n",
    "    # Create mapping and visualize\n",
    "    cfg = Config(**parameters)\n",
    "    mapping = create_mapping(cfg, latent_left_sampled_equally, latent_right_sampled_equally)\n",
    "    mapping.fit()\n",
    "    storage_path = f'results/transformations/mapping_files/{name_model2}/{file1.strip(\".pth\")}>{file1.strip(\".pth\")}>{cfg.mapping}_{num_samples}_{lamda}_{sampling_strategy}'\n",
    "    Path(storage_path).mkdir(parents=True, exist_ok=True)\n",
    "    mapping.save_results(storage_path)\n",
    "    transformations_database = pd.concat([transformations_database, pd.DataFrame({\"model1\": [file1], \"model2\": [file2], \"mapping\": [storage_path]})], ignore_index=True)\n",
    "    return transformations_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling removing outliers:   0%|          | 0/6 [00:36<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_save_mappings = pd.read_csv(\"results/transformations/mapping_files/transfomations_index.csv\")\n",
    "except:\n",
    "    df_save_mappings = pd.DataFrame(columns=[\"model1\", \"model2\", \"mapping\"])\n",
    "\n",
    "## Here is the part that you have to modify however you want\n",
    "## Define directories where you want to ieratively create the mapping, and then write down the parameters you want to use\n",
    "folder1 = \"models/checkpoints/VerySmallAE/MNIST/\"\n",
    "folder2 = \"models/checkpoints/VerySmallAE/MNIST/\"\n",
    "number_samples = [10,50,100,200,300]\n",
    "mapping_list = [\"Linear\", \"Affine\"]\n",
    "lamda_list = [0,0.1, 0.01]\n",
    "use_test_set = False\n",
    "filter = '' #write here if you want that the processed files contain this string (example \"_50_\" to only process the files with latent size 50)\n",
    "\n",
    "## this autiomatically creates all teh possible setups with the paramenters and the files you speicified, and sets up the correct dataset\n",
    "files1 = [f for f in os.listdir(folder1) if f.endswith(\".pth\") and filter in f]\n",
    "files2 = [f for f in os.listdir(folder2) if f.endswith(\".pth\") and filter in f]\n",
    "list_of_files = [(f1, f2) for f1, f2 in itertools.product(files1, files2) if f1 != f2]\n",
    "combinations_parameters = list(itertools.product(number_samples, mapping_list, lamda_list))\n",
    "pbar = tqdm(list(itertools.product(list_of_files, combinations_parameters)))\n",
    "images, labels, n_classes = define_dataloader(files1[0], files2[0], use_test_set)\n",
    "images = images.type(torch.float32)\n",
    "labels = labels.type(torch.float32)\n",
    "\n",
    "# Loop through combinations\n",
    "for (file1, file2), (num_samples, mapping, lamda) in pbar:\n",
    "    parameters = {\"num_samples\": num_samples, \"mapping\": mapping, \"lamda\": lamda} #This is done to go around some hydra stuff (<3 kai)\n",
    "    name_dataset1, name_model1, size_of_the_latent1, seed1 = file1.strip(\".pth\").split(\"_\")\n",
    "    name_dataset2, name_model2, size_of_the_latent2, seed2 = file2.strip(\".pth\").split(\"_\")\n",
    "    #Load models\n",
    "    model1 = load_model(model_name=name_model1, name_dataset=name_dataset1, latent_size=size_of_the_latent1, seed=seed1, model_path = folder1 + file1)\n",
    "    model2 = load_model(model_name=name_model2, name_dataset=name_dataset2, latent_size=size_of_the_latent2, seed=seed2, model_path = folder1 + file2)\n",
    "    model1 = model1.to(DEVICE)\n",
    "    model2 = model2.to(DEVICE)\n",
    "    model1.load_state_dict(torch.load(folder1 + file1))\n",
    "    model2.load_state_dict(torch.load(folder2 + file2))\n",
    "    #Calculate the samples\n",
    "    pbar.set_description(\"Sampling equally per class\")\n",
    "    images_sampled_equally, labels_sampled_equally = sample_equally_per_class_images(num_samples, images, labels)\n",
    "    pbar.set_description(\"Sampling removing outliers\")\n",
    "    images_sampled_max_distance, labels_sampled_drop_outliers = sample_removing_outliers(num_samples, images, labels, model2)\n",
    "    pbar.set_description(\"Sampling worst classes\")\n",
    "    images_sampled_worst_classes, labels_sampled_worst_classes = sample_with_half_worst_classes_images(num_samples, images, labels, model2)\n",
    "    pbar.set_description(\"Sampling convex hull\")\n",
    "    images_sampled_best_classes, labels_sampled_convex_hull = sample_convex_hulls_images(num_samples, images, labels, model1)\n",
    "    pbar.set_description(\"Processing %s and %s\" % (file1, file2))\n",
    "    #Calculate and save mappings\n",
    "    df_save_mappings = calculate_and_save_mapping(model1, model2, \"equally\", images_sampled_equally, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    df_save_mappings = calculate_and_save_mapping(model1, model2, \"outliers\", images_sampled_max_distance, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    df_save_mappings = calculate_and_save_mapping(model1, model2, \"worst_classes\", images_sampled_worst_classes, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    df_save_mappings = calculate_and_save_mapping(model1, model2, \"convex_hull\", images_sampled_best_classes, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    pbar.set_description(\"Processed %s and %s\" % (file1, file2))\n",
    "df_save_mappings.to_csv(\"results/transformations/mapping_files/transfomations_index.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".zeroshot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
