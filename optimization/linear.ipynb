{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Transformation \n",
    "We will start with the alignement of the same models for different seeds. \n",
    "- First we do not restrict the matrix.\n",
    "- Second we restrict the matrix to be a rotation matrix.\n",
    "- Thrid use affine transformation \n",
    "- Last but not least we are using different norms and regularization techniques to improve the results\n",
    "\n",
    "\n",
    "\n",
    "Steps: \n",
    "- Load the same model but with different seed\n",
    "- Sample different images and get latent representation \n",
    "- Create Datamatrix X and X'\n",
    "- Solve the simple optimization problem (Using closed form solution as well cvxpy solver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.decomposition import PCA\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reimpmort modules with autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "config = {\n",
    "    'path1': \"/Users/federicoferoggio/Documents/vs_code/latent-communication/models/checkpoints/VAE/MNIST/MNIST_VAE_1_10.pth\",\n",
    "    'modelname1': 'VAE',\n",
    "    'seed1': '1',\n",
    "    'path2': \"/Users/federicoferoggio/Documents/vs_code/latent-communication/models/checkpoints/VAE/MNIST/MNIST_VAE_4_10.pth\",\n",
    "    'modelname2': 'VAE',\n",
    "    'seed2': '1',\n",
    "    'num_samples': '100',\n",
    "    'storage_path': 'VAE-ResNet-LinearTransform',\n",
    "\n",
    "}\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Problem in the Linear Case \n",
    "Let $x^i,y^i \\in \\mathbb{R^n}$ for $i = 1,...,m$ and $A \\in \\mathbb{R}^{n \\times n}$ we are looking for the optimal A, which solves the following optimization problem \n",
    "$$ min_A \\sum_{i = 1}^n ||Ax^i - y^i||^2 $$\n",
    "$$ min_ a \\sum_{i=1} \\sum_{j =1} (A_{(j)} x^i - y^i_j)^2 $$\n",
    "where we are using the euclidian norm when not otherwise stated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Transformed Data for VAE\n",
    "In this section we load the trained models, which we prepaired for our experimental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils.dataloaders.DataLoaderMNIST_single import DataLoader_MNIST\n",
    "\n",
    "\n",
    "def load_model(model_name, model_path):\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "    if model_name == 'VAE':\n",
    "        from models.definitions.vae import VAE\n",
    "        model = VAE(in_dim=784, dims=[256, 128, 64, 32], distribution_dim=16).to(DEVICE)\n",
    "    elif model_name == 'resnet':\n",
    "        from models.definitions.resnet import ResNet\n",
    "        model = ResNet().to(DEVICE)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    return model\n",
    "\n",
    "def load_Models():\n",
    "    model1 = load_model(config['modelname1'], config['path1'])\n",
    "    model2 = load_model(config['modelname2'], config['path2'])\n",
    "    return model1, model2\n",
    "\n",
    "def get_transformations(model_name):\n",
    "    if model_name == 'VAE':\n",
    "        return [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,)),\n",
    "            transforms.Lambda(lambda x: x.view(-1))\n",
    "        ]\n",
    "    elif model_name == 'resnet':\n",
    "        return [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.repeat(3, 1, 1))\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "\n",
    "def transformations():\n",
    "    transformations1 = get_transformations(config['modelname1'])\n",
    "    transformations2 = get_transformations(config['modelname2'])\n",
    "    return transformations1, transformations2\n",
    "\n",
    "# Load models\n",
    "model1, model2 = load_Models()\n",
    "\n",
    "# Get transformations\n",
    "transformations1, transformations2 = transformations()\n",
    "\n",
    "# Initialize data loader\n",
    "data_loader_VAE_1 = DataLoader_MNIST(128, get_transformations(config['modelname1']), seed=10)\n",
    "data_loader_VAE_2 = DataLoader_MNIST(128, get_transformations(config['modelname2']), seed=10)\n",
    "\n",
    "# Get train and test loaders\n",
    "train_loader_vae_1 = data_loader_VAE_1.get_train_loader()\n",
    "test_loader_vae_1 = data_loader_VAE_1.get_test_loader()\n",
    "\n",
    "train_loader_vae_2 = data_loader_VAE_2.get_train_loader()\n",
    "test_loader_vae_2 = data_loader_VAE_2.get_test_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(num_samples)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Sample simply \u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m z1\u001b[38;5;241m=\u001b[39m \u001b[43msimple_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader_VAE_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m z2 \u001b[38;5;241m=\u001b[39m simple_sampler(num_samples, model1, model2, data_loader_VAE_2, DEVICE)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Sample from each class\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#z1_suf, z2_suf, images_suf, labels_suf = class_sampler(config['num_samples'], model, model2, data_loader, DEVICE)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/vs_code/latent-communication/optimization/../utils/sampler.py:17\u001b[0m, in \u001b[0;36msimple_sampler\u001b[0;34m(m, model1, model2, data_loader, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimple_sampler\u001b[39m(m, model1, model2, data_loader, device):\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    Input:\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    - m: Samples\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    This function samples the latent space of the model and returns the latent vectors of the model 1 and model2\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     data_loader1, data_loader2 \u001b[38;5;241m=\u001b[39m data_loader\u001b[38;5;241m.\u001b[39mget_train_loader()\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Sample indices from the train set\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandperm(\u001b[38;5;28mlen\u001b[39m(data_loader1\u001b[38;5;241m.\u001b[39mdataset))[:m]\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from utils.sampler import simple_sampler, class_sampler\n",
    "\n",
    "# Convertiere String in Integer\n",
    "num_samples= int(config['num_samples'])\n",
    "m = 100\n",
    "\n",
    "print(num_samples)\n",
    "# Sample simply \n",
    "z1 = simple_sampler(num_samples, model1, model2, data_loader_VAE_1, DEVICE)\n",
    "z2 = simple_sampler(num_samples, model1, model2, data_loader_VAE_2, DEVICE)\n",
    "\n",
    "data_loader1, data_loader2 = data_loader.get_train_loader()\n",
    "\n",
    "# Sample indices from the train set\n",
    "indices = torch.randperm(len(data_loader1.dataset))[:m]\n",
    "\n",
    "# Get the corresponding images\n",
    "all_images_sample1 = torch.stack([data_loader1.dataset[i][0] for i in indices])\n",
    "all_images_sample2 = torch.stack([data_loader2.dataset[i][0] for i in indices])\n",
    "\n",
    "z1 = model1.get_latent_space(all_images_sample1.to(DEVICE))\n",
    "z2 = model2.get_latent_space(all_images_sample2.to(DEVICE))\n",
    "\n",
    "# Sample from each class\n",
    "#z1_suf, z2_suf, images_suf, labels_suf = class_sampler(config['num_samples'], model, model2, data_loader, DEVICE)\n",
    "\n",
    "\n",
    "print(z1.shape)\n",
    "print(z2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex Optimization Solver\n",
    "## Linear Transformation with regularization\n",
    "We are using the cvxpy solver which is a open source solver for convex optimization problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#Ã¤ Get wd \n",
    "print(os.getcwd())\n",
    "# Linear Transformation\n",
    "from optimizer import LinearFitting\n",
    "\n",
    "linear_fitting = LinearFitting(z1, z2,lamda=0.01)\n",
    "\n",
    "linear_fitting.solve_problem()\n",
    "\n",
    "loss, A  = linear_fitting.get_results()\n",
    "\n",
    "name = 'Linear_' + config['modelname1'] + '_' + config['seed1'] + '_' + config['modelname2'] + '_' + config['seed2'] + '_' + config['num_samples']\n",
    "path = 'optimization/' + config['storage_path'] + '/' + name \n",
    "\n",
    "linear_fitting.save_results(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine transformation\n",
    "In this section we implement the affine transformation. We are adding a offset to the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizer import AffineFitting\n",
    "\n",
    "affine_fitting = AffineFitting(z1, z2, lamda=0.01)\n",
    "\n",
    "# Solve the problem\n",
    "affine_fitting.solve_problem()\n",
    "\n",
    "# Get the results\n",
    "loss, A, b = affine_fitting.get_results()\n",
    "\n",
    "# Show the results\n",
    "print('Loss:', loss)\n",
    "print('A:', A)\n",
    "print('b:', b)\n",
    "\n",
    "# Save the results\n",
    "name = 'Affine_' + config['modelname1'] + '_' + config['seed1'] + '_' + config['modelname2'] + '_' + config['seed2'] + '_' + config['num_samples']\n",
    "path = 'optimization/'+ config['storage_path'] + '/' + name\n",
    "\n",
    "\n",
    "# Save the results\n",
    "affine_fitting.save_results(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Transformation with constraints (psd)\n",
    "In this section we relax the problem and consider that the matrix has to be positive semidefinite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization Variable\n",
    "A_psd = cp.Variable((32, 32))\n",
    "\n",
    "# Loss Function\n",
    "loss_psd = cp.norm2(cp.vstack([A_psd @ z1[i] - z2[i] for i in range(z1.shape[0])]))**2 + lamda * cp.norm(A_psd, 'fro')**2\n",
    "\n",
    "# Objective Function\n",
    "objective_psd = cp.Minimize(loss_psd)\n",
    "\n",
    "# Constraints\n",
    "constraints = [A_psd >> 0]\n",
    "\n",
    "# Problem\n",
    "\n",
    "problem_psd = cp.Problem(objective_psd, constraints)\n",
    "\n",
    "# Solve the problem\n",
    "\n",
    "problem_psd.solve()\n",
    "\n",
    "# Print results\n",
    "print(\"Optimal value: \", problem_psd.value)\n",
    "print(A_psd.value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Transfomrmation with constraint (psd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_aff_psd = cp.Variable((32, 32))\n",
    "b_aff_psd = cp.Variable(32)\n",
    "\n",
    "# Loss Function\n",
    "loss_aff_psd = cp.norm2(cp.vstack([A_aff_psd @ z1[i] + b_aff_psd - z2[i] for i in range(z1.shape[0])]))**2 + lamda * cp.norm(A_aff_psd, 'fro')**2\n",
    "\n",
    "# Objective Function\n",
    "objective_aff_psd = cp.Minimize(loss_aff_psd)\n",
    "\n",
    "# Constraints\n",
    "constraints_aff_psd = [A_aff_psd >> 0]\n",
    "\n",
    "# Problem\n",
    "problem_aff_psd = cp.Problem(objective_aff_psd, constraints_aff_psd)\n",
    "\n",
    "# Solve the problem\n",
    "problem_aff_psd.solve()\n",
    "\n",
    "# Print results\n",
    "print(\"Optimal value: \", problem_aff_psd.value)\n",
    "print(A_aff_psd.value)\n",
    "print(b_aff_psd.value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different norms \n",
    "We begin to reformulate the problem with the L1 Norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_L1 = cp.Variable((32, 32))\n",
    "\n",
    "#May need another solver\n",
    "\n",
    "\n",
    "\n",
    "# Loss Function\n",
    "loss_L1 = cp.norm1(cp.vstack([A_L1 @ z1[i] - z2[i] for i in range(z1.shape[0])]))**2 + lamda * cp.norm(A_L1, '')**2\n",
    "\n",
    "# Objective Function\n",
    "objective_L1 = cp.Minimize(loss_L1)\n",
    "\n",
    "\n",
    "# Problem\n",
    "problem_L1= cp.Problem(objective_L1)\n",
    "\n",
    "# Solve the problem\n",
    "problem_L1.solve(verbose=True, solver=cp.ECOS)\n",
    "\n",
    "# Print results\n",
    "print(\"Optimal value: \", problem_L1.value)\n",
    "print(A_L1.value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the total distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Latent Space for al"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
