{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Transformation \n",
    "We will start with the alignement of the same models for different seeds. \n",
    "- First we do not restrict the matrix.\n",
    "- Second we restrict the matrix to be a rotation matrix.\n",
    "- Thrid use affine transformation \n",
    "- Last but not least we are using different norms and regularization techniques to improve the results\n",
    "\n",
    "\n",
    "\n",
    "Steps: \n",
    "- Load the same model but with different seed\n",
    "- Sample different images and get latent representation \n",
    "- Create Datamatrix X and X'\n",
    "- Solve the simple optimization problem (Using closed form solution as well cvxpy solver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.decomposition import PCA\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reimpmort modules with autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "config = {\n",
    "    'path1': \"/Users/federicoferoggio/Documents/vs_code/latent-communication/models/checkpoints/VAE/MNIST/MNIST_VAE_1_10.pth\",\n",
    "    'modelname1': 'VAE',\n",
    "    'seed1': '1',\n",
    "    'path2': \"/Users/federicoferoggio/Documents/vs_code/latent-communication/models/checkpoints/VAE/MNIST/MNIST_VAE_4_10.pth\",\n",
    "    'modelname2': 'VAE',\n",
    "    'seed2': '1',\n",
    "    'num_samples': '1000',\n",
    "    'storage_path': 'VAE-ResNet-LinearTransform',\n",
    "\n",
    "}\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Problem in the Linear Case \n",
    "Let $x^i,y^i \\in \\mathbb{R^n}$ for $i = 1,...,m$ and $A \\in \\mathbb{R}^{n \\times n}$ we are looking for the optimal A, which solves the following optimization problem \n",
    "$$ min_A \\sum_{i = 1}^n ||Ax^i - y^i||^2 $$\n",
    "$$ min_ a \\sum_{i=1} \\sum_{j =1} (A_{(j)} x^i - y^i_j)^2 $$\n",
    "where we are using the euclidian norm when not otherwise stated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Transformed Data for VAE\n",
    "In this section we load the trained models, which we prepaired for our experimental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils.dataloaders.DataLoaderMNIST_single import DataLoader_MNIST\n",
    "\n",
    "\n",
    "def load_model(model_name, model_path):\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "    if model_name == 'VAE':\n",
    "        from models.definitions.vae import VAE\n",
    "        model = VAE(in_dim=784, dims=[256, 128, 64, 32], distribution_dim=16).to(DEVICE)\n",
    "    elif model_name == 'resnet':\n",
    "        from models.definitions.resnet import ResNet\n",
    "        model = ResNet().to(DEVICE)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    return model\n",
    "\n",
    "def load_Models():\n",
    "    model1 = load_model(config['modelname1'], config['path1'])\n",
    "    model2 = load_model(config['modelname2'], config['path2'])\n",
    "    return model1, model2\n",
    "\n",
    "def get_transformations(model_name):\n",
    "    if model_name == 'VAE':\n",
    "        return [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,)),\n",
    "            transforms.Lambda(lambda x: x.view(-1))\n",
    "        ]\n",
    "    elif model_name == 'resnet':\n",
    "        return [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.repeat(3, 1, 1))\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "\n",
    "def transformations():\n",
    "    transformations1 = get_transformations(config['modelname1'])\n",
    "    transformations2 = get_transformations(config['modelname2'])\n",
    "    return transformations1, transformations2\n",
    "\n",
    "# Load models\n",
    "model1, model2 = load_Models()\n",
    "\n",
    "# Get transformations\n",
    "transformations1, transformations2 = transformations()\n",
    "\n",
    "# Initialize data loader\n",
    "data_loader_VAE_1 = DataLoader_MNIST(128, get_transformations(config['modelname1']), seed=10)\n",
    "len_dataset_train = len(data_loader_VAE_1.get_train_loader().dataset)\n",
    "print(len_dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(int(config['num_samples']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 32) (1000, 32)\n"
     ]
    }
   ],
   "source": [
    "from utils.sampler import simple_sampler, class_sampler\n",
    "indices = np.random.permutation(len_dataset_train)[:int(config['num_samples'])]\n",
    "z1 = simple_sampler(indices, model1, transformations1, DEVICE)\n",
    "z2 = simple_sampler(indices, model2, transformations2, DEVICE)\n",
    "#\n",
    "# Sample from each class\n",
    "print(z1.shape, z2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex Optimization Solver\n",
    "## Linear Transformation with regularization\n",
    "We are using the cvxpy solver which is a open source solver for convex optimization problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/federicoferoggio/Documents/vs_code/latent-communication/optimization\n",
      "Solving the problem\n",
      "Defining the problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federicoferoggio/Documents/vs_code/latent-communication/.zeroshot/lib/python3.9/site-packages/cvxpy/problems/problem.py:164: UserWarning: Constraint #0 contains too many subexpressions. Consider vectorizing your CVXPY code to speed up compilation.\n",
      "  warnings.warn(f\"Constraint #{i} contains too many subexpressions. \"\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "#Ã¤ Get wd \n",
    "print(os.getcwd())\n",
    "# Linear Transformation\n",
    "from optimizer import LinearFitting\n",
    "\n",
    "linear_fitting = LinearFitting(z1, z2,lamda=0.01)\n",
    "\n",
    "linear_fitting.solve_problem()\n",
    "\n",
    "loss, A  = linear_fitting.get_results()\n",
    "\n",
    "name = 'Linear_' + config['modelname1'] + '_' + config['seed1'] + '_' + config['modelname2'] + '_' + config['seed2'] + '_' + config['num_samples']\n",
    "path = 'results/' + config['storage_path'] + '/' + name \n",
    "\n",
    "#linear_fitting.save_results(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine transformation\n",
    "In this section we implement the affine transformation. We are adding a offset to the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizer import AffineFitting\n",
    "\n",
    "affine_fitting = AffineFitting(z1, z2, lamda=0.01)\n",
    "\n",
    "# Solve the problem\n",
    "affine_fitting.solve_problem()\n",
    "\n",
    "# Get the results\n",
    "loss, A, b = affine_fitting.get_results()\n",
    "\n",
    "# Show the results\n",
    "print('Loss:', loss)\n",
    "print('A:', A)\n",
    "print('b:', b)\n",
    "\n",
    "# Save the results\n",
    "name = 'Affine_' + config['modelname1'] + '_' + config['seed1'] + '_' + config['modelname2'] + '_' + config['seed2'] + '_' + config['num_samples']\n",
    "path = 'optimization/'+ config['storage_path'] + '/' + name\n",
    "\n",
    "\n",
    "# Save the results\n",
    "affine_fitting.save_results(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Transformation with constraints (psd)\n",
    "In this section we relax the problem and consider that the matrix has to be positive semidefinite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization Variable\n",
    "A_psd = cp.Variable((32, 32))\n",
    "\n",
    "# Loss Function\n",
    "loss_psd = cp.norm2(cp.vstack([A_psd @ z1[i] - z2[i] for i in range(z1.shape[0])]))**2 + lamda * cp.norm(A_psd, 'fro')**2\n",
    "\n",
    "# Objective Function\n",
    "objective_psd = cp.Minimize(loss_psd)\n",
    "\n",
    "# Constraints\n",
    "constraints = [A_psd >> 0]\n",
    "\n",
    "# Problem\n",
    "\n",
    "problem_psd = cp.Problem(objective_psd, constraints)\n",
    "\n",
    "# Solve the problem\n",
    "\n",
    "problem_psd.solve()\n",
    "\n",
    "# Print results\n",
    "print(\"Optimal value: \", problem_psd.value)\n",
    "print(A_psd.value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Transfomrmation with constraint (psd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_aff_psd = cp.Variable((32, 32))\n",
    "b_aff_psd = cp.Variable(32)\n",
    "\n",
    "# Loss Function\n",
    "loss_aff_psd = cp.norm2(cp.vstack([A_aff_psd @ z1[i] + b_aff_psd - z2[i] for i in range(z1.shape[0])]))**2 + lamda * cp.norm(A_aff_psd, 'fro')**2\n",
    "\n",
    "# Objective Function\n",
    "objective_aff_psd = cp.Minimize(loss_aff_psd)\n",
    "\n",
    "# Constraints\n",
    "constraints_aff_psd = [A_aff_psd >> 0]\n",
    "\n",
    "# Problem\n",
    "problem_aff_psd = cp.Problem(objective_aff_psd, constraints_aff_psd)\n",
    "\n",
    "# Solve the problem\n",
    "problem_aff_psd.solve()\n",
    "\n",
    "# Print results\n",
    "print(\"Optimal value: \", problem_aff_psd.value)\n",
    "print(A_aff_psd.value)\n",
    "print(b_aff_psd.value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different norms \n",
    "We begin to reformulate the problem with the L1 Norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_L1 = cp.Variable((32, 32))\n",
    "\n",
    "#May need another solver\n",
    "\n",
    "\n",
    "\n",
    "# Loss Function\n",
    "loss_L1 = cp.norm1(cp.vstack([A_L1 @ z1[i] - z2[i] for i in range(z1.shape[0])]))**2 + lamda * cp.norm(A_L1, '')**2\n",
    "\n",
    "# Objective Function\n",
    "objective_L1 = cp.Minimize(loss_L1)\n",
    "\n",
    "\n",
    "# Problem\n",
    "problem_L1= cp.Problem(objective_L1)\n",
    "\n",
    "# Solve the problem\n",
    "problem_L1.solve(verbose=True, solver=cp.ECOS)\n",
    "\n",
    "# Print results\n",
    "print(\"Optimal value: \", problem_L1.value)\n",
    "print(A_L1.value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the total distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Latent Space for al"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
