{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working directory: /mnt/c/Users/Hillary Hauger/Documents/Studium/SoSe2024/Case Study Non Linear Optimization/Code\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(os.path.dirname(os.path.abspath(\"\")))\n",
    "print(\"current working directory:\", os.getcwd())\n",
    "\n",
    "from utils.dataloaders.full_dataloaders import DataLoaderMNIST, DataLoaderFashionMNIST, DataLoaderCIFAR10, DataLoaderCIFAR100\n",
    "from utils.visualization import (\n",
    "    visualize_mapping_error,\n",
    "    visualize_latent_space_pca,\n",
    "    plot_latent_space,\n",
    "    highlight_cluster,\n",
    ")\n",
    "from utils.model import load_model, get_transformations\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stitched_output(model1, model2, mapping, images):\n",
    "    latent_space1 = model1.get_latent_space(images).to(dtype=torch.float32)\n",
    "    latent_space_stitched = mapping.predict(latent_space1.detach().cpu())\n",
    "    #Convert to tensor if necessary and to the right dtype\n",
    "    if isinstance(latent_space_stitched, np.ndarray):\n",
    "        latent_space_stitched = torch.tensor(latent_space_stitched, dtype=torch.float32)\n",
    "    elif isinstance(latent_space_stitched, torch.Tensor):\n",
    "        latent_space_stitched = latent_space_stitched.to(dtype=torch.float32)\n",
    "    \n",
    "    outputs = model2.decode(latent_space_stitched.to(DEVICE))\n",
    "    return outputs\n",
    "\n",
    "def simple_sampler(indices, model, transformations, device, seed=10):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    - model: Model\n",
    "    - indices: Indices of the dataset\n",
    "    - transformations: Transformations to be applied to the images\n",
    "    Output:\n",
    "    - z: Latent vectors of the model\n",
    "    - labels: Labels of the dataset\n",
    "\n",
    "    This function samples the latent space of the model and returns the latent vectors\n",
    "    \"\"\"\n",
    "    data_loader = DataLoaderMNIST(128, transformations, seed=seed, indices=indices)\n",
    "    train_loader = data_loader.get_train_loader()\n",
    "\n",
    "    # get all images from train_loader and convert them to latent space\n",
    "    all_images = []\n",
    "    all_latent_space=[]\n",
    "    for images, _ in train_loader:\n",
    "        images = images.to(device)\n",
    "        latent_space = model.get_latent_space(images)\n",
    "        all_latent_space.append(latent_space)\n",
    "        all_images.append(images)\n",
    "    images = torch.cat(all_images, dim=0)\n",
    "    z = torch.cat(all_latent_space, dim=0)\n",
    "    z = z.detach().cpu().numpy()\n",
    "    labels = data_loader.train_loader.dataset.dataset.targets[indices]\n",
    "    return z,images,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_model = \"VerySmall-AE\"\n",
    "name_dataset = \"MNIST\"\n",
    "size_of_the_latent = 10\n",
    "seed1,seed2=1,2\n",
    "num_samples = 200\n",
    "model_path1 = f\"models/checkpoints/VerySmallAE/{name_dataset}/{name_dataset}_{name_model}_{size_of_the_latent}_{seed1}.pth\"\n",
    "model_path2 = f\"models/checkpoints/VerySmallAE/{name_dataset}/{name_dataset}_{name_model}_{size_of_the_latent}_{seed2}.pth\"\n",
    "model1 = load_model(model_name=name_model, name_dataset=name_dataset, latent_size=int(size_of_the_latent), seed=int(seed1), model_path = model_path1)\n",
    "model2 = load_model(model_name=name_model, name_dataset=name_dataset, latent_size=int(size_of_the_latent), seed=int(seed2), model_path = model_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device (CPU/GPU): cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(\"Using device (CPU/GPU):\", device)\n",
    "transformations = get_transformations(name_model)\n",
    "indices = np.random.randint(0, 10000, num_samples)\n",
    "latent_space1, images,labels = simple_sampler(indices, model1, transformations, device, seed=10)\n",
    "latent_space2, images,labels = simple_sampler(indices, model2, transformations, device, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 10)\n",
      "(200, 10)\n"
     ]
    }
   ],
   "source": [
    "print(latent_space1.shape)\n",
    "print(latent_space2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dual coefficients (alpha):\n",
      "(160, 10)\n",
      "Predictions error on train set:\n",
      "44.140335\n",
      "Predictions error on test set\n",
      "46.823223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X= latent_space1\n",
    "y =latent_space2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "kr = KernelRidge(kernel='rbf', gamma=0.1, alpha=1.0)\n",
    "kr.fit(X_train,y_train)\n",
    "\n",
    "print(\"Dual coefficients (alpha):\")\n",
    "print(kr.dual_coef_.shape)\n",
    "\n",
    "# Make predictions\n",
    "predictions = kr.predict(X_train)\n",
    "print(\"Predictions error on train set:\")\n",
    "print(np.linalg.norm(predictions-y_train))\n",
    "predictions = kr.predict(X_test)\n",
    "print(\"Predictions error on test set\")\n",
    "print(np.linalg.norm(predictions-y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficent:\n",
      "(10, 10)\n",
      "Predictions error on train set:\n",
      "23.043707\n",
      "Predictions error on test set\n",
      "13.790824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Create and fit the Linear Regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Coefficent:\")\n",
    "print(lr.coef_.shape)\n",
    "\n",
    "# Make predictions\n",
    "predictions = lr.predict(X_train)\n",
    "print(\"Predictions error on train set:\")\n",
    "print(np.linalg.norm(predictions-y_train))\n",
    "predictions = lr.predict(X_test)\n",
    "print(\"Predictions error on test set\")\n",
    "print(np.linalg.norm(predictions-y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression coefficients:\n",
      "(10, 65)\n",
      "Predictions error on train set:\n",
      "13.207867\n",
      "Predictions error on test set\n",
      "15.442214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Generate example data\n",
    "\n",
    "# Polynomial regression setup (degree 2 for example)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly_train = poly.fit_transform(X_train)\n",
    "X_poly_test = poly.transform(X_test)\n",
    "\n",
    "# Create and fit the Polynomial Regression model\n",
    "lr_poly = LinearRegression()\n",
    "lr_poly.fit(X_poly_train, y_train)\n",
    "\n",
    "print(\"Polynomial Regression coefficients:\")\n",
    "print(lr_poly.coef_.shape)\n",
    "\n",
    "# Make predictions\n",
    "predictions = lr_poly.predict(X_poly_train)\n",
    "print(\"Predictions error on train set:\")\n",
    "print(np.linalg.norm(predictions-y_train))\n",
    "predictions = lr_poly.predict(X_poly_test)\n",
    "print(\"Predictions error on test set\")\n",
    "print(np.linalg.norm(predictions-y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spline Regression coefficients shape:\n",
      "(10, 60)\n",
      "\n",
      "Spline Regression Predictions error on train set:\n",
      "16.928808\n",
      "Spline Regression Predictions error on test set:\n",
      "16.00588\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import SplineTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a spline transformer\n",
    "spline_transformer = SplineTransformer(degree=3, n_knots=5, include_bias=False)\n",
    "\n",
    "# Create a pipeline with the spline transformer and linear regression\n",
    "spline_regression = make_pipeline(spline_transformer, LinearRegression())\n",
    "spline_regression.fit(X_train, y_train)\n",
    "\n",
    "# Print the shape of the coefficients for Spline Regression\n",
    "print(\"\\nSpline Regression coefficients shape:\")\n",
    "print(spline_regression.named_steps['linearregression'].coef_.shape)\n",
    "\n",
    "# Make predictions with Spline Regression\n",
    "spline_train_predictions = spline_regression.predict(X_train)\n",
    "spline_test_predictions = spline_regression.predict(X_test)\n",
    "\n",
    "# Evaluate the Spline Regression model\n",
    "spline_train_error = np.linalg.norm(spline_train_predictions - y_train)\n",
    "spline_test_error = np.linalg.norm(spline_test_predictions - y_test)\n",
    "\n",
    "print(\"\\nSpline Regression Predictions error on train set:\")\n",
    "print(spline_train_error)\n",
    "print(\"Spline Regression Predictions error on test set:\")\n",
    "print(spline_test_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
