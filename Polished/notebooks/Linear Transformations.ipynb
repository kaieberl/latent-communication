{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Transformation \n",
    "\n",
    "\n",
    "This notebook creates a linear transformation between two latent spaces. It takes as input two models, and uses then cvxpy to optimize a matrix to transform model 1 into model 2. The Anchor points are selected purely at random in the latent space.\n",
    "\n",
    "Expected results are:\n",
    "- Representations in PCA of the two latent spaces\n",
    "- Representation of the transformed latent space of model 1\n",
    "- Output of a image inserted into model 1 and decoded by model 2 through latent stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federicoferoggio/Documents/vs_code/latent-communication/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import relevant libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "from gekko import GEKKO\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration\n",
    "# Add here all the models that we want to use\n",
    "# Naming convention is 'path' + number of model + 'modelname' + number of model\n",
    "\n",
    "config = {\n",
    "    'path1': \"Polished/models/checkpoints/Pretrained_AE/MNIST/LightningAutoencoder_3.ckpt\",\n",
    "    'modelname1': 'Model 1',\n",
    "    'path2' : 'Polished/models/checkpoints/Mario_VAE/MNIST/MNIST_VAE_3_10.pth',\n",
    "    'modelname2': 'Model 2',\n",
    "}\n",
    "\n",
    "os.chdir('/Users/federicoferoggio/Documents/vs_code/latent-communication/')\n",
    "\n",
    "from Polished.models.definitions.Pretrained_Autoencoder import LightningAutoencoder\n",
    "from Polished.models.definitions.VariationalAE import VAE\n",
    "\n",
    "model1 = LightningAutoencoder.load_from_checkpoint(checkpoint_path=config['path1'])\n",
    "\n",
    "model2 = VAE(in_dim=784, dims=[256, 128, 64, 32], distribution_dim=16)\n",
    "model2.load_state_dict(state_dict = torch.load(config['path2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Problem in the Linear Case \n",
    "Let $x^i,y^i \\in \\mathbb{R^n}$ for $i = 1,...,m$ and $A \\in \\mathbb{R}^{n \\times n}$ we are looking for the optimal A, which solves the following optimization problem \n",
    "$$ min_A \\sum_{i = 1}^n ||Ax^i - y^i||^2 $$\n",
    "where we are using the euclidian norm when not otherwise stated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Here the dataset is loaded. For stability, the anchors are also defined here, so any change in that can be done here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 28, 28])\n",
      "torch.Size([500, 500])\n",
      "torch.Size([32, 500])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import Data \n",
    "from Polished.utils.dataloaders.DataLoaderMNIST_single import DataLoader_MNIST\n",
    "\n",
    "# Transdormations\n",
    "transformations = [transforms.ToTensor(), \n",
    "                                # Normalize between -1 and 1\n",
    "                                transforms.Normalize((0.5,), (0.5,))\n",
    "                                ]\n",
    "# Load the data\n",
    "data_loader = DataLoader_MNIST(128, transformations)\n",
    "\n",
    "n_anchors = 500\n",
    "images, _ = next(iter(data_loader.train_loader))\n",
    "all_images = []\n",
    "all_labels = []\n",
    "for images, labels in data_loader.train_loader:\n",
    "    all_images.append(images)\n",
    "    all_labels.append(labels)\n",
    "# Concatenate all the batches to form a single tensor for images and labels\n",
    "all_images = torch.cat(all_images, dim=0)\n",
    "all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "# Distinct labels\n",
    "labels = torch.unique(all_labels)\n",
    "# Sample size per label\n",
    "m_per_label = n_anchors // len(labels)\n",
    "# Sample from each label\n",
    "indices = []\n",
    "for label in labels:\n",
    "    indices_label = np.where(all_labels == label)[0]\n",
    "    indices_label = np.random.choice(indices_label, m_per_label, replace=False)\n",
    "    indices.extend(indices_label)\n",
    "\n",
    "all_images_sample = all_images[indices]\n",
    "all_labels_sample = all_labels[indices]\n",
    "\n",
    "print(all_images_sample.shape)\n",
    "\n",
    "# Get latent space \n",
    "z1 = model1.get_latent_space(all_images_sample)\n",
    "all_images_sample_view_for_vae = all_images_sample.view(-1, 784)\n",
    "z2 = model2.get_latent_space(all_images_sample_view_for_vae)\n",
    "\n",
    "print(z1.T.shape)\n",
    "print(z2.T.shape)\n",
    "# Detach from GPU\n",
    "z1_values = z1.T.detach().numpy()\n",
    "z2_values = z2.T.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "For the optimization, it is assumed that the first model has a bigger latent space than the second one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.5.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) May 30 12:41:56 PM: Your problem has 16000 variables, 0 constraints, and 0 parameters.\n",
      "(CVXPY) May 30 12:41:56 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) May 30 12:41:56 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) May 30 12:41:56 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) May 30 12:41:56 PM: Your problem is compiled with the CPP canonicalization backend.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) May 30 12:41:56 PM: Compiling problem (target solver=SCS).\n",
      "(CVXPY) May 30 12:41:56 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> SCS\n",
      "(CVXPY) May 30 12:41:56 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) May 30 12:41:56 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) May 30 12:41:56 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) May 30 12:42:10 PM: Applying reduction SCS\n",
      "(CVXPY) May 30 12:42:10 PM: Finished problem compilation (took 1.445e+01 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) May 30 12:42:10 PM: Invoking solver SCS  to obtain a solution.\n",
      "------------------------------------------------------------------\n",
      "\t       SCS v3.2.4 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012\n",
      "------------------------------------------------------------------\n",
      "problem:  variables n: 16501, constraints m: 16501\n",
      "cones: \t  z: primal zero / dual free vars: 500\n",
      "\t  q: soc vars: 16001, qsize: 1\n",
      "settings: eps_abs: 1.0e-05, eps_rel: 1.0e-05, eps_infeas: 1.0e-07\n",
      "\t  alpha: 1.50, scale: 1.00e-01, adaptive_scale: 1\n",
      "\t  max_iters: 100000, normalize: 1, rho_x: 1.00e-06\n",
      "\t  acceleration_lookback: 10, acceleration_interval: 10\n",
      "lin-sys:  sparse-direct-amd-qdldl\n",
      "\t  nnz(A): 6393813, nnz(P): 500\n",
      "------------------------------------------------------------------\n",
      " iter | pri res | dua res |   gap   |   obj   |  scale  | time (s)\n",
      "------------------------------------------------------------------\n",
      "     0| 7.73e+01  1.91e+00  1.73e+02  9.86e+01  1.00e-01  4.84e+00 \n",
      "   250| 5.74e-02  9.74e-03  2.43e-01  9.78e+01  1.00e-01  1.07e+01 \n",
      "   500| 1.84e-01  1.00e-02  2.56e-01  8.70e+01  3.13e-02  2.02e+01 \n",
      "   750| 7.34e-02  4.24e-03  1.19e-01  6.79e+01  3.13e-02  2.59e+01 \n",
      "  1000| 6.76e-01  1.19e-02  1.03e-01  7.95e+01  3.03e-03  3.93e+01 \n",
      "  1250| 2.97e-01  2.03e-03  5.29e-02  5.44e+01  3.03e-03  4.50e+01 \n",
      "  1500| 8.59e-02  2.98e-04  1.37e-02  4.76e+01  3.03e-03  5.07e+01 \n",
      "  1750| 6.25e-02  1.78e-04  1.09e-02  4.69e+01  3.03e-03  5.64e+01 \n",
      "  2000| 4.41e-02  2.31e-04  2.10e-04  4.76e+01  3.03e-03  6.21e+01 \n",
      "  2250| 2.20e-02  1.54e-04  1.77e-03  4.73e+01  3.03e-03  6.78e+01 \n",
      "  2500| 4.71e-01  3.19e-03  6.99e-03  4.65e+01  3.03e-03  7.36e+01 \n",
      "  2750| 8.73e-03  4.41e-05  3.75e-04  4.69e+01  3.03e-03  7.93e+01 \n",
      "  3000| 5.48e-03  3.57e-05  2.15e-04  4.68e+01  3.03e-03  8.51e+01 \n",
      "  3100| 4.83e-03  3.36e-05  2.93e-04  4.68e+01  3.03e-03  8.74e+01 \n",
      "------------------------------------------------------------------\n",
      "status:  solved\n",
      "timings: total: 8.74e+01s = setup: 4.78e+00s + solve: 8.26e+01s\n",
      "\t lin-sys: 6.94e+01s, cones: 1.34e-01s, accel: 5.14e-02s\n",
      "------------------------------------------------------------------\n",
      "objective = 46.812442\n",
      "------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) May 30 12:43:38 PM: Problem status: optimal\n",
      "(CVXPY) May 30 12:43:38 PM: Optimal value: 4.668e+01\n",
      "(CVXPY) May 30 12:43:38 PM: Compilation took 1.445e+01 seconds\n",
      "(CVXPY) May 30 12:43:38 PM: Solver (including time spent in interface) took 8.739e+01 seconds\n",
      "Optimal value:  46.678340520755114\n",
      "[[-4.16344401e-02  3.01753129e+01 -2.54974419e+00 ... -9.88259225e-03\n",
      "  -9.31001984e+00 -4.47956821e+00]\n",
      " [-4.16344401e-02  3.01753129e+01 -2.54974419e+00 ... -9.88259225e-03\n",
      "  -9.31001984e+00 -4.47956821e+00]\n",
      " [-4.16344401e-02  3.01753129e+01 -2.54974419e+00 ... -9.88259225e-03\n",
      "  -9.31001984e+00 -4.47956821e+00]\n",
      " ...\n",
      " [-4.16344401e-02  3.01753129e+01 -2.54974419e+00 ... -9.88259225e-03\n",
      "  -9.31001984e+00 -4.47956821e+00]\n",
      " [-4.16344401e-02  3.01753129e+01 -2.54974419e+00 ... -9.88259225e-03\n",
      "  -9.31001984e+00 -4.47956821e+00]\n",
      " [-4.16344401e-02  3.01753129e+01 -2.54974419e+00 ... -9.88259225e-03\n",
      "  -9.31001984e+00 -4.47956821e+00]]\n"
     ]
    }
   ],
   "source": [
    "lamda = 0.01\n",
    "\n",
    "latent_size_1, n_anchors = z1_values.shape\n",
    "latent_size_2, _ = z2_values.shape\n",
    "\n",
    "A = cp.Variable((latent_size_2, latent_size_1))\n",
    "\n",
    "loss = cp.sum((cp.vstack([cp.sum(A @ z1_values[:,i] - z2_values[:,i])**2 for i in range(n_anchors)]))) + lamda * cp.norm(A, 'fro')\n",
    "objective = cp.Minimize(loss)\n",
    "problem = cp.Problem(objective)\n",
    "\n",
    "# Solve the problem\n",
    "problem.solve(verbose=True, solver=cp.SCS, enforce_dpp = True)\n",
    "\n",
    "# Print results\n",
    "print(\"Optimal value: \", problem.value)\n",
    "print(A.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plot_pca_latent.pca_def() got an unexpected keyword argument 'vector'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPolished\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting_fun\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot_pca_latent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_pca_latent\n\u001b[1;32m      3\u001b[0m plotting_fun1 \u001b[38;5;241m=\u001b[39m plot_pca_latent(data_loader)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mplotting_fun1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpca_def\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mz1_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m plotting_fun1\u001b[38;5;241m.\u001b[39mplotLatentTransformed(model1, np\u001b[38;5;241m.\u001b[39meye(latent_size_1), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel 1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m plotting_fun2 \u001b[38;5;241m=\u001b[39m plot_pca_latent(data_loader)\n",
      "\u001b[0;31mTypeError\u001b[0m: plot_pca_latent.pca_def() got an unexpected keyword argument 'vector'"
     ]
    }
   ],
   "source": [
    "from Polished.utils.plotting_fun.plot_pca_latent import Plot_pca_latent\n",
    "\n",
    "plotting_fun1 = Plot_pca_latent(data_loader)\n",
    "plotting_fun1.pca_def(vector = z1_values)\n",
    "plotting_fun1.plot_latent_transformed(model1, np.eye(latent_size_1), 'Model 1')\n",
    "\n",
    "plotting_fun2 = Plot_pca_latent(data_loader)\n",
    "plotting_fun2.pca_def(z2_values)\n",
    "plotting_fun2.plot_latent_transformed(model2, np.eye(latent_size_2), 'Model 2')\n",
    "\n",
    "plotting_fun2.plot_latent_transformed(model1, A.values, 'Model 1 Transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Polished.utils.metrics.distances import Distances\n",
    "\n",
    "distances = Distances(model1, model2)\n",
    "print(distances.distance_latents(A.value @ z1_values, z2_values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
