{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Transformation \n",
    "We will start with the alignement of the same models for different seeds. \n",
    "- First we do not restrict the matrix.\n",
    "- Second we restrict the matrix to be a rotation matrix.\n",
    "- Thrid use affine transformation \n",
    "- Last but not least we are using different norms and regularization techniques to improve the results\n",
    "\n",
    "\n",
    "\n",
    "Steps: \n",
    "- Load the same model but with different seed\n",
    "- Sample different images and get latent representation \n",
    "- Create Datamatrix X and X'\n",
    "- Solve the simple optimization problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federicoferoggio/Documents/vs_code/latent-communication/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import relevant libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "config = {\n",
    "    'path1': \"/Users/federicoferoggio/Documents/vs_code/latent-communication/Pretrained_models/LightningAutoencoder_1.ckpt\",\n",
    "    'modelname1': 'AE1',\n",
    "    'path2': \"/Users/federicoferoggio/Documents/vs_code/latent-communication/Pretrained_models/LightningAutoencoder_1.ckpt\",\n",
    "    'modelname2': 'AE2',\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Problem in the Linear Case \n",
    "Let $x^i,y^i \\in \\mathbb{R^n}$ for $i = 1,...,m$ and $A \\in \\mathbb{R}^{n \\times n}$ we are looking for the optimal A, which solves the following optimization problem \n",
    "$$ min_A \\sum_{i = 1}^n ||Ax^i - y^i||^2 $$\n",
    "where we are using the euclidian norm when not otherwise stated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Transformed Data for VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get working directory\n",
    "import os\n",
    "# Change directory\n",
    "os.chdir('/Users/federicoferoggio/Documents/vs_code/latent-communication/')\n",
    "\n",
    "# Import Data \n",
    "from helper.DataLoaderMNIST import DataLoader_MNIST\n",
    "\n",
    "# Transdormations\n",
    "transformations = [transforms.ToTensor(), \n",
    "                                # Normalize between -1 and 1\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                                # Flatten the Image to a vector\n",
    "                                transforms.Lambda(lambda x: x.view(-1) )\n",
    "                                ]\n",
    "# Load the data\n",
    "data_loader = DataLoader_MNIST(128, transformations)\n",
    "\n",
    "from AE.model_def import LightningAutoencoder\n",
    "\n",
    "# Initialize the models\n",
    "model1 = LightningAutoencoder()\n",
    "\n",
    "# Load pretrained weights for model1\n",
    "model1 = LightningAutoencoder.load_from_checkpoint(checkpoint_path=config['path1'])\n",
    "# Initialize the model 2\n",
    "model2 = LightningAutoencoder()\n",
    "# Load pretrained weights for model2\n",
    "model2 = LightningAutoencoder.load_from_checkpoint(checkpoint_path=config['path2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling \n",
    "We sample images from the train set and encode those for each model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 500])\n",
      "torch.Size([128, 500])\n"
     ]
    }
   ],
   "source": [
    "# Sample Size \n",
    "m = 100\n",
    "\n",
    "# Sample images from train set \n",
    "images, _ = next(iter(data_loader.train_loader))\n",
    "\n",
    "\n",
    "images = images.view(images.size(0), 1, 28, 28)\n",
    "#\n",
    "z1 = model1.getLatenSpace(images)\n",
    "z2 = model2.getLatenSpace(images)\n",
    "\n",
    "print(z1.shape)\n",
    "print(z2.shape)\n",
    "# Detach from GPU\n",
    "z1 = z1.detach().cpu().numpy()\n",
    "z2 = z2.detach().cpu().numpy()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calulate optimal matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 500)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m d \u001b[38;5;241m=\u001b[39m z1\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Initalize the matrices\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m L \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((d, d))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Compute the matrices\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# Regularization \n",
    "lamda = 0.0001\n",
    "\n",
    "print(z1.shape)\n",
    "# Get the dimensions of the latent space\n",
    "d = z1.shape[1]\n",
    "\n",
    "\n",
    "# Initalize the matrices\n",
    "M = np.zeros((d, d))\n",
    "L = np.zeros((d, d))\n",
    "\n",
    "# Compute the matrices\n",
    "for i in range(d):\n",
    "    M = M + np.outer(z1[1][i], z2[1][i])\n",
    "    L = L + np.outer(z1[1][i], z2[1][i])\n",
    "\n",
    "# COmpute the optimal regularized matrix\n",
    "A = L @ np.linalg.inv(M + lamda * np.eye(d))\n",
    "\n",
    "# Compute distance\n",
    "np.linalg.norm(A@z1[1][i] - z2[1][i])\n",
    "distance = np.zeros(m)\n",
    "for i in range(m):\n",
    "    distance[i] = np.linalg.norm(A@z1[1][i] - z2[1][i])\n",
    "\n",
    "# Plot the distance\n",
    "plt.hist(distance)\n",
    "\n",
    "# Overall Loss \n",
    "\n",
    "overall_loss = np.mean(distance)\n",
    "print(overall_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DEVICE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Iterate through all batches in train_loader\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m data_loader\u001b[38;5;241m.\u001b[39mtrain_loader:\n\u001b[0;32m----> 8\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(\u001b[43mDEVICE\u001b[49m)\n\u001b[1;32m      9\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mview(images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m     latent_space \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgetLatenSpace(images)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DEVICE' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Latent Space\n",
    "latent_spaces = []\n",
    "latent_spaces2 = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterate through all batches in train_loader\n",
    "for images, labels in data_loader.train_loader:\n",
    "    images = images.to(DEVICE)\n",
    "    images = images.view(images.size(0), -1)\n",
    "    latent_space = model.getLatenSpace(images)\n",
    "    latent_space2 = model2.getLatenSpace(images)\n",
    "    latent_spaces.append(latent_space.cpu().detach().numpy())\n",
    "    latent_spaces2.append(latent_space2.cpu().detach().numpy())\n",
    "    all_labels.append(labels.numpy())\n",
    "\n",
    "# Concatenate latent space representations from all batches\n",
    "latent_space = np.concatenate(latent_spaces, axis=0)\n",
    "latent_space2 = np.concatenate(latent_spaces2, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "print(latent_space.shape)\n",
    "print(all_labels.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Plot latent space via PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "\n",
    "latent_space_pca = pca.fit_transform(latent_space)\n",
    "\n",
    "# Plot the latent space\n",
    "plot = plt.scatter(latent_space_pca[:, 0], latent_space_pca[:, 1], c=all_labels, cmap='tab10', label=all_labels)\n",
    "plt.show(plot)\n",
    "\n",
    "# Transform the latent space\n",
    "latent_space_transformed = np.dot(latent_space, A.T)\n",
    "# Plot latent space via PCA\n",
    "pca = PCA(n_components=2)\n",
    "latent_space_pca = pca.fit_transform(latent_space_transformed)\n",
    "\n",
    "# Plot the latent space\n",
    "plot = plt.scatter(latent_space_pca[:, 0], latent_space_pca[:, 1], c=all_labels, cmap='tab10', label=all_labels)\n",
    "plt.show(plot)\n",
    "\n",
    "\n",
    "# Plot the second latent space\n",
    "latent_space_pca2 = pca.fit_transform(latent_space2)\n",
    "\n",
    "pca_second = PCA(n_components=2)\n",
    "plot_second = plt.scatter(latent_space_pca2[:, 0], latent_space_pca2[:, 1], c=all_labels, cmap='tab10', label=all_labels)\n",
    "plt.show(plot_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
