{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Transformation \n",
    "We will start with the alignement of the same models for different seeds. \n",
    "- First we do not restrict the matrix.\n",
    "- Second we restrict the matrix to be a rotation matrix.\n",
    "- Thrid use affine transformation \n",
    "- Last but not least we are using different norms and regularization techniques to improve the results\n",
    "\n",
    "\n",
    "\n",
    "Steps: \n",
    "- Load the same model but with different seed\n",
    "- Sample different images and get latent representation \n",
    "- Create Datamatrix X and X'\n",
    "- Solve the simple optimization problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federicoferoggio/Documents/vs_code/latent-communication/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import relevant libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from gekko import GEKKO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "config = {\n",
    "    'path1': \"/Users/federicoferoggio/Documents/vs_code/latent-communication/Pretrained_models/LightningAutoencoder_1.ckpt\",\n",
    "    'modelname1': 'AE1',\n",
    "    'path2': \"/Users/federicoferoggio/Documents/vs_code/latent-communication/Pretrained_models/LightningAutoencoder_1.ckpt\",\n",
    "    'modelname2': 'AE2',\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Problem in the Linear Case \n",
    "Let $x^i,y^i \\in \\mathbb{R^n}$ for $i = 1,...,m$ and $A \\in \\mathbb{R}^{n \\times n}$ we are looking for the optimal A, which solves the following optimization problem \n",
    "$$ min_A \\sum_{i = 1}^n ||Ax^i - y^i||^2 $$\n",
    "where we are using the euclidian norm when not otherwise stated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Transformed Data for VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get working directory\n",
    "import os\n",
    "# Change directory\n",
    "os.chdir('/Users/federicoferoggio/Documents/vs_code/latent-communication/')\n",
    "\n",
    "# Import Data \n",
    "from helper.DataLoaderMNIST_single import DataLoader_MNIST\n",
    "\n",
    "# Transdormations\n",
    "transformations = [transforms.ToTensor(), \n",
    "                                # Normalize between -1 and 1\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                                # Flatten the Image to a vector\n",
    "                                transforms.Lambda(lambda x: x.view(-1) )\n",
    "                                ]\n",
    "# Load the data\n",
    "data_loader = DataLoader_MNIST(128, transformations)\n",
    "\n",
    "from AE.model_def import LightningAutoencoder\n",
    "\n",
    "# Initialize the models\n",
    "model1 = LightningAutoencoder()\n",
    "\n",
    "# Load pretrained weights for model1\n",
    "model1 = LightningAutoencoder.load_from_checkpoint(checkpoint_path=config['path1'])\n",
    "# Initialize the model 2\n",
    "model2 = LightningAutoencoder()\n",
    "# Load pretrained weights for model2\n",
    "model2 = LightningAutoencoder.load_from_checkpoint(checkpoint_path=config['path2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling \n",
    "We sample images from the train set and encode those for each model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 600])\n",
      "torch.Size([500, 600])\n"
     ]
    }
   ],
   "source": [
    "m = 600\n",
    "images, _ = next(iter(data_loader.train_loader))\n",
    "all_images = []\n",
    "all_labels = []\n",
    "for images, labels in data_loader.train_loader:\n",
    "    all_images.append(images)\n",
    "    all_labels.append(labels)\n",
    "# Concatenate all the batches to form a single tensor for images and labels\n",
    "all_images = torch.cat(all_images, dim=0)\n",
    "all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "# Distinct labels\n",
    "labels = torch.unique(all_labels)\n",
    "# Sample size per label\n",
    "m_per_label = m // len(labels)\n",
    "# Sample from each label\n",
    "indices = []\n",
    "for label in labels:\n",
    "    indices_label = np.where(all_labels == label)[0]\n",
    "    indices_label = np.random.choice(indices_label, m_per_label, replace=False)\n",
    "    indices.extend(indices_label)\n",
    "\n",
    "all_images_sample = all_images[indices]\n",
    "all_labels_sample = all_labels[indices]\n",
    "\n",
    "all_images_sample = all_images_sample.view(-1, 1, 28, 28)\n",
    "\n",
    "# Get latent space \n",
    "z1 = model1.getLatenSpace(all_images_sample)\n",
    "z2 = model2.getLatenSpace(all_images_sample)\n",
    "\n",
    "print(z1.T.shape)\n",
    "print(z2.T.shape)\n",
    "# Detach from GPU\n",
    "z1_values = z1.T\n",
    "z2_values = z2.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calulate optimal matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading setup\n",
      "loading model\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 49\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# # Objective function: Minimize sum of squared differences with regularization\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# objective = 0\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# for i in range(d):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Define the objective function\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m objective \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m([m\u001b[38;5;241m.\u001b[39msum([A[i,j]\u001b[38;5;241m*\u001b[39m(z1[i,k]\u001b[38;5;241m-\u001b[39mz2[j,k])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(d) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(d)]) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m)])\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Set the objective function to be minimized\u001b[39;00m\n\u001b[1;32m     52\u001b[0m m\u001b[38;5;241m.\u001b[39mMinimize(objective)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "# Regularization parameter\n",
    "lamda = 0.0001\n",
    "\n",
    "# Get the dimensions of the latent space\n",
    "m, d = z1_values.shape\n",
    "\n",
    "\n",
    "# Initialize Gekko model\n",
    "model = GEKKO(remote=False)\n",
    "\n",
    "z1 = model.Array(model.Param, (m, d), value=z1_values)  # replace z1_values with your actual values\n",
    "z2 = model.Array(model.Param, (m, d), value=z2_values)  # replace z2_values with your actual values\n",
    "\n",
    "# Define the matrix variables in Gekko with initial guesses\n",
    "A = model.Array(model.Var, (m, m), value=1.0)\n",
    "\n",
    "print(\"loading setup\")\n",
    "\n",
    "# Set the mode to steady-state optimization (mode 3)\n",
    "model.options.DIAGLEVEL = 1\n",
    "model.options.IMODE = 2\n",
    "model.options.COLDSTART = 2\n",
    "model.options.SOLVER = 1\n",
    "model.solver_options = [\n",
    "    'max_iter 1000',     # Maximum number of iterations\n",
    "    'tol 1e-6',          # Tolerance\n",
    "    'acceptable_tol 1e-5',  # Acceptable tolerance\n",
    "    'acceptable_iter 10'  # Acceptable number of iterations\n",
    "]\n",
    "\n",
    "print(\"loading model\")\n",
    "\n",
    "# # Objective function: Minimize sum of squared differences with regularization\n",
    "# objective = 0\n",
    "# for i in range(d):\n",
    "#     print(i)\n",
    "#     z1_transformed = [model.sum([A[j][k] * z1[k, i] for k in range(m)]) for j in range(m)]\n",
    "#     for j in range(m):\n",
    "#         summed = (z1_transformed[j] - z2[j, i])**2\n",
    "#     objective += model.sqrt(summed)\n",
    "\n",
    "# # Regularization term (Frobenius norm)\n",
    "# reg_term = lamda * model.sqrt(model.sum([A[i][j]**2 for i in range(m) for j in range(m)]))\n",
    "\n",
    "# # Combine the objective and regularization term\n",
    "# model.Obj(objective + reg_term)\n",
    "\n",
    "# Define the objective function\n",
    "objective = model.sum([model.sum([A[i,j]*(z1[i,k]-z2[j,k])**2 for i in range(d) for j in range(d)]) for k in range(m)])\n",
    "\n",
    "# Set the objective function to be minimized\n",
    "m.Minimize(objective)\n",
    "\n",
    "# Solve the optimization problem\n",
    "print(\"solving\")\n",
    "model.solve(disp=True, debug=2)\n",
    "\n",
    "# Check if the solution is found and extract the optimized matrix A\n",
    "if model.options.APPSTATUS == 1 or model.options.APPSTATUS == 2:\n",
    "    A_opt = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            A_opt[i, j] = A[i][j].value[0]\n",
    "\n",
    "    # Compute distance\n",
    "    distance = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        z1_transformed = np.dot(A_opt, z1[i, :])\n",
    "        distance[i] = np.linalg.norm(z1_transformed - z2[i, :])\n",
    "\n",
    "    # Plot the distance\n",
    "    plt.hist(distance)\n",
    "    plt.title('Histogram of distances')\n",
    "    plt.xlabel('Distance')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    # Overall Loss \n",
    "    overall_loss = np.mean(distance)\n",
    "    print(f'Overall Loss: {overall_loss}')\n",
    "    print(f'Optimized Matrix A:\\n{A_opt}')\n",
    "else:\n",
    "    print(\"Solution not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Latent Space\n",
    "latent_spaces1 = []\n",
    "latent_spaces2 = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterate through all batches in train_loader\n",
    "for images, labels in data_loader.train_loader:\n",
    "    images = images.view(images.size(0), 1, 28, 28)\n",
    "    latent_space1 = model1.getLatenSpace(images)\n",
    "    latent_space2 = model2.getLatenSpace(images)\n",
    "    latent_spaces1.append(latent_space1.cpu().detach().numpy())\n",
    "    latent_spaces2.append(latent_space2.cpu().detach().numpy())\n",
    "    all_labels.append(labels.numpy())\n",
    "\n",
    "# Concatenate latent space representations from all batches\n",
    "latent_space1 = np.concatenate(latent_spaces1, axis=0)\n",
    "latent_space2 = np.concatenate(latent_spaces2, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "\n",
    "print(latent_space.shape)\n",
    "print(all_labels.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Plot latent space via PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "\n",
    "latent_space_pca = pca.fit_transform(latent_space)\n",
    "\n",
    "# Plot the latent space\n",
    "plot = plt.scatter(latent_space_pca[:, 0], latent_space_pca[:, 1], c=all_labels, cmap='tab10', label=all_labels)\n",
    "plt.show(plot)\n",
    "\n",
    "# Transform the latent space\n",
    "latent_space_transformed = np.dot(latent_space, A.T)\n",
    "# Plot latent space via PCA\n",
    "pca = PCA(n_components=2)\n",
    "latent_space_pca = pca.fit_transform(latent_space_transformed)\n",
    "\n",
    "# Plot the latent space\n",
    "plot = plt.scatter(latent_space_pca[:, 0], latent_space_pca[:, 1], c=all_labels, cmap='tab10', label=all_labels)\n",
    "plt.show(plot)\n",
    "\n",
    "\n",
    "# Plot the second latent space\n",
    "latent_space_pca2 = pca.fit_transform(latent_space2)\n",
    "\n",
    "pca_second = PCA(n_components=2)\n",
    "plot_second = plt.scatter(latent_space_pca2[:, 0], latent_space_pca2[:, 1], c=all_labels, cmap='tab10', label=all_labels)\n",
    "plt.show(plot_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
