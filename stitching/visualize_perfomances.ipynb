{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_class = pd.read_csv(\"results_class.csv\")\n","results = pd.read_csv(\"results.csv\")\n","results_top = pd.read_csv(\"results_top.csv\")\n","\n","\n","results_top.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plotting\n","plt.figure(figsize=(14, 10))\n","\n","# Plot MSE_loss vs. lambda\n","plt.subplot(2, 2, 1)\n","sns.lineplot(data=results, x='lambda', y='MSE_loss', marker='o')\n","plt.title('MSE Loss vs. Lambda')\n","plt.xlabel('Lambda')\n","plt.ylabel('MSE Loss')\n","\n","# Plot MSE_loss vs. num_samples\n","plt.subplot(2, 2, 2)\n","sns.lineplot(data=results, x='num_samples', y='MSE_loss', marker='o')\n","plt.title('MSE Loss vs. Number of Samples')\n","plt.xlabel('Number of Samples')\n","plt.ylabel('MSE Loss')\n","\n","# Plot MSE_loss vs. mapping (as a categorical variable)\n","plt.subplot(2, 2, 3)\n","sns.boxplot(data=results, x='mapping', y='MSE_loss')\n","plt.title('MSE Loss vs. Mapping')\n","plt.xlabel('Mapping')\n","plt.ylabel('MSE Loss')\n","\n","# Plot MSE_loss vs. latent dimension\n","plt.subplot(2, 2, 4)\n","# Change opacity of the boxplot\n","temp_res = results.copy()\n","\n","# Function to safely extract the third part\n","def extract_third_part(s):\n","    parts = s.split('_')\n","    print(parts)\n","    if len(parts) >= 3:\n","        return parts[2]\n","    else:\n","        return None  # Or any default value you prefer\n","\n","temp_res['latent_dim'] = temp_res['model2'].apply(extract_third_part)\n","\n","\n","sns.lineplot(data=temp_res, x='latent_dim', y='MSE_loss_model2')\n","\n","plt.title('MSE Loss of Model2 and Model1')\n","plt.xlabel('Model')\n","plt.ylabel('MSE Loss')\n","\n","\n","# Show all plots\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use different colors for each class blue\n","\n","#sns.set_palette(sns.color_palette(\"tab10\"))\n","\n","# Plot MSE_loss per class vs. lambda\n","plt.figure(figsize=(14, 10))\n","plt.subplot(2, 2, 1)\n","sns.lineplot(data=results_class, x='lambda', y='MSE_loss', marker='o', hue='class', err_style='bars')\n","# Make Variance of the lineplot not visible\n","\n","\n","plt.title('MSE Loss per Class vs. Lambda')\n","plt.xlabel('Lambda')\n","plt.ylabel('MSE Loss')\n","\n","# Plot MSE_loss per class vs. num_samples\n","plt.subplot(2, 2, 2)\n","sns.lineplot(data=results_class, x='num_samples', y='MSE_loss', marker='o', hue='class', err_style='bars')\n","plt.title('MSE Loss per Class vs. Number of Samples')\n","plt.xlabel('Number of Samples')\n","plt.ylabel('MSE Loss')\n","\n","# Plot MSE_loss per class vs. mapping\n","plt.subplot(2, 2, 3)\n","sns.boxplot(data=results_class, x='mapping', y='MSE_loss', hue='class')\n","plt.title('MSE Loss per Class vs. Mapping')\n","plt.xlabel('Mapping')\n","plt.ylabel('MSE Loss')\n","\n","# Plot class outliers for each class \n","plt.subplot(2, 2, 4)\n","sns.barplot(data=results_class, x='class', y='MSE_loss_model2', color='purple', alpha=0.5)\n","sns.barplot(data=results_class, x='class', y='MSE_loss_model1', color='orange', fill=None, linewidth=2)\n","\n","plt.title('MSE Loss per Class for Model2 and Model1')\n","plt.xlabel('Class')\n","plt.ylabel('MSE Loss')\n","\n","\n","# Show all plots\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["################################################\n","filter = {\n","    \"model1\": \"models/checkpoints/PCKTAE/FMNIST/FMNIST_PCKTAE_10_2.pth\",\n","    \"model2\": \"models/checkpoints/PCKTAE/FMNIST/FMNIST_PCKTAE_10_1.pth\",\n","    \"mapping\": \"Linear\",\n","    \"lambda\": 0.01,\n","    \"num_samples\": 100,\n","    \"dataset\": \"FMNIST\"\n","}\n","################################################\n","\n","print(results_top.describe())\n","\n","# Get results top for the filter\n","results_top_filtered = results_top[(results_top[\"model1\"] == filter[\"model1\"]) & (results_top[\"model2\"] == filter[\"model2\"]) & (results_top[\"mapping\"] == filter[\"mapping\"]) & (results_top[\"lambda\"] == filter[\"lambda\"]) & (results_top[\"num_samples\"] == filter[\"num_samples\"]) & (results_top[\"dataset\"] == filter[\"dataset\"])]\n","\n","# Add a new column for the x-axis index\n","results_top_filtered = results_top_filtered.reset_index(drop=True)\n","results_top_filtered['index'] = results_top_filtered.index + 1\n","\n","print(results_top_filtered)\n","# Random indices for sampling\n","np.random.seed(42)  # For reproducibility\n","random_indices = np.random.choice(results_top_filtered.index, 100, replace=False)\n","\n","# Take only the random indices\n","results_top_filtered_sampled = results_top_filtered.loc[random_indices]\n","\n","# Plot the reconstruction error \n","plt.figure(figsize=(14, 10))\n","\n","plt.subplot(2, 2, 1)\n","# Use as x the index of the datapoints\n","sns.lineplot(data=results_top_filtered_sampled, x='index', y='reconstruction_error_model1', marker='o', color='blue', label='Model 1')\n","sns.lineplot(data=results_top_filtered_sampled, x='index', y='reconstruction_error_stitched', marker='s', color='green', label='Stitched')\n","plt.title('Reconstruction per Sample Stitched vs. Model 1')\n","plt.xlabel('Samples')\n","plt.ylabel('Reconstruction Error')\n","plt.legend()\n","\n","plt.subplot(2, 2, 2)\n","# Use as x the index of the datapoints\n","sns.lineplot(data=results_top_filtered_sampled, x='index', y='reconstruction_error_model2', marker='o', color='orange', label='Model 2')\n","sns.lineplot(data=results_top_filtered_sampled, x='index', y='reconstruction_error_stitched', marker='s', color='green', label='Stitched')\n","plt.title('Reconstruction per Sample Stitched vs. Model 1')\n","plt.xlabel('Samples')\n","plt.ylabel('Reconstruction Error')\n","plt.legend()\n","\n","# Get indices of the top 5% of each model\n","top_indices_model1 = results_top_filtered_sampled[results_top_filtered_sampled[\"model1_top\"] == True]\n","top_indices_model2 = results_top_filtered_sampled[results_top_filtered_sampled[\"model2_top\"] == True]\n","top_indices_stitched = results_top_filtered_sampled[results_top_filtered_sampled[\"stitched_top\"] == True]\n","\n","# Convert the indices to numpy arrays\n","top_indices_model1_array = top_indices_model1.index.to_numpy()\n","top_indices_model2_array = top_indices_model2.index.to_numpy()\n","top_indices_stitched_array = top_indices_stitched.index.to_numpy()\n","\n","# Intersection of all the top indices that are in the top 5% of all models\n","intersection_top = np.intersect1d(top_indices_model1_array, top_indices_stitched_array)\n","intersection_top_mod2 = np.intersect1d(top_indices_model2_array, top_indices_model2_array)\n","\n","# Add color column to DataFrame\n","results_top_filtered['color_model1'] = 'blue'\n","results_top_filtered.loc[intersection_top, 'color_model1'] = 'red'\n","results_top_filtered['color_model2'] = 'blue'\n","results_top_filtered.loc[intersection_top_mod2, 'color_model2'] = 'red'\n","\n","\n","\n","plt.subplot(2, 2, 3)\n","# Use as x the index of the datapoints\n","sns.scatterplot(data=results_top_filtered.loc[top_indices_model1_array], x='index', y='reconstruction_error_model1', hue='color_model1', palette={'blue': 'blue', 'red': 'red'}, legend=False)\n","sns.scatterplot(data=results_top_filtered.loc[top_indices_stitched_array], x='index', y='reconstruction_error_stitched', marker='x', color='green', legend=False)\n","plt.title('Reconstruction per Sample for Top 5% Model 1 and Stitched')\n","plt.xlabel('Samples')\n","plt.ylabel('Reconstruction Error')\n","\n","plt.subplot(2, 2, 4)\n","# Use as x the index of the datapoints\n","sns.scatterplot(data=results_top_filtered.loc[top_indices_model2_array], x='index', y='reconstruction_error_model2', hue='color_model2', palette={'blue': 'blue', 'red': 'red'}, legend=False)\n","sns.scatterplot(data=results_top_filtered.loc[top_indices_stitched_array], x='index', y='reconstruction_error_stitched', marker='x', color='green', legend=False)\n","plt.title('Reconstruction per Sample for Top 5% Model 2 and Stitched')\n","plt.xlabel('Samples')\n","plt.ylabel('Reconstruction Error')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the influence on the latent space \n","results_top_filtered_sampled = results_top_filtered_sampled\n","\n","\n","# Plot the reconstruction error \n","plt.figure(figsize=(14, 10))\n","\n","plt.subplot(2, 2, 1)\n","# Use as x the index of the datapoints\n","sns.lineplot(data=results_top_filtered_sampled, x='latent_diff_original', y='reconstruction_error_stitched', marker='o', color='blue')\n","#sns.lineplot(data=results_top_filtered_sampled, x='index', y='reconstruction_error_stitched', marker='s', color='green', label='Stitched')\n","plt.title('Latentrepresentation')\n","plt.xlabel('Latent difference between x1 and x2')\n","plt.ylabel('Reconstruction Error')\n","plt.legend()\n","\n","plt.subplot(2, 2, 2)\n","# Use as x the index of the datapoints\n","sns.lineplot(data=results_top_filtered_sampled, x='latent_diff_mod1', y='reconstruction_error_stitched', marker='o', color='blue')\n","#sns.lineplot(data=results_top_filtered_sampled, x='index', y='reconstruction_error_stitched', marker='s', color='green', label='Stitched')\n","plt.title('Latentdifference vs. Reconstruction Error')\n","plt.xlabel('Latent difference between x1 and transformed x1')\n","plt.ylabel('Reconstruction Error')\n","plt.legend()\n","\n","# \n","plt.subplot(2, 2, 3)\n","# Use as x the index of the datapoints\n","sns.lineplot(data=results_top_filtered_sampled, x='latent_diff_mod2', y='reconstruction_error_stitched', marker='o', color='blue')\n","#sns.lineplot(data=results_top_filtered_sampled, x='index', y='reconstruction_error_stitched', marker='s', color='green', label='Stitched')\n","plt.title('Latentdifference vs. Reconstruction Error')\n","plt.xlabel('Latent difference between x2 and transformed x1')\n","plt.ylabel('Reconstruction Error')\n","plt.legend()\n","\n","\n","# Reconstruction error for the worse 5% of the model\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_top = pd.read_csv(\"results_top.csv\")\n","\n","plt.figure(figsize=(14, 10))\n","\n","plt.subplot(2, 2, 1)\n","plt.title('MSE Loss per Class vs. num samples, convex hull sampling strategy')\n","plt.xlabel('num_samples')\n","plt.ylabel('MSE Loss')\n","sns.lineplot(data=results_class[results_class['sampling_strategy'] == 'equally'], x='num_samples', y='MSE_loss', marker='o', hue='class', err_style='bars')\n","\n","# Plot MSE_loss per class vs. num_samples\n","plt.subplot(2, 2, 2)\n","plt.title('MSE Loss per Class vs. num samples, equal sampling strategy')\n","plt.xlabel('num_samples')\n","plt.ylabel('MSE Loss')\n","sns.lineplot(data=results_class[results_class['sampling_strategy'] == 'convex_hull'], x='num_samples', y='MSE_loss', marker='o', hue='class', err_style='bars')\n","\n","plt.subplot(2, 2, 3)\n","plt.title('MSE Loss per Class vs. num samples, worst classes sampling strategy')\n","plt.xlabel('num_samples')\n","plt.ylabel('MSE Loss')\n","sns.lineplot(data=results_class[results_class['sampling_strategy'] == 'worst_classes'], x='num_samples', y='MSE_loss', marker='o', hue='class', err_style='bars')\n","\n","plt.subplot(2, 2, 4)\n","plt.title('MSE Loss per Class vs. num samples, outliers sampling strategy')\n","plt.xlabel('num_samples')\n","plt.ylabel('MSE Loss')\n","sns.lineplot(data=results_class[results_class['sampling_strategy'] == 'outliers'], x='num_samples', y='MSE_loss', marker='o', hue='class', err_style='bars')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from scipy.stats import norm\n","\n","# Load the data\n","error_distribution = pd.read_csv(\"error_distribution.csv\")\n","error_distribution['class'] = error_distribution['class'].astype(int)\n","\n","# Calculate the mean of the means and variances\n","absolute_variance = error_distribution['variance'].mean()\n","absolute_mean = error_distribution['mean'].mean()\n","\n","# Generate points for plotting\n","points = np.linspace(absolute_mean - 3 * np.sqrt(absolute_variance), \n","                     absolute_mean + 3 * np.sqrt(absolute_variance), 100)\n","\n","# Define function to get y-values for the normal distribution based on each row\n","def get_points_y(row):\n","    mean = row['mean']\n","    variance = row['variance']\n","    return norm.pdf(points, mean, np.sqrt(variance))\n","\n","# Apply the function to each row to get the distribution\n","error_distribution['distribution'] = error_distribution.apply(get_points_y, axis=1)\n","\n","# Prepare data for plotting\n","plot_data = pd.DataFrame()\n","for idx, row in error_distribution.iterrows():\n","    temp_df = pd.DataFrame({\n","        'x': points,\n","        'y': row['distribution'],\n","        'class': row['class']\n","    })\n","    plot_data = pd.concat([plot_data, temp_df], ignore_index=True)\n","\n","# Plot using Seaborn\n","plt.figure(figsize=(14, 10))\n","plt.title('Loss distribution per class, over all models')\n","plt.xlabel('Mse Loss')\n","plt.ylabel('Frequency')\n","\n","num_classes = len(error_distribution['class'].unique())\n","palette = sns.color_palette(\"husl\", num_classes)\n","\n","sns.lineplot(data=plot_data, x='x', y='y', hue='class', palette=palette)\n","\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO3lmY1oGLw3QSQdXXMxAnA","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
