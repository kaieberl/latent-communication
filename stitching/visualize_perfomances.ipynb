{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4983,"status":"ok","timestamp":1718635171770,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"},"user_tz":-120},"id":"K1cJ-c9gGw5K","outputId":"fd440935-905d-4c2c-d079-556faeba8e36"},"outputs":[],"source":["\"\"\"\n","#Amount google drive\n","from google.colab import drive\n","import os\n","\n","gdrive_path='/content/gdrive/MyDrive/case_study_opti/latent-communication'\n","\n","# This will mount your google drive under 'MyDrive'\n","drive.mount('/content/gdrive', force_remount=True)\n","# In order to access the files in this notebook we have to navigate to the correct folder\n","os.chdir(gdrive_path)\n","# Check manually if all files are present\n","# LMU is not a rwal university <3\n","print(sorted(os.listdir()))\n","\n","#!pip install lightning\n","#!pip install omegaconf\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1718635187694,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"},"user_tz":-120},"id":"UKlbMVGEG56s"},"outputs":[],"source":["from pathlib import Path\n","import torch.nn as nn\n","import os\n","import itertools\n","import torch\n","import numpy as np\n","from tqdm import tqdm\n","from torchvision.datasets import MNIST\n","from torchvision.transforms import transforms\n","from sklearn.decomposition import PCA\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","import logging\n","\n","from skimage.metrics import structural_similarity as ssim\n","from skimage.metrics import peak_signal_noise_ratio as psnr\n","\n","from utils.dataloaders.full_dataloaders import DataLoaderMNIST, DataLoaderFashionMNIST, DataLoaderCIFAR10, DataLoaderCIFAR100\n","from utils.visualization import (\n","    visualize_mapping_error,\n","    visualize_latent_space_pca,\n","    plot_latent_space,\n","    highlight_cluster,\n",")\n","from utils.model import load_model, get_transformations\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n","\n","class Config:\n","    def __init__(self, **entries):\n","        self.__dict__.update(entries)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":520,"status":"ok","timestamp":1718628680802,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"},"user_tz":-120},"id":"KHSotjQGHYRL"},"outputs":[],"source":["def clear_memory():\n","    torch.cuda.empty_cache()\n","\n","def define_dataloader(name_dataset, name_model, use_test_set=False, seed=0):\n","    augumentation = get_transformations(name_model)\n","    if name_dataset.lower() == \"mnist\":\n","        dataloader = DataLoaderMNIST(transformation=augumentation, batch_size=64, seed=int(seed))\n","    if name_dataset.lower() == \"fmnist\":\n","        dataloader = DataLoaderFashionMNIST(transformation=augumentation,batch_size=64, seed=int(seed))\n","    if name_dataset.lower() == \"cifar10\":\n","        dataloader = DataLoaderCIFAR10(transformation=augumentation,batch_size=64, seed=int(seed))\n","    if name_dataset.lower() == \"cifar100\":\n","        dataloader = DataLoaderCIFAR100(transformation=augumentation,batch_size=64, seed=int(seed))\n","    if use_test_set:\n","        full_dataset_images, full_dataset_labels = dataloader.get_full_test_dataset()\n","    else:\n","        full_dataset_images, full_dataset_labels = dataloader.get_full_train_dataset()\n","    return full_dataset_images, full_dataset_labels, len(np.unique(full_dataset_labels.numpy()))\n","\n","def load_mapping(path,mapping):\n","    if mapping.lower() == 'linear':\n","        from optimization.optimizer import LinearFitting\n","        mapping = LinearFitting.from_file(path)\n","    elif mapping.lower() == 'affine':\n","        from optimization.optimizer import AffineFitting\n","        mapping = AffineFitting.from_file(path)\n","    elif mapping.lower() == 'neuralnetwork':\n","        from optimization.optimizer import NeuralNetworkFitting\n","        mapping = NeuralNetworkFitting.from_file(path)\n","    else:\n","        raise ValueError(\"Invalid experiment name\")\n","    return mapping"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"executionInfo":{"elapsed":44066,"status":"error","timestamp":1718635603838,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"},"user_tz":-120},"id":"8xjVNZ4BHwEl","outputId":"298dc0e6-a90a-44f3-9400-c5640d8d9e2a"},"outputs":[],"source":["##############################################\n","#Specify here which files you want to use\n","#Sorry but this fucking thing of the path is ALWAYS broken for me unless I do this. REMOVE when you run this notebook\n","os.chdir(\"/Users/federicoferoggio/Documents/vs_code/latent-communication\")\n","\n","#changed the processing of the file: It reads all the transomrations available given cerain filters. It should be possible to pass a single file.\n","directory_to_explore = 'results/transformations/mapping_files/PCKTAE'\n","results_list = os.listdir(directory_to_explore)\n","filters =  ['FMNIST']\n","results_dataframe  = []\n","results_dataframe_by_classes = []\n","###############################################\n","##Sort the result list\n","results_list = sorted(results_list)\n","## Parameters of the iteraction before to avoid repeated loading\n","data_info_1_old, data_info_2_old, name_dataset1_old, name_dataset2_old = None, None, None, None\n","criterion = nn.MSELoss()\n","for file in tqdm(results_list):\n","    file = file[:-4]\n","    for filter in filters:\n","        if filter.lower() in file.lower():\n","            data_info_1, data_info_2, trans_info = file.split(\">\")\n","            \n","            if name_dataset1_old != data_info_1.split(\"_\")[0]:\n","                name_dataset1, name_model1, size_of_the_latent1, seed1 = data_info_1.split(\"_\")\n","                images, labels, n_classes = define_dataloader(name_dataset1, name_model1, seed=seed1, use_test_set=True)\n","                images = images.to(DEVICE).float()  # Ensure float32\n","                labels = labels.to(DEVICE)\n","\n","            if data_info_1_old != data_info_1:\n","                name_dataset1, name_model1, size_of_the_latent1, seed1 = data_info_1.split(\"_\")\n","                file1 = f'models/checkpoints/{name_model1}/{name_dataset1}/{name_dataset1}_{name_model1}_{size_of_the_latent1}_{seed1}.pth'\n","                model1 = load_model(model_name=name_model1, name_dataset=name_dataset1, latent_size=size_of_the_latent1, seed=seed1, model_path=file1).to(DEVICE)\n","                latent_left = model1.get_latent_space(images).detach().cpu().numpy().astype('float32')  # Ensure float32\n","                \n","            if data_info_2_old != data_info_2:\n","                name_dataset2, name_model2, size_of_the_latent2, seed2 = data_info_2.split(\"_\")\n","                file2 = f'models/checkpoints/{name_model2}/{name_dataset2}/{name_dataset2}_{name_model2}_{size_of_the_latent2}_{seed2}.pth'\n","                model2 = load_model(model_name=name_model2, name_dataset=name_dataset2, latent_size=size_of_the_latent2, seed=seed2, model_path=file2).to(DEVICE)\n","                latent_right = model2.get_latent_space(images).to(DEVICE).float()  # Ensure float32\n","                \n","            list_info_trans = trans_info.split(\"_\")\n","            mapping_name, num_samples, lamda_t = list_info_trans.pop(0), list_info_trans.pop(0), list_info_trans.pop(0)\n","            sampling_strategy = \"_\".join(list_info_trans)\n","            mapping = load_mapping(directory_to_explore + \"/\" + file, mapping_name)\n","            transformed_latent_space = torch.tensor(mapping.transform(latent_left), dtype=torch.float32).to(DEVICE)  # Ensure float32\n","            \n","            decoded = model2.decode(latent_right).to(DEVICE).float()  # Ensure float32\n","            decoded_transformed = model2.decode(transformed_latent_space).to(DEVICE).float()  # Ensure float32\n","            \n","            mse_loss = criterion(decoded, images).item()\n","            mse_loss_transformed = criterion(decoded_transformed, images).item()\n","            \n","            results_dataframe.append({\n","                \"dataset\": name_dataset1,\n","                \"model1\": file1,\n","                \"model2\": file2,\n","                \"mapping\": mapping_name,\n","                \"lambda\": lamda_t,\n","                \"num_samples\": num_samples,\n","                \"sampling_strategy\": sampling_strategy,\n","                \"MSE_loss\": mse_loss,\n","                \"MSE_loss_transformed\": mse_loss_transformed,\n","                \"class\": \"all\"\n","            })\n","            \n","            for i in range(n_classes):\n","                mask = labels == i\n","                mse_loss = criterion(decoded_transformed[mask], images[mask]).item()\n","                results_dataframe_by_classes.append({\n","                    \"dataset\": name_dataset1,\n","                    \"model1\": file1,\n","                    \"model2\": file2,\n","                    \"mapping\": mapping_name,\n","                    \"lambda\": lamda_t,\n","                    \"num_samples\": num_samples,\n","                    \"sampling_strategy\": sampling_strategy,\n","                    \"MSE_loss\": mse_loss,\n","                    \"class\": i\n","                })\n","\n","results = pd.DataFrame(results_dataframe)\n","results_by_classes = pd.DataFrame(results_dataframe_by_classes)\n","\n","# Save results\n","path_result = \"results_optimization.csv\"\n","results.to_csv(path_result, index=False)\n","path_result = \"results_optimization_by_classes.csv\"\n","results_by_classes.to_csv(path_result, index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":300,"status":"ok","timestamp":1718635270274,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"},"user_tz":-120},"id":"j1yQLvckpQI0","outputId":"8211eb63-26e9-4cc0-96df-b361e3d8b237"},"outputs":[],"source":["results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":948},"executionInfo":{"elapsed":1295,"status":"ok","timestamp":1718635165465,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"},"user_tz":-120},"id":"DGO7DruBV_si","outputId":"fdf98d8c-ea8f-45d2-d95b-e1f20b9b23d1"},"outputs":[],"source":["# Plotting\n","plt.figure(figsize=(14, 10))\n","\n","# Plot MSE_loss vs. lambda\n","plt.subplot(2, 2, 1)\n","sns.lineplot(data=results, x='lambda', y='MSE_loss', marker='o')\n","plt.title('MSE Loss vs. Lambda')\n","plt.xlabel('Lambda')\n","plt.ylabel('MSE Loss')\n","\n","# Plot MSE_loss vs. num_samples\n","plt.subplot(2, 2, 2)\n","sns.lineplot(data=results, x='num_samples', y='MSE_loss', marker='o')\n","plt.title('MSE Loss vs. Number of Samples')\n","plt.xlabel('Number of Samples')\n","plt.ylabel('MSE Loss')\n","\n","# Plot MSE_loss vs. mapping (as a categorical variable)\n","plt.subplot(2, 2, 3)\n","sns.boxplot(data=results, x='mapping', y='MSE_loss')\n","plt.title('MSE Loss vs. Mapping')\n","plt.xlabel('Mapping')\n","plt.ylabel('MSE Loss')\n","\n","# Show all plots\n","plt.tight_layout()\n","plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO3lmY1oGLw3QSQdXXMxAnA","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
