{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/mariotuci/Desktop/Latent-Communication/latent-communication/models/training_models/PCKTAE_without_all_classes.ipynb Zelle 1\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mariotuci/Desktop/Latent-Communication/latent-communication/models/training_models/PCKTAE_without_all_classes.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets, transforms\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mariotuci/Desktop/Latent-Communication/latent-communication/models/training_models/PCKTAE_without_all_classes.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader, Subset\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mariotuci/Desktop/Latent-Communication/latent-communication/models/training_models/PCKTAE_without_all_classes.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataloaders\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfull_dataloaders\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoaderMNIST, DataLoaderCIFAR10, DataLoaderCIFAR100, DataLoaderFashionMNIST\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mariotuci/Desktop/Latent-Communication/latent-communication/models/training_models/PCKTAE_without_all_classes.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdefinitions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mPCKTAE\u001b[39;00m \u001b[39mimport\u001b[39;00m PocketAutoencoder\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mariotuci/Desktop/Latent-Communication/latent-communication/models/training_models/PCKTAE_without_all_classes.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from utils.dataloaders.full_dataloaders import DataLoaderMNIST, DataLoaderCIFAR10, DataLoaderCIFAR100, DataLoaderFashionMNIST\n",
    "from models.definitions.PCKTAE import PocketAutoencoder\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.getLogger('torchvision.datasets').setLevel(logging.ERROR)\n",
    "os.chdir('../../')\n",
    "\n",
    "\n",
    "# Initialize DataFrame with additional columns\n",
    "loss_dataset = pd.DataFrame(columns=['Dataset', 'Model','Latent Size', 'Seed', 'Loss'])\n",
    "\n",
    "# Define the lists\n",
    "dataset = 'FMNIST'\n",
    "size_input = 28\n",
    "channels_input = 1\n",
    "seeds = [1, 2, 3]\n",
    "epochs = [20]\n",
    "batch_sizes = [128]\n",
    "learning_rates = [0.005]\n",
    "latent_sizes = [10, 30, 50]\n",
    "\n",
    "# Create combinations for MNIST and CIFAR datasets separately\n",
    "combinations1 = [seeds, epochs, batch_sizes, learning_rates, latent_sizes[:3]]\n",
    "combinations1 = list(itertools.product(*combinations1))\n",
    "\n",
    "# Combine both sets of combinations\n",
    "combinations = combinations1 \n",
    "\n",
    "# Print the combinations and their count\n",
    "print(combinations, len(combinations))\n",
    "\n",
    "# Example of setting device and augmentations (adjust according to your actual use case)\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "for combo in tqdm(combinations):\n",
    "    seed, epoch, batch_size, learning_rate, latent_size = combo\n",
    "    print(f\"Dataset: {dataset}, Channels input: {channels_input}, Epochs: {epoch}, Batch size: {batch_size}, Learning rate: {learning_rate}, Latent size: {latent_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the datloader with specific labels\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download and load the dataset\n",
    "trainset = datasets.FashionMNIST(root=os.getcwd()+'/data/', download=True, train=True, transform=transform)\n",
    "testset = datasets.FashionMNIST(root=os.getcwd()+'/data/', download=True, train=False, transform=transform)\n",
    "\n",
    "# Specify the labels you want to keep\n",
    "specific_labels = [0, 1, 2, 3,4]\n",
    "labels_string = '_'.join(map(str, specific_labels))\n",
    "\n",
    "def filter_by_label(dataset, labels):\n",
    "    indices = [i for i, label in enumerate(dataset.targets) if label in labels]\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "# Filter the datasets\n",
    "trainset_filtered = filter_by_label(trainset, specific_labels)\n",
    "testset_filtered = filter_by_label(testset, specific_labels)\n",
    "\n",
    "# Create DataLoaders\n",
    "trainloader_filtered = DataLoader(trainset_filtered, batch_size=64, shuffle=True)\n",
    "testloader_filtered = DataLoader(testset_filtered, batch_size=64, shuffle=True)\n",
    "path_model = f'models/checkpoints/SMALLAE_not_all_classes/FMNIST/classes{labels_string}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0_1_2_3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.0004904168944156516:   0%|          | 0/9 [04:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m overall_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()  \u001b[38;5;66;03m# Set the model to training mode\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrainloader_filtered\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/opti/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/opti/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/opti/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/opti/lib/python3.12/site-packages/torch/utils/data/dataset.py:399\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/miniconda3/envs/opti/lib/python3.12/site-packages/torchvision/datasets/mnist.py:142\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    138\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index])\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m~/miniconda3/envs/opti/lib/python3.12/site-packages/PIL/Image.py:3154\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3151\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3152\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mtostring()\n\u001b[0;32m-> 3154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrombuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/opti/lib/python3.12/site-packages/PIL/Image.py:3060\u001b[0m, in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   3058\u001b[0m     args \u001b[38;5;241m=\u001b[39m mode, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   3059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m _MAPMODES:\n\u001b[0;32m-> 3060\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mnew\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3061\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39m_new(core\u001b[38;5;241m.\u001b[39mmap_buffer(data, size, decoder_name, \u001b[38;5;241m0\u001b[39m, args))\n\u001b[1;32m   3062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/opti/lib/python3.12/site-packages/PIL/Image.py:2974\u001b[0m, in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   2972\u001b[0m     im\u001b[38;5;241m.\u001b[39mpalette \u001b[38;5;241m=\u001b[39m ImagePalette\u001b[38;5;241m.\u001b[39mImagePalette()\n\u001b[1;32m   2973\u001b[0m     color \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mgetcolor(color)\n\u001b[0;32m-> 2974\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m im\u001b[38;5;241m.\u001b[39m_new(\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iterations_ = tqdm(combinations)\n",
    "for seed, num_epochs, batch_size, learning_rate, latent_dim in iterations_:\n",
    "    \n",
    "    config = {\n",
    "        'model_name': 'PCKTAE',\n",
    "        'dataset': dataset,\n",
    "        'weight_var': 1,\n",
    "        'weight_mean': 0,\n",
    "        'seed': seed,\n",
    "        'batch_size': batch_size,\n",
    "        'num_epochs': num_epochs,\n",
    "        'learning_rate': learning_rate,\n",
    "        'path': path_model\n",
    "    }\n",
    "    \n",
    "    torch.manual_seed(config['seed'])\n",
    "    model = PocketAutoencoder(hidden_dim=latent_dim, n_input_channels=channels_input, input_size=size_input)\n",
    "    model.to(DEVICE)\n",
    "    optimizer = Adam(model.parameters(), lr=config['learning_rate'], weight_decay=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        overall_loss = 0\n",
    "        model.train()  # Set the model to training mode\n",
    "        \n",
    "        for batch_idx, (x, _) in enumerate(trainloader_filtered):\n",
    "            x = x.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            loss = model.training_step(x)\n",
    "            overall_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        avg_loss = overall_loss / (len(trainloader_filtered) * batch_size)\n",
    "        new_row = pd.DataFrame({'Dataset': [config['dataset']],\n",
    "                                'Model': [config['model_name']],\n",
    "                                'Seed': [config['seed']],\n",
    "                                'Latent Size': [latent_dim],\n",
    "                                'Loss': [avg_loss]})\n",
    "        loss_dataset = pd.concat([loss_dataset, new_row], ignore_index=True)\n",
    "        iterations_.set_description(f\"Epoch: {epoch}, Loss: {avg_loss}\")\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        test_loss = 0\n",
    "        for x_test, _ in testloader_filtered:\n",
    "            x_test = x_test.to(DEVICE)\n",
    "            test_loss += model.validation_step(x_test).item()\n",
    "        \n",
    "        avg_test_loss = test_loss / (len(testloader_filtered) * batch_size)\n",
    "        scheduler.step(avg_test_loss)  # Update the learning rate based on the test loss\n",
    "        new_row = pd.DataFrame({'Dataset': [config['dataset']],\n",
    "                                'Model': [config['model_name']],\n",
    "                                'Seed': [config['seed']],\n",
    "                                'Latent Size': [latent_dim],\n",
    "                                'Loss': [avg_test_loss]})\n",
    "        loss_dataset = pd.concat([loss_dataset, new_row], ignore_index=True)\n",
    "        iterations_.set_description(f\"Test Loss: {avg_test_loss}\")    \n",
    "    \n",
    "    # Save the model\n",
    "    name = f\"{config['dataset']}_{config['model_name']}_{latent_dim}_{config['seed']}.pth\"\n",
    "    print(name)\n",
    "    path = config['path'] + name\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "loss_dataset.to_csv(f'models/checkpoints/SMALLAE_classes/lossesFMNIST.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".zeroshot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
