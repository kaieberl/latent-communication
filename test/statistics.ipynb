{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mariotuci/Documents/latent-communication\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "import re\n",
    "\n",
    "PROJECT_ROOT_DIR = \"latent-communication\"\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Find the project root by walking up the directory tree\n",
    "while current_dir:\n",
    "    if os.path.basename(current_dir) == PROJECT_ROOT_DIR:\n",
    "        break  # Found the project root!\n",
    "    current_dir = os.path.dirname(current_dir)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Project root '{PROJECT_ROOT_DIR}' not found in the directory tree.\")\n",
    "\n",
    "os.chdir(current_dir)\n",
    "# Add the project root and any necessary subdirectories to sys.path\n",
    "sys.path.insert(0, current_dir) \n",
    "sys.path.insert(0, os.path.join(current_dir, \"utils\"))  # Add the utils directory if needed\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "\n",
    "import itertools\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import logging\n",
    "from optimization.fit_mapping import create_mapping\n",
    "from utils.sampler import *\n",
    "from optimization.optimizer import AffineFitting, ScalingFitting\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "from utils.dataloaders.full_dataloaders import DataLoaderMNIST, DataLoaderFashionMNIST, DataLoaderCIFAR10, DataLoaderCIFAR100\n",
    "from utils.visualization import (\n",
    "    visualize_mapping_error,\n",
    "    visualize_latent_space,\n",
    "    plot_latent_space,\n",
    "    highlight_cluster,\n",
    ")\n",
    "from utils.model import load_model, get_transformations\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def define_dataloader(file, file2, use_test_set=False):\n",
    "    if file.strip(\"_\")[0] != file2.strip(\"_\")[0]:\n",
    "        logging.error(\"The datasets are different\")\n",
    "    # Define the dataloaders\n",
    "    name_dataset, name_model, size_of_the_latent, seed = file.strip(\".pth\").split(\"_\")\n",
    "    augumentation = get_transformations(name_model)\n",
    "    if name_dataset.lower() == \"mnist\":\n",
    "        dataloader = DataLoaderMNIST(transformation=augumentation, batch_size=64, seed=int(seed))\n",
    "    if name_dataset.lower() == \"fmnist\":\n",
    "        dataloader = DataLoaderFashionMNIST(transformation=augumentation,batch_size=64, seed=int(seed))\n",
    "    if name_dataset.lower() == \"cifar10\":\n",
    "        dataloader = DataLoaderCIFAR10(transformation=augumentation,batch_size=64, seed=int(seed))\n",
    "    if name_dataset.lower() == \"cifar100\":\n",
    "        dataloader = DataLoaderCIFAR100(transformation=augumentation,batch_size=64, seed=int(seed))\n",
    "    if use_test_set:\n",
    "        full_dataset_images, full_dataset_labels = dataloader.get_full_test_dataset()\n",
    "    else:\n",
    "        full_dataset_images, full_dataset_labels = dataloader.get_full_train_dataset()\n",
    "    return full_dataset_images, full_dataset_labels, len(np.unique(full_dataset_labels.numpy()))\n",
    "\n",
    "def load_mapping(path,mapping):\n",
    "    if mapping == 'Linear':\n",
    "        from optimization.optimizer import LinearFitting\n",
    "        mapping = LinearFitting.from_file(path)\n",
    "    elif mapping == 'Affine':\n",
    "        from optimization.optimizer import AffineFitting\n",
    "        mapping = AffineFitting.from_file(path)\n",
    "    elif mapping == 'NeuralNetwork':\n",
    "        from optimization.optimizer import NeuralNetworkFitting\n",
    "        mapping = NeuralNetworkFitting.from_file(path)\n",
    "    elif mapping == 'Decouple':\n",
    "        from optimization.optimizer import DecoupleFitting\n",
    "        mapping = DecoupleFitting.from_file(path)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid experiment name\")\n",
    "    return mapping\n",
    "\n",
    "def get_same_mapping(files):\n",
    "    # Extract the seed (last number)\n",
    "    final_dict = {}\n",
    "    for file in files:\n",
    "        seed = re.findall(r'\\d+', files)[-1]\n",
    "\n",
    "        # Define the prefix (string before the last number and any extensions)\n",
    "        prefix = re.sub(r'_[\\d\\.]+\\.npy$', '', file)\n",
    "\n",
    "        # Create a dictionary with prefix as key and seed as value\n",
    "        information_dict = {\n",
    "            'seed': int(seed),\n",
    "            'mse': 0,\n",
    "        }\n",
    "        # Append the dictionary to the list\n",
    "\n",
    "        final_dict[prefix] = information_dict\n",
    "  \n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yh/rbd67mcj2zd4nychzgcydvt40000gn/T/ipykernel_33283/2682783819.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  decoded_transformed = model2.decode(torch.tensor(transformed_latent_space, dtype=torch.float32).to(images.device)).detach().cpu().numpy()\n",
      "100%|██████████| 6/6 [02:43<00:00, 27.29s/it]\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "#Specify here which files you want to use\n",
    "folder1 = \"models/checkpoints/VAE/FMNIST\"\n",
    "folder2 = \"models/checkpoints/VAE/FMNIST\"\n",
    "\n",
    "dataset=\"FMNIST\"\n",
    "number_samples = [50]\n",
    "mapping_list = [\"Linear\"]\n",
    "lamda_list = [0]\n",
    "sampling_strategy = \"equally\"\n",
    "filter = \"_16_\" #write here if you want that the processed files contain this string (example \"_50_\" to only process the files with latent size 50)\n",
    "###############################################\n",
    "## this autiomatically creates all the possible setups with the paramenters and the files you speicified, and sets up the correct dataset\n",
    "files1 = [f for f in os.listdir(folder1) if f.endswith(\".pth\") and filter in f]\n",
    "files2 = [f for f in os.listdir(folder2) if f.endswith(\".pth\") and filter in f]\n",
    "\n",
    "\n",
    "list_of_files = [(f1, f2) for f1, f2 in itertools.product(files1, files2) if f1 != f2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combinations_parameters = list(itertools.product(number_samples, mapping_list, lamda_list))\n",
    "pbar = tqdm(list(itertools.product(list_of_files, combinations_parameters)))\n",
    "images, labels, n_classes = define_dataloader(files1[0], files2[0], use_test_set=True)\n",
    "images = images.type(torch.float32)\n",
    "labels = labels.type(torch.float32)\n",
    "criterion = nn.MSELoss()\n",
    "# Result of all the combinations \n",
    "results = []\n",
    "criterion = nn.MSELoss()\n",
    "# Get for each class the corresponding indices \n",
    "class_indices = {i: np.where(labels.numpy() == i)[0] for i in range(n_classes)}\n",
    "# Get the corresponding class for each index\n",
    "indices_class = {i: labels.numpy()[i] for i in range(len(labels))}\n",
    "\n",
    "result_data = pd.DataFrame(columns=['reconstruction_error', 'reconstruction_error_model1', 'reconstruction_error_model2', 'name'])\n",
    "result_data_list = []\n",
    "\n",
    "for (file1, file2), (num_samples, mapping_name, lamda) in pbar:\n",
    "  name_dataset1, name_model1, size_of_the_latent1, seed1 = file1.strip(\".pth\").split(\"_\")\n",
    "  name_dataset2, name_model2, size_of_the_latent2, seed2 = file2.strip(\".pth\").split(\"_\")\n",
    "  #Load model\n",
    "  model1 = load_model(model_name=name_model1, name_dataset=name_dataset1, latent_size=int(size_of_the_latent1), seed=int(seed1), model_path = folder1 +\"/\"+ file1)\n",
    "  model2 = load_model(model_name=name_model2, name_dataset=name_dataset2, latent_size=int(size_of_the_latent2), seed=int(seed2), model_path = folder1 +\"/\"+ file2)\n",
    "\n",
    "  #Load mapping\n",
    "  for seed in range(1,20):\n",
    "\n",
    "    mapping_path = f'test/uncertain//{name_model2}/{file1.strip(\".pth\")}>{file2.strip(\".pth\")}>{mapping_name}_{num_samples}_{lamda}_{sampling_strategy}_{seed}'\n",
    "    mapping = load_mapping(mapping_path,mapping_name)\n",
    "    #Calculate latent spaces\n",
    "    latent_left = model1.get_latent_space(images).detach().cpu().numpy()\n",
    "    latent_right = model2.get_latent_space(images).detach().cpu().numpy()\n",
    "    transformed_latent_space = mapping.transform(latent_left)\n",
    "\n",
    "    #Model1 output\n",
    "    decoded_left = model1.decode(torch.tensor(latent_left, dtype=torch.float32).to(images.device)).detach().cpu().numpy()\n",
    "    # Model2 output\n",
    "    decoded_right = model2.decode(torch.tensor(latent_right, dtype=torch.float32).to(images.device)).detach().cpu().numpy()\n",
    "    #Get stitched output\n",
    "    decoded_transformed = model2.decode(torch.tensor(transformed_latent_space, dtype=torch.float32).to(images.device)).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "    mse_loss = criterion(torch.tensor(decoded_transformed),images).item()\n",
    "    # MSE loss for the model1 \n",
    "    mse_loss_model1 = criterion(torch.tensor(decoded_left),images).item()\n",
    "    # MSE loss for the model2\n",
    "    mse_loss_model2 = criterion(torch.tensor(decoded_right),images).item()\n",
    "\n",
    "    name = f'{name_model2}/{file1.strip(\".pth\")}>{file2.strip(\".pth\")}>{mapping_name}_{num_samples}_{lamda}_{sampling_strategy}'\n",
    "\n",
    "    # Add to pandas dataframe\n",
    "\n",
    "    result_data_list.append({\n",
    "      'reconstruction_error': mse_loss,\n",
    "      'reconstruction_error_model1': mse_loss_model1,\n",
    "      'reconstruction_error_model2': mse_loss_model2,\n",
    "      'name': name\n",
    "    })\n",
    "\n",
    "    result_data = pd.DataFrame(result_data_list)\n",
    "  \n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">reconstruction_error</th>\n",
       "      <th colspan=\"2\" halign=\"left\">reconstruction_error_model1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">reconstruction_error_model2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VAE/FMNIST_VAE_16_1&gt;FMNIST_VAE_16_2&gt;Linear_50_0_convex_hull</th>\n",
       "      <td>0.136787</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>0.079943</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.083600</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAE/FMNIST_VAE_16_1&gt;FMNIST_VAE_16_3&gt;Linear_50_0_convex_hull</th>\n",
       "      <td>0.156299</td>\n",
       "      <td>0.013303</td>\n",
       "      <td>0.079934</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.081642</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAE/FMNIST_VAE_16_2&gt;FMNIST_VAE_16_1&gt;Linear_50_0_convex_hull</th>\n",
       "      <td>0.144384</td>\n",
       "      <td>0.012714</td>\n",
       "      <td>0.083585</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.079927</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAE/FMNIST_VAE_16_2&gt;FMNIST_VAE_16_3&gt;Linear_50_0_convex_hull</th>\n",
       "      <td>0.120135</td>\n",
       "      <td>0.009818</td>\n",
       "      <td>0.083587</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.081628</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAE/FMNIST_VAE_16_3&gt;FMNIST_VAE_16_1&gt;Linear_50_0_convex_hull</th>\n",
       "      <td>0.164794</td>\n",
       "      <td>0.022424</td>\n",
       "      <td>0.081626</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.079917</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAE/FMNIST_VAE_16_3&gt;FMNIST_VAE_16_2&gt;Linear_50_0_convex_hull</th>\n",
       "      <td>0.133023</td>\n",
       "      <td>0.015326</td>\n",
       "      <td>0.081645</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.083603</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reconstruction_error  \\\n",
       "                                                                   mean   \n",
       "name                                                                      \n",
       "VAE/FMNIST_VAE_16_1>FMNIST_VAE_16_2>Linear_50_0...             0.136787   \n",
       "VAE/FMNIST_VAE_16_1>FMNIST_VAE_16_3>Linear_50_0...             0.156299   \n",
       "VAE/FMNIST_VAE_16_2>FMNIST_VAE_16_1>Linear_50_0...             0.144384   \n",
       "VAE/FMNIST_VAE_16_2>FMNIST_VAE_16_3>Linear_50_0...             0.120135   \n",
       "VAE/FMNIST_VAE_16_3>FMNIST_VAE_16_1>Linear_50_0...             0.164794   \n",
       "VAE/FMNIST_VAE_16_3>FMNIST_VAE_16_2>Linear_50_0...             0.133023   \n",
       "\n",
       "                                                              \\\n",
       "                                                         std   \n",
       "name                                                           \n",
       "VAE/FMNIST_VAE_16_1>FMNIST_VAE_16_2>Linear_50_0...  0.009693   \n",
       "VAE/FMNIST_VAE_16_1>FMNIST_VAE_16_3>Linear_50_0...  0.013303   \n",
       "VAE/FMNIST_VAE_16_2>FMNIST_VAE_16_1>Linear_50_0...  0.012714   \n",
       "VAE/FMNIST_VAE_16_2>FMNIST_VAE_16_3>Linear_50_0...  0.009818   \n",
       "VAE/FMNIST_VAE_16_3>FMNIST_VAE_16_1>Linear_50_0...  0.022424   \n",
       "VAE/FMNIST_VAE_16_3>FMNIST_VAE_16_2>Linear_50_0...  0.015326   \n",
       "\n",
       "                                                   reconstruction_error_model1  \\\n",
       "                                                                          mean   \n",
       "name                                                                             \n",
       "VAE/FMNIST_VAE_16_1>FMNIST_VAE_16_2>Linear_50_0...                    0.079943   \n",
       "VAE/FMNIST_VAE_16_1>FMNIST_VAE_16_3>Linear_50_0...                    0.079934   \n",
       "VAE/FMNIST_VAE_16_2>FMNIST_VAE_16_1>Linear_50_0...                    0.083585   \n",
       "VAE/FMNIST_VAE_16_2>FMNIST_VAE_16_3>Linear_50_0...                    0.083587   \n",
       "VAE/FMNIST_VAE_16_3>FMNIST_VAE_16_1>Linear_50_0...                    0.081626   \n",
       "VAE/FMNIST_VAE_16_3>FMNIST_VAE_16_2>Linear_50_0...                    0.081645   \n",
       "\n",
       "                                                              \\\n",
       "                                                         std   \n",
       "name                                                           \n",
       "VAE/FMNIST_VAE_16_1>FMNIST_VAE_16_2>Linear_50_0...  0.000031   \n",
       "VAE/FMNIST_VAE_16_1>FMNIST_VAE_16_3>Linear_50_0...  0.000053   \n",
       "VAE/FMNIST_VAE_16_2>FMNIST_VAE_16_1>Linear_50_0...  0.000036   \n",
       "VAE/FMNIST_VAE_16_2>FMNIST_VAE_16_3>Linear_50_0...  0.000030   \n",
       "VAE/FMNIST_VAE_16_3>FMNIST_VAE_16_1>Linear_50_0...  0.000042   \n",
       "VAE/FMNIST_VAE_16_3>FMNIST_VAE_16_2>Linear_50_0...  0.000045   \n",
       "\n",
       "                                                   reconstruction_error_model2  \\\n",
       "                                                                          mean   \n",
       "name                                                                             \n",
       "VAE/FMNIST_VAE_16_1>FMNIST_VAE_16_2>Linear_50_0...                    0.083600   \n",
       "VAE/FMNIST_VAE_16_1>FMNIST_VAE_16_3>Linear_50_0...                    0.081642   \n",
       "VAE/FMNIST_VAE_16_2>FMNIST_VAE_16_1>Linear_50_0...                    0.079927   \n",
       "VAE/FMNIST_VAE_16_2>FMNIST_VAE_16_3>Linear_50_0...                    0.081628   \n",
       "VAE/FMNIST_VAE_16_3>FMNIST_VAE_16_1>Linear_50_0...                    0.079917   \n",
       "VAE/FMNIST_VAE_16_3>FMNIST_VAE_16_2>Linear_50_0...                    0.083603   \n",
       "\n",
       "                                                              \n",
       "                                                         std  \n",
       "name                                                          \n",
       "VAE/FMNIST_VAE_16_1>FMNIST_VAE_16_2>Linear_50_0...  0.000029  \n",
       "VAE/FMNIST_VAE_16_1>FMNIST_VAE_16_3>Linear_50_0...  0.000035  \n",
       "VAE/FMNIST_VAE_16_2>FMNIST_VAE_16_1>Linear_50_0...  0.000040  \n",
       "VAE/FMNIST_VAE_16_2>FMNIST_VAE_16_3>Linear_50_0...  0.000037  \n",
       "VAE/FMNIST_VAE_16_3>FMNIST_VAE_16_1>Linear_50_0...  0.000034  \n",
       "VAE/FMNIST_VAE_16_3>FMNIST_VAE_16_2>Linear_50_0...  0.000039  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by the name and get the mean and standard deviation\n",
    "result_data_grouped = result_data.groupby('name').agg(['mean', 'std'])\n",
    "\n",
    "# Show the data Frame\n",
    "result_data_grouped "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relreps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
