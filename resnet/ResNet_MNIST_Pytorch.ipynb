{"cells":[{"cell_type":"markdown","metadata":{"id":"wxJkQXLcYQlP"},"source":["# Training ResNET\n","In this notebook one pretrained ResNet is trained and one ResNet from scratch is trained.\n","The models are saved in models/."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6531,"status":"ok","timestamp":1715682240626,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"},"user_tz":-120},"id":"3O67DncFKbBB","outputId":"be18b464-54b9-4e7d-9928-6968f81637d7"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Amount google driv\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      7\u001b[0m gdrive_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/gdrive/MyDrive/case_study_opti\u001b[39m\u001b[38;5;124m'\u001b[39m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"]}],"source":["seed=5 # (1,2,3,4,5)\n","model_folder = \"models/\"\n","#Amount google driv\n","from google.colab import drive\n","import os\n","\n","gdrive_path='/content/gdrive/MyDrive/case_study_opti'\n","\n","# This will mount your google drive under 'MyDrive'\n","drive.mount('/content/gdrive', force_remount=True)\n","# In order to access the files in this notebook we have to navigate to the correct folder\n","os.chdir(gdrive_path)\n","# Check manually if all files are present\n","print(sorted(os.listdir()))"]},{"cell_type":"markdown","metadata":{"id":"C3OpFPt8BvcL"},"source":["**ResNet Pytorch implementation for MNIST classification**\n","First we import the required packages."]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":100,"status":"ok","timestamp":1715681898187,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"},"user_tz":-120},"id":"xAKTOMBhZnsO"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'latent-communication'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Variable\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m model_resnet \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatent-communication.resnet.model_def\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m utils \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatent-communication.resnet.utils\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m~/miniconda3/envs/opti/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1310\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1310\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1324\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'latent-communication'"]}],"source":["import torch\n","#Set seed\n","torch.manual_seed(seed)\n","\n","%matplotlib inline\n","import torch.nn as nn\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.models as models\n","from torchvision import transforms\n","import torch.optim as optim\n","import time\n","import tqdm as tqdm\n","from torch.autograd import Variable\n","import importlib\n","model_resnet = importlib.import_module('latent-communication.resnet.model_def')\n","utils = importlib.import_module('latent-communication.resnet.utils')"]},{"cell_type":"markdown","metadata":{"id":"eH9o40oiCEAo"},"source":["## **Load Dataset**\n","We can load data from pytorch dataset and preprocess it using *transform* function.\n","\n","Note that the ResNet implemented in torchvision take RGB images as inputs, which has three channels. So, here we repeat the single-channel grey scale digits image three times to fit the torchvision model."]},{"cell_type":"code","execution_count":92,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":94,"status":"ok","timestamp":1715681898194,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"},"user_tz":-120},"id":"6dkW6FggBsnQ","outputId":"2a4d4048-bb06-4f0b-a27e-e3eaaca7cac9"},"outputs":[{"name":"stdout","output_type":"stream","text":["60000 10000\n"]}],"source":["transform = transforms.Compose([transforms.ToTensor(),\n","                                # expand channel from 1 to 3 to fit\n","                                # ResNet pretrained model\n","                                transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n","                                ])\n","batch_size = 256\n","\n","data_file_path=\"./data\"\n","# download dataset\n","mnist_train = datasets.MNIST(root=data_file_path, train=True, download=True, transform=transform)\n","mnist_test = datasets.MNIST(root=data_file_path, train=False, download=True, transform=transform)\n","print(len(mnist_train), len(mnist_test))\n","\n","# Load dataset\n","train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size,\n","    shuffle=True, num_workers=0)\n","test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size,\n","    shuffle=True, num_workers=0)"]},{"cell_type":"markdown","metadata":{"id":"qNPQ35vFDxPW"},"source":["## **Building the model**\n","\n","The torchvision model is pretrained on ImageNet with 1000 classes of output, therefore, the network structure is not suitable for the classification in MNIST dataset."]},{"cell_type":"code","execution_count":93,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":72,"status":"ok","timestamp":1715681898201,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"},"user_tz":-120},"id":"v8QIpQbPE_Hl","outputId":"6c536d32-75d7-47c7-c6e4-c141401129a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")\n"]}],"source":["# print pretrain model structure\n","net = models.resnet18()\n","print(net)"]},{"cell_type":"markdown","metadata":{"id":"a_Hmk1y4GJ33"},"source":["## **Modify Pretrain Model Structure**\n","The main structure of the ResNet can be split into two parts: the feature generator (G) and the classifier (F). The pretrained weights on the feature generator can be reused and a new classifier can be trained to fit the calssfication task in MNIST.\n","\n","In the following codes, *ResNetFeatrueExtractor18* reproduces the feature extraction parts of the ResNet18, with an option to load the pretained model. And *ResClassifier* use a fully connected layer to get 10 class predictions.\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1715682240630,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"},"user_tz":-120},"id":"tQU0tzUdbWid"},"outputs":[],"source":["\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        torch.nn.init.xavier_uniform_(m.weight)\n","    elif classname.find('Linear') != -1:\n","        torch.nn.init.xavier_uniform_(m.weight)\n","    elif classname.find('BatchNorm') != -1:\n","        m.weight.data.normal_(1.0, 0.01)\n","\n","# calculate test accuracy\n","def test_accuracy(data_iter, model):\n","    \"\"\"Evaluate testset accuracy of a model.\"\"\"\n","    acc_sum,n = 0,0\n","    for (imgs, labels) in data_iter:\n","        # send data to the GPU if cuda is availabel\n","        if torch.cuda.is_available():\n","            imgs = imgs.cuda()\n","            labels = labels.cuda()\n","        model.eval()\n","        with torch.no_grad():\n","            labels = labels.long()\n","            acc_sum += torch.sum((torch.argmax(model(imgs)), dim=1) == labels).float()\n","            n += labels.shape[0]\n","    return acc_sum.item()/n"]},{"cell_type":"markdown","metadata":{"id":"flCHdHBv1QhI"},"source":["## **Pre-trained model**"]},{"cell_type":"markdown","metadata":{"id":"jWc_WfomXWeu"},"source":["### Training"]},{"cell_type":"code","execution_count":101,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":150035,"status":"ok","timestamp":1715682391226,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"},"user_tz":-120},"id":"OA2mJHVQd_aA","outputId":"bdcd485e-5170-4581-fd0e-1d531aaf2894"},"outputs":[{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 1, loss 0.0008, train acc 0.935, test acc 0.982, time 14.7 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 2, loss 0.0002, train acc 0.988, test acc 0.986, time 14.8 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 3, loss 0.0001, train acc 0.993, test acc 0.987, time 14.8 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 4, loss 0.0001, train acc 0.996, test acc 0.988, time 14.8 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 5, loss 0.0000, train acc 0.997, test acc 0.988, time 14.9 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:14, 16.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 6, loss 0.0000, train acc 0.998, test acc 0.988, time 16.7 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 7, loss 0.0000, train acc 0.999, test acc 0.988, time 15.5 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 8, loss 0.0000, train acc 0.999, test acc 0.989, time 14.8 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 9, loss 0.0000, train acc 0.999, test acc 0.989, time 14.8 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 10, loss 0.0000, train acc 0.999, test acc 0.990, time 14.7 sec\n"]}],"source":["model = model = model_resnet.ResNet(pretrained=True)\n","\n","if torch.cuda.is_available():\n","    model = model.cuda()\n","\n","# setting up optimizer for both feature generator G and classifier F.\n","opt = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0005,momentum=0.9)\n","\n","# loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","for epoch in range(0, 10):\n","    n, start = 0, time.time()\n","    train_l_sum = torch.tensor([0.0], dtype=torch.float32)\n","    train_acc_sum = torch.tensor([0.0], dtype=torch.float32)\n","    for i, (imgs, labels) in tqdm.tqdm(enumerate(iter(train_loader))):\n","        model.train()\n","        imgs = Variable(imgs)\n","        labels = Variable(labels)\n","        # train on GPU if possible\n","        if torch.cuda.is_available():\n","            imgs = imgs.cuda()\n","            labels = labels.cuda()\n","            train_l_sum = train_l_sum.cuda()\n","            train_acc_sum = train_acc_sum.cuda()\n","\n","        opt.zero_grad()\n","        # predicted labels\n","        label_hat = model(imgs)\n","\n","        # loss function\n","        loss= criterion(label_hat, labels)\n","        loss.backward()\n","        opt.step()\n","\n","        # calcualte training error\n","        model.eval()\n","        labels = labels.long()\n","        train_l_sum += loss.float()\n","        train_acc_sum += (torch.sum((torch.argmax(label_hat, dim=1) == labels))).float()\n","        n += labels.shape[0]\n","    test_acc = test_accuracy(iter(test_loader), model)\n","    print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\\\n","        % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc, time.time() - start))\n"]},{"cell_type":"code","execution_count":102,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1715682391227,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"},"user_tz":-120},"id":"v0ZGY7JaYsgJ"},"outputs":[],"source":["## Save the model\n","torch.save(model.state_dict(), f'latent-communication/resnet/models/pretrained_model_seed{seed}.pth')"]},{"cell_type":"markdown","metadata":{"id":"YTZsV8zd1WHw"},"source":["## **Training without Pre-trained model**"]},{"cell_type":"code","execution_count":103,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":151148,"status":"ok","timestamp":1715682542362,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"},"user_tz":-120},"id":"098y1Mwn07qZ","outputId":"7c7e772e-0851-49d2-e454-c186a9d8da99"},"outputs":[{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 1, loss 0.0009, train acc 0.930, test acc 0.973, time 15.0 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 2, loss 0.0002, train acc 0.983, test acc 0.978, time 14.9 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 3, loss 0.0001, train acc 0.992, test acc 0.981, time 14.8 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 4, loss 0.0001, train acc 0.997, test acc 0.983, time 14.9 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 5, loss 0.0000, train acc 0.999, test acc 0.984, time 14.9 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 6, loss 0.0000, train acc 1.000, test acc 0.985, time 15.2 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 7, loss 0.0000, train acc 1.000, test acc 0.985, time 15.6 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 8, loss 0.0000, train acc 1.000, test acc 0.985, time 15.2 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 9, loss 0.0000, train acc 1.000, test acc 0.985, time 14.9 sec\n"]},{"name":"stderr","output_type":"stream","text":["235it [00:13, 17.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 10, loss 0.0000, train acc 1.000, test acc 0.985, time 14.9 sec\n"]}],"source":["# setting pretrained to False. The rest is the same\n","model = model_resnet.ResNet(pretrained=False)\n","\n","if torch.cuda.is_available():\n","    model = model.cuda()\n","\n","opt = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0005,momentum=0.9)\n","criterion = nn.CrossEntropyLoss()\n","\n","for epoch in range(0, 10):\n","    n, start = 0, time.time()\n","    train_l_sum = torch.tensor([0.0], dtype=torch.float32)\n","    train_acc_sum = torch.tensor([0.0], dtype=torch.float32)\n","    for i, (imgs, labels) in tqdm.tqdm(enumerate(iter(train_loader))):\n","        model.train()\n","        imgs = Variable(imgs)\n","        labels = Variable(labels)\n","        if torch.cuda.is_available():\n","            imgs = imgs.cuda()\n","            labels = labels.cuda()\n","            train_l_sum = train_l_sum.cuda()\n","            train_acc_sum = train_acc_sum.cuda()\n","\n","        opt.zero_grad()\n","\n","        label_hat = model(imgs)\n","\n","        # loss function\n","        loss= criterion(label_hat, labels)\n","        loss.backward()\n","        opt.step()\n","\n","\n","        # calcualte training error\n","        model.eval()\n","        labels = labels.long()\n","        train_l_sum += loss.float()\n","        train_acc_sum += (torch.sum((torch.argmax(label_hat, dim=1) == labels))).float()\n","        n += labels.shape[0]\n","    test_acc = test_accuracy(iter(test_loader), model)\n","    print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\\\n","        % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc, time.time() - start))\n"]},{"cell_type":"code","execution_count":104,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1715682542364,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"},"user_tz":-120},"id":"z-QcJKsraA0z"},"outputs":[],"source":["## Save the model\n","torch.save(model.state_dict(), f'latent-communication/resnet/models/model_seed{seed}.pth')"]},{"cell_type":"code","execution_count":104,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1715682542365,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"},"user_tz":-120},"id":"zWvSOkoknBYS"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
