{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Training ResNET\n","In this notebook one pretrained ResNet is trained and one ResNet from scratch is trained.\n","The models are saved in models/."],"metadata":{"id":"wxJkQXLcYQlP"}},{"cell_type":"code","source":["seed=5 # (1,2,3,4,5)\n","model_folder = \"models/\"\n","#Amount google driv\n","from google.colab import drive\n","import os\n","\n","gdrive_path='/content/gdrive/MyDrive/case_study_opti'\n","\n","# This will mount your google drive under 'MyDrive'\n","drive.mount('/content/gdrive', force_remount=True)\n","# In order to access the files in this notebook we have to navigate to the correct folder\n","os.chdir(gdrive_path)\n","# Check manually if all files are present\n","print(sorted(os.listdir()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3O67DncFKbBB","executionInfo":{"status":"ok","timestamp":1715682240626,"user_tz":-120,"elapsed":6531,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"}},"outputId":"be18b464-54b9-4e7d-9928-6968f81637d7"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","['data', 'latent-communication']\n"]}]},{"cell_type":"markdown","metadata":{"id":"C3OpFPt8BvcL"},"source":["**ResNet Pytorch implementation for MNIST classification**\n","First we import the required packages."]},{"cell_type":"code","metadata":{"id":"xAKTOMBhZnsO","executionInfo":{"status":"ok","timestamp":1715681898187,"user_tz":-120,"elapsed":100,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"}}},"source":["import torch\n","#Set seed\n","torch.manual_seed(seed)\n","\n","%matplotlib inline\n","import torch.nn as nn\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.models as models\n","from torchvision import transforms\n","import torch.optim as optim\n","import time\n","import tqdm as tqdm\n","from torch.autograd import Variable\n","import importlib\n","utils = importlib.import_module('latent-communication.resnet.utils')"],"execution_count":91,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eH9o40oiCEAo"},"source":["## **Load Dataset**\n","We can load data from pytorch dataset and preprocess it using *transform* function.\n","\n","Note that the ResNet implemented in torchvision take RGB images as inputs, which has three channels. So, here we repeat the single-channel grey scale digits image three times to fit the torchvision model."]},{"cell_type":"code","metadata":{"id":"6dkW6FggBsnQ","outputId":"2a4d4048-bb06-4f0b-a27e-e3eaaca7cac9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715681898194,"user_tz":-120,"elapsed":94,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"}}},"source":["transform = transforms.Compose([transforms.ToTensor(),\n","                                # expand chennel from 1 to 3 to fit\n","                                # ResNet pretrained model\n","                                transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n","                                ])\n","batch_size = 256\n","\n","data_file_path=\"./data\"\n","# download dataset\n","mnist_train = datasets.MNIST(root=data_file_path, train=True, download=True, transform=transform)\n","mnist_test = datasets.MNIST(root=data_file_path, train=False, download=True, transform=transform)\n","print(len(mnist_train), len(mnist_test))\n","\n","# Load dataset\n","train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size,\n","    shuffle=True, num_workers=0)\n","test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size,\n","    shuffle=True, num_workers=0)"],"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["60000 10000\n"]}]},{"cell_type":"markdown","metadata":{"id":"qNPQ35vFDxPW"},"source":["## **Building the model**\n","\n","The torchvision model is pretrained on ImageNet with 1000 classes of output, therefore, the network structure is not suitable for the classification in MNIST dataset."]},{"cell_type":"code","metadata":{"id":"v8QIpQbPE_Hl","outputId":"6c536d32-75d7-47c7-c6e4-c141401129a2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715681898201,"user_tz":-120,"elapsed":72,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"}}},"source":["# print pretrain model structure\n","net = models.resnet18()\n","print(net)"],"execution_count":93,"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")\n"]}]},{"cell_type":"markdown","metadata":{"id":"a_Hmk1y4GJ33"},"source":["## **Modify Pretrain Model Structure**\n","The main structure of the ResNet can be split into two parts: the feature generator (G) and the classifier (F). The pretrained weights on the feature generator can be reused and a new classifier can be trained to fit the calssfication task in MNIST.\n","\n","In the following codes, *ResNetFeatrueExtractor18* reproduces the feature extraction parts of the ResNet18, with an option to load the pretained model. And *ResClassifier* use a fully connected layer to get 10 class predictions.\n","\n"]},{"cell_type":"code","metadata":{"id":"tQU0tzUdbWid","executionInfo":{"status":"ok","timestamp":1715682240630,"user_tz":-120,"elapsed":22,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"}}},"source":["\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        torch.nn.init.xavier_uniform_(m.weight)\n","    elif classname.find('Linear') != -1:\n","        torch.nn.init.xavier_uniform_(m.weight)\n","    elif classname.find('BatchNorm') != -1:\n","        m.weight.data.normal_(1.0, 0.01)\n","\n","# calculate test accuracy\n","def test_accuracy(data_iter, netG, netF):\n","    \"\"\"Evaluate testset accuracy of a model.\"\"\"\n","    acc_sum,n = 0,0\n","    for (imgs, labels) in data_iter:\n","        # send data to the GPU if cuda is availabel\n","        if torch.cuda.is_available():\n","            imgs = imgs.cuda()\n","            labels = labels.cuda()\n","        netG.eval()\n","        netF.eval()\n","        with torch.no_grad():\n","            labels = labels.long()\n","            acc_sum += torch.sum((torch.argmax(netF(netG(imgs)), dim=1) == labels)).float()\n","            n += labels.shape[0]\n","    return acc_sum.item()/n"],"execution_count":100,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"flCHdHBv1QhI"},"source":["## **Pre-trained model**"]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"jWc_WfomXWeu"}},{"cell_type":"code","metadata":{"id":"OA2mJHVQd_aA","outputId":"bdcd485e-5170-4581-fd0e-1d531aaf2894","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715682391226,"user_tz":-120,"elapsed":150035,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"}}},"source":["encoder = utils.ResNetFeatrueExtractor18(pretrained = True)\n","classifier = utils.ResClassifier()\n","\n","if torch.cuda.is_available():\n","    encoder = encoder.cuda()\n","    classifier = classifier.cuda()\n","\n","# setting up optimizer for both feature generator G and classifier F.\n","opt_g = optim.SGD(encoder.parameters(), lr=0.01, weight_decay=0.0005)\n","opt_f = optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n","\n","# loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","for epoch in range(0, 10):\n","    n, start = 0, time.time()\n","    train_l_sum = torch.tensor([0.0], dtype=torch.float32)\n","    train_acc_sum = torch.tensor([0.0], dtype=torch.float32)\n","    for i, (imgs, labels) in tqdm.tqdm(enumerate(iter(train_loader))):\n","        encoder.train()\n","        classifier.train()\n","        imgs = Variable(imgs)\n","        labels = Variable(labels)\n","        # train on GPU if possible\n","        if torch.cuda.is_available():\n","            imgs = imgs.cuda()\n","            labels = labels.cuda()\n","            train_l_sum = train_l_sum.cuda()\n","            train_acc_sum = train_acc_sum.cuda()\n","\n","        opt_g.zero_grad()\n","        opt_f.zero_grad()\n","\n","        # extracted feature\n","        bottleneck = encoder(imgs)\n","\n","        # predicted labels\n","        label_hat = classifier(bottleneck)\n","\n","        # loss function\n","        loss= criterion(label_hat, labels)\n","        loss.backward()\n","        opt_g.step()\n","        opt_f.step()\n","\n","        # calcualte training error\n","        encoder.eval()\n","        classifier.eval()\n","        labels = labels.long()\n","        train_l_sum += loss.float()\n","        train_acc_sum += (torch.sum((torch.argmax(label_hat, dim=1) == labels))).float()\n","        n += labels.shape[0]\n","    test_acc = test_accuracy(iter(test_loader), encoder, classifier)\n","    print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\\\n","        % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc, time.time() - start))\n"],"execution_count":101,"outputs":[{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 1, loss 0.0008, train acc 0.935, test acc 0.982, time 14.7 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 2, loss 0.0002, train acc 0.988, test acc 0.986, time 14.8 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 3, loss 0.0001, train acc 0.993, test acc 0.987, time 14.8 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 4, loss 0.0001, train acc 0.996, test acc 0.988, time 14.8 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 5, loss 0.0000, train acc 0.997, test acc 0.988, time 14.9 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:14, 16.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 6, loss 0.0000, train acc 0.998, test acc 0.988, time 16.7 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 7, loss 0.0000, train acc 0.999, test acc 0.988, time 15.5 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 8, loss 0.0000, train acc 0.999, test acc 0.989, time 14.8 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 9, loss 0.0000, train acc 0.999, test acc 0.989, time 14.8 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 10, loss 0.0000, train acc 0.999, test acc 0.990, time 14.7 sec\n"]}]},{"cell_type":"code","source":["## Save the model\n","torch.save(encoder.state_dict(), f'latent-communication/resnet/models/encoder_pretrained_model_seed{seed}.pth')\n","torch.save(classifier.state_dict(),f'latent-communication/resnet/models/classifier_pretrained_model_seed{seed}.pth')"],"metadata":{"id":"v0ZGY7JaYsgJ","executionInfo":{"status":"ok","timestamp":1715682391227,"user_tz":-120,"elapsed":17,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"}}},"execution_count":102,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YTZsV8zd1WHw"},"source":["## **Training without Pre-trained model**"]},{"cell_type":"code","metadata":{"id":"098y1Mwn07qZ","outputId":"7c7e772e-0851-49d2-e454-c186a9d8da99","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715682542362,"user_tz":-120,"elapsed":151148,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"}}},"source":["# setting pretrained to False. The rest is the same\n","encoder = utils.ResNetFeatrueExtractor18(pretrained=False)\n","classifier = utils.ResClassifier()\n","\n","if torch.cuda.is_available():\n","    encoder = encoder.cuda()\n","    classifier = classifier.cuda()\n","\n","opt_g = optim.SGD(encoder.parameters(), lr=0.01, weight_decay=0.0005)\n","opt_f = optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","for epoch in range(0, 10):\n","    n, start = 0, time.time()\n","    train_l_sum = torch.tensor([0.0], dtype=torch.float32)\n","    train_acc_sum = torch.tensor([0.0], dtype=torch.float32)\n","    for i, (imgs, labels) in tqdm.tqdm(enumerate(iter(train_loader))):\n","        encoder.train()\n","        classifier.train()\n","        imgs = Variable(imgs)\n","        labels = Variable(labels)\n","        if torch.cuda.is_available():\n","            imgs = imgs.cuda()\n","            labels = labels.cuda()\n","            train_l_sum = train_l_sum.cuda()\n","            train_acc_sum = train_acc_sum.cuda()\n","\n","        opt_g.zero_grad()\n","        opt_f.zero_grad()\n","\n","        bottleneck = encoder(imgs)\n","\n","        label_hat = classifier(bottleneck)\n","\n","        # loss function\n","        loss= criterion(label_hat, labels)\n","        loss.backward()\n","        opt_g.step()\n","        opt_f.step()\n","\n","        # calcualte training error\n","        encoder.eval()\n","        classifier.eval()\n","        labels = labels.long()\n","        train_l_sum += loss.float()\n","        train_acc_sum += (torch.sum((torch.argmax(label_hat, dim=1) == labels))).float()\n","        n += labels.shape[0]\n","    test_acc = test_accuracy(iter(test_loader), encoder, classifier)\n","    print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\\\n","        % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc, time.time() - start))\n"],"execution_count":103,"outputs":[{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 1, loss 0.0009, train acc 0.930, test acc 0.973, time 15.0 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 2, loss 0.0002, train acc 0.983, test acc 0.978, time 14.9 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 3, loss 0.0001, train acc 0.992, test acc 0.981, time 14.8 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 4, loss 0.0001, train acc 0.997, test acc 0.983, time 14.9 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 5, loss 0.0000, train acc 0.999, test acc 0.984, time 14.9 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 6, loss 0.0000, train acc 1.000, test acc 0.985, time 15.2 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 7, loss 0.0000, train acc 1.000, test acc 0.985, time 15.6 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 8, loss 0.0000, train acc 1.000, test acc 0.985, time 15.2 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 9, loss 0.0000, train acc 1.000, test acc 0.985, time 14.9 sec\n"]},{"output_type":"stream","name":"stderr","text":["235it [00:13, 17.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 10, loss 0.0000, train acc 1.000, test acc 0.985, time 14.9 sec\n"]}]},{"cell_type":"code","source":["## Save the model\n","torch.save(encoder.state_dict(), f'latent-communication/resnet/models/encoder_model_seed{seed}.pth')\n","torch.save(classifier.state_dict(),f'latent-communication/resnet/models/classifier_model_seed{seed}.pth')"],"metadata":{"id":"z-QcJKsraA0z","executionInfo":{"status":"ok","timestamp":1715682542364,"user_tz":-120,"elapsed":36,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"}}},"execution_count":104,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zWvSOkoknBYS","executionInfo":{"status":"ok","timestamp":1715682542365,"user_tz":-120,"elapsed":32,"user":{"displayName":"Hillary H.","userId":"06776921334812731064"}}},"execution_count":104,"outputs":[]}]}