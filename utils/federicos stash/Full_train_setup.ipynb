{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('MNIST', 'models/checkpoints/SMALLAE/MNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderMNIST'>, 1, 28), 1, 20, 128, 0.005, 10), (('MNIST', 'models/checkpoints/SMALLAE/MNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderMNIST'>, 1, 28), 1, 20, 128, 0.005, 30), (('MNIST', 'models/checkpoints/SMALLAE/MNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderMNIST'>, 1, 28), 1, 20, 128, 0.005, 50), (('MNIST', 'models/checkpoints/SMALLAE/MNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderMNIST'>, 1, 28), 2, 20, 128, 0.005, 10), (('MNIST', 'models/checkpoints/SMALLAE/MNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderMNIST'>, 1, 28), 2, 20, 128, 0.005, 30), (('MNIST', 'models/checkpoints/SMALLAE/MNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderMNIST'>, 1, 28), 2, 20, 128, 0.005, 50), (('MNIST', 'models/checkpoints/SMALLAE/MNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderMNIST'>, 1, 28), 3, 20, 128, 0.005, 10), (('MNIST', 'models/checkpoints/SMALLAE/MNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderMNIST'>, 1, 28), 3, 20, 128, 0.005, 30), (('MNIST', 'models/checkpoints/SMALLAE/MNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderMNIST'>, 1, 28), 3, 20, 128, 0.005, 50), (('FMNIST', 'models/checkpoints/SMALLAE/FMNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderFashionMNIST'>, 1, 28), 1, 20, 128, 0.005, 10), (('FMNIST', 'models/checkpoints/SMALLAE/FMNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderFashionMNIST'>, 1, 28), 1, 20, 128, 0.005, 30), (('FMNIST', 'models/checkpoints/SMALLAE/FMNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderFashionMNIST'>, 1, 28), 1, 20, 128, 0.005, 50), (('FMNIST', 'models/checkpoints/SMALLAE/FMNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderFashionMNIST'>, 1, 28), 2, 20, 128, 0.005, 10), (('FMNIST', 'models/checkpoints/SMALLAE/FMNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderFashionMNIST'>, 1, 28), 2, 20, 128, 0.005, 30), (('FMNIST', 'models/checkpoints/SMALLAE/FMNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderFashionMNIST'>, 1, 28), 2, 20, 128, 0.005, 50), (('FMNIST', 'models/checkpoints/SMALLAE/FMNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderFashionMNIST'>, 1, 28), 3, 20, 128, 0.005, 10), (('FMNIST', 'models/checkpoints/SMALLAE/FMNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderFashionMNIST'>, 1, 28), 3, 20, 128, 0.005, 30), (('FMNIST', 'models/checkpoints/SMALLAE/FMNIST/', <class 'utils.dataloaders.full_dataloaders.DataLoaderFashionMNIST'>, 1, 28), 3, 20, 128, 0.005, 50), (('CIFAR10', 'models/checkpoints/SMALLAE/CIFAR10/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR10'>, 3, 32), 1, 20, 128, 0.005, 100), (('CIFAR10', 'models/checkpoints/SMALLAE/CIFAR10/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR10'>, 3, 32), 1, 20, 128, 0.005, 500), (('CIFAR10', 'models/checkpoints/SMALLAE/CIFAR10/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR10'>, 3, 32), 1, 20, 128, 0.005, 1000), (('CIFAR10', 'models/checkpoints/SMALLAE/CIFAR10/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR10'>, 3, 32), 2, 20, 128, 0.005, 100), (('CIFAR10', 'models/checkpoints/SMALLAE/CIFAR10/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR10'>, 3, 32), 2, 20, 128, 0.005, 500), (('CIFAR10', 'models/checkpoints/SMALLAE/CIFAR10/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR10'>, 3, 32), 2, 20, 128, 0.005, 1000), (('CIFAR10', 'models/checkpoints/SMALLAE/CIFAR10/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR10'>, 3, 32), 3, 20, 128, 0.005, 100), (('CIFAR10', 'models/checkpoints/SMALLAE/CIFAR10/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR10'>, 3, 32), 3, 20, 128, 0.005, 500), (('CIFAR10', 'models/checkpoints/SMALLAE/CIFAR10/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR10'>, 3, 32), 3, 20, 128, 0.005, 1000), (('CIFAR100', 'models/checkpoints/SMALLAE/CIFAR100/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR100'>, 3, 32), 1, 20, 128, 0.005, 100), (('CIFAR100', 'models/checkpoints/SMALLAE/CIFAR100/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR100'>, 3, 32), 1, 20, 128, 0.005, 500), (('CIFAR100', 'models/checkpoints/SMALLAE/CIFAR100/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR100'>, 3, 32), 1, 20, 128, 0.005, 1000), (('CIFAR100', 'models/checkpoints/SMALLAE/CIFAR100/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR100'>, 3, 32), 2, 20, 128, 0.005, 100), (('CIFAR100', 'models/checkpoints/SMALLAE/CIFAR100/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR100'>, 3, 32), 2, 20, 128, 0.005, 500), (('CIFAR100', 'models/checkpoints/SMALLAE/CIFAR100/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR100'>, 3, 32), 2, 20, 128, 0.005, 1000), (('CIFAR100', 'models/checkpoints/SMALLAE/CIFAR100/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR100'>, 3, 32), 3, 20, 128, 0.005, 100), (('CIFAR100', 'models/checkpoints/SMALLAE/CIFAR100/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR100'>, 3, 32), 3, 20, 128, 0.005, 500), (('CIFAR100', 'models/checkpoints/SMALLAE/CIFAR100/', <class 'utils.dataloaders.full_dataloaders.DataLoaderCIFAR100'>, 3, 32), 3, 20, 128, 0.005, 1000)] 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:00<00:00, 151906.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: MNIST,DataLoaderMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 10\n",
      "Dataset: MNIST,DataLoaderMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 30\n",
      "Dataset: MNIST,DataLoaderMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 50\n",
      "Dataset: MNIST,DataLoaderMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 10\n",
      "Dataset: MNIST,DataLoaderMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 30\n",
      "Dataset: MNIST,DataLoaderMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 50\n",
      "Dataset: MNIST,DataLoaderMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 10\n",
      "Dataset: MNIST,DataLoaderMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 30\n",
      "Dataset: MNIST,DataLoaderMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 50\n",
      "Dataset: FMNIST,DataLoaderFashionMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 10\n",
      "Dataset: FMNIST,DataLoaderFashionMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 30\n",
      "Dataset: FMNIST,DataLoaderFashionMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 50\n",
      "Dataset: FMNIST,DataLoaderFashionMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 10\n",
      "Dataset: FMNIST,DataLoaderFashionMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 30\n",
      "Dataset: FMNIST,DataLoaderFashionMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 50\n",
      "Dataset: FMNIST,DataLoaderFashionMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 10\n",
      "Dataset: FMNIST,DataLoaderFashionMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 30\n",
      "Dataset: FMNIST,DataLoaderFashionMNIST, Channels input: 1, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 50\n",
      "Dataset: CIFAR10,DataLoaderCIFAR10, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 100\n",
      "Dataset: CIFAR10,DataLoaderCIFAR10, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 500\n",
      "Dataset: CIFAR10,DataLoaderCIFAR10, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 1000\n",
      "Dataset: CIFAR10,DataLoaderCIFAR10, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 100\n",
      "Dataset: CIFAR10,DataLoaderCIFAR10, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 500\n",
      "Dataset: CIFAR10,DataLoaderCIFAR10, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 1000\n",
      "Dataset: CIFAR10,DataLoaderCIFAR10, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 100\n",
      "Dataset: CIFAR10,DataLoaderCIFAR10, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 500\n",
      "Dataset: CIFAR10,DataLoaderCIFAR10, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 1000\n",
      "Dataset: CIFAR100,DataLoaderCIFAR100, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 100\n",
      "Dataset: CIFAR100,DataLoaderCIFAR100, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 500\n",
      "Dataset: CIFAR100,DataLoaderCIFAR100, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 1000\n",
      "Dataset: CIFAR100,DataLoaderCIFAR100, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 100\n",
      "Dataset: CIFAR100,DataLoaderCIFAR100, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 500\n",
      "Dataset: CIFAR100,DataLoaderCIFAR100, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 1000\n",
      "Dataset: CIFAR100,DataLoaderCIFAR100, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 100\n",
      "Dataset: CIFAR100,DataLoaderCIFAR100, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 500\n",
      "Dataset: CIFAR100,DataLoaderCIFAR100, Channels input: 3, Epochs: 20, Batch size: 128, Learning rate: 0.005, Latent size: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from utils.dataloaders.full_dataloaders import DataLoaderMNIST, DataLoaderCIFAR10, DataLoaderCIFAR100, DataLoaderFashionMNIST\n",
    "from models.definitions.PCKTAE import PocketAutoencoder\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.getLogger('torchvision.datasets').setLevel(logging.ERROR)\n",
    "os.chdir('/Users/federicoferoggio/Documents/vs_code/latent-communication')\n",
    "\n",
    "\n",
    "# Initialize DataFrame with additional columns\n",
    "loss_dataset = pd.DataFrame(columns=['Dataset', 'Model','Latent Size', 'Seed', 'Loss'])\n",
    "\n",
    "# Define the lists\n",
    "datasets_list = [ 'MNIST' ,'FMNIST', 'CIFAR10', 'CIFAR100']\n",
    "seeds = [1, 2, 3]\n",
    "paths = ['models/checkpoints/SMALLAE/MNIST/', 'models/checkpoints/SMALLAE/FMNIST/', 'models/checkpoints/SMALLAE/CIFAR10/', 'models/checkpoints/SMALLAE/CIFAR100/']\n",
    "dataloader_l = [DataLoaderMNIST, DataLoaderFashionMNIST, DataLoaderCIFAR10, DataLoaderCIFAR100]\n",
    "channels_input = [1, 1, 3, 3]\n",
    "size_input = [28, 28, 32, 32]  \n",
    "epochs = [20]\n",
    "batch_sizes = [128]\n",
    "learning_rates = [0.005]\n",
    "latent_sizes = [10, 30, 50, 100, 500, 1000]\n",
    "\n",
    "# Create a list of tuples with dataset, corresponding path, dataloader, and input channels\n",
    "dataset_info = list(zip(datasets_list, paths, dataloader_l, channels_input, size_input))\n",
    "\n",
    "# Split dataset_info based on the dataset type\n",
    "mnist_info = dataset_info[:2]\n",
    "cifar_info = dataset_info[2:]\n",
    "\n",
    "# Create combinations for MNIST and CIFAR datasets separately\n",
    "combinations1 = [mnist_info, seeds, epochs, batch_sizes, learning_rates, latent_sizes[:3]]\n",
    "combinations1 = list(itertools.product(*combinations1))\n",
    "\n",
    "combinations2 = [cifar_info, seeds, epochs, batch_sizes, learning_rates, latent_sizes[3:]]\n",
    "combinations2 = list(itertools.product(*combinations2))\n",
    "\n",
    "# Combine both sets of combinations\n",
    "combinations = combinations1 + combinations2\n",
    "\n",
    "# Print the combinations and their count\n",
    "print(combinations, len(combinations))\n",
    "\n",
    "# Example of setting device and augmentations (adjust according to your actual use case)\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "augmentations_mnist = transforms.Compose([transforms.ToTensor()])\n",
    "augmentations_cifar = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "for combo in tqdm(combinations):\n",
    "    (dataset, path, dataloader, channels_input, size_input), seed, epoch, batch_size, learning_rate, latent_size = combo\n",
    "    print(f\"Dataset: {dataset},{dataloader.__name__}, Channels input: {channels_input}, Epochs: {epoch}, Batch size: {batch_size}, Learning rate: {learning_rate}, Latent size: {latent_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/36 [00:00<?, ?it/s]/var/folders/tp/9l7ncvh137x08kdlp_fvr1nw0000gn/T/ipykernel_79754/3857517217.py:43: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  loss_dataset = pd.concat([loss_dataset, new_row], ignore_index=True)\n",
      "Test Loss: 0.00020605821753380514:   3%|▎         | 1/36 [02:16<1:19:20, 136.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_PCKTAE_10_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00011217213964128066:   6%|▌         | 2/36 [04:36<1:18:27, 138.44s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_PCKTAE_30_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 9.17200231924653e-05:   8%|▊         | 3/36 [06:51<1:15:25, 137.13s/it]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_PCKTAE_50_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00020088920372691524:  11%|█         | 4/36 [09:03<1:12:05, 135.18s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_PCKTAE_10_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00011288747366420523:  14%|█▍        | 5/36 [11:23<1:10:36, 136.65s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_PCKTAE_30_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 9.620922751712931e-05:  17%|█▋        | 6/36 [13:43<1:08:57, 137.90s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_PCKTAE_50_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0002197606333964681:  19%|█▉        | 7/36 [16:03<1:06:56, 138.49s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_PCKTAE_10_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00012516352709801277:  22%|██▏       | 8/36 [18:18<1:04:08, 137.44s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_PCKTAE_30_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 8.790682624772049e-05:  25%|██▌       | 9/36 [20:33<1:01:29, 136.65s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_PCKTAE_50_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00020999202296238014:  28%|██▊       | 10/36 [22:46<58:41, 135.45s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMNIST_PCKTAE_10_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00016339955581764725:  31%|███       | 11/36 [24:59<56:11, 134.85s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMNIST_PCKTAE_30_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00015180893360248096:  33%|███▎      | 12/36 [27:13<53:51, 134.63s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMNIST_PCKTAE_50_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00020394296900375121:  36%|███▌      | 13/36 [29:26<51:26, 134.21s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMNIST_PCKTAE_10_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00020273912331837972:  39%|███▉      | 14/36 [31:41<49:13, 134.26s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMNIST_PCKTAE_30_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0001767902101590475:  42%|████▏     | 15/36 [33:55<46:59, 134.26s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMNIST_PCKTAE_50_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00020252968644416785:  44%|████▍     | 16/36 [36:08<44:39, 134.00s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMNIST_PCKTAE_10_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00018998811756779405:  47%|████▋     | 17/36 [38:23<42:27, 134.06s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMNIST_PCKTAE_30_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00014130567967496766:  50%|█████     | 18/36 [40:37<40:14, 134.16s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMNIST_PCKTAE_50_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00016098348880658233:  53%|█████▎    | 19/36 [43:14<39:56, 140.97s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10_PCKTAE_100_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00019003859981953439:  56%|█████▌    | 20/36 [45:55<39:12, 147.02s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10_PCKTAE_500_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00021873708778279068:  58%|█████▊    | 21/36 [48:52<39:02, 156.15s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10_PCKTAE_1000_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00016339024388131132:  61%|██████    | 22/36 [51:33<36:45, 157.55s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10_PCKTAE_100_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00021887839866855147:  64%|██████▍   | 23/36 [54:21<34:48, 160.66s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10_PCKTAE_500_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00034671796734822043:  67%|██████▋   | 24/36 [57:23<33:24, 167.08s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10_PCKTAE_1000_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0001702678116860717:  69%|██████▉   | 25/36 [1:00:06<30:24, 165.89s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10_PCKTAE_100_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00036423591730373473:  72%|███████▏  | 26/36 [1:02:58<27:56, 167.69s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10_PCKTAE_500_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00015172825391622426:  75%|███████▌  | 27/36 [1:06:10<26:14, 174.97s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10_PCKTAE_1000_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00016156063692149104:  78%|███████▊  | 28/36 [1:08:56<22:57, 172.17s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100_PCKTAE_100_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0002996987450272552:  81%|████████  | 29/36 [1:11:49<20:08, 172.61s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100_PCKTAE_500_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00043580564301861805:  83%|████████▎ | 30/36 [1:15:06<17:58, 179.82s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100_PCKTAE_1000_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0001483652585987709:  86%|████████▌ | 31/36 [1:17:52<14:37, 175.59s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100_PCKTAE_100_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00019259809732254405:  89%|████████▉ | 32/36 [1:20:46<11:40, 175.05s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100_PCKTAE_500_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00019620391916000296:  92%|█████████▏| 33/36 [1:24:03<09:05, 181.86s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100_PCKTAE_1000_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0001611016564368848:  94%|█████████▍| 34/36 [1:26:49<05:54, 177.00s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100_PCKTAE_100_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00021326949372681305:  97%|█████████▋| 35/36 [1:29:43<02:56, 176.11s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100_PCKTAE_500_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.000324873584528937: 100%|██████████| 36/36 [1:33:00<00:00, 155.01s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100_PCKTAE_1000_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "iterations_ = tqdm(combinations)\n",
    "for (dataset, path, dataloader, channels_input, size_input), seed, num_epochs, batch_size, learning_rate, latent_dim in iterations_:\n",
    "    augmentations = [transforms.ToTensor()]\n",
    "    dataloader = dataloader(batch_size=batch_size, transformation=augmentations, seed=seed, shuffle_train_flag = True)\n",
    "    test_loader = dataloader.get_test_loader()\n",
    "    train_loader = dataloader.get_train_loader()\n",
    "    config = {\n",
    "        'model_name': 'PCKTAE',\n",
    "        'dataset': dataset,\n",
    "        'weight_var': 1,\n",
    "        'weight_mean': 0,\n",
    "        'seed': seed,\n",
    "        'batch_size': batch_size,\n",
    "        'num_epochs': num_epochs,\n",
    "        'learning_rate': learning_rate,\n",
    "        'path': path\n",
    "    }\n",
    "    \n",
    "    torch.manual_seed(config['seed'])\n",
    "    model = PocketAutoencoder(hidden_dim=latent_dim, n_input_channels=channels_input, input_size=size_input)\n",
    "    model.to(DEVICE)\n",
    "    optimizer = Adam(model.parameters(), lr=config['learning_rate'], weight_decay=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        overall_loss = 0\n",
    "        model.train()  # Set the model to training mode\n",
    "        \n",
    "        for batch_idx, (x, _) in enumerate(train_loader):\n",
    "            x = x.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            loss = model.training_step(x)\n",
    "            overall_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        avg_loss = overall_loss / (len(train_loader) * batch_size)\n",
    "        new_row = pd.DataFrame({'Dataset': [config['dataset']],\n",
    "                                'Model': [config['model_name']],\n",
    "                                'Seed': [config['seed']],\n",
    "                                'Latent Size': [latent_dim],\n",
    "                                'Loss': [avg_loss]})\n",
    "        loss_dataset = pd.concat([loss_dataset, new_row], ignore_index=True)\n",
    "        iterations_.set_description(f\"Epoch: {epoch}, Loss: {avg_loss}\")\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        test_loss = 0\n",
    "        for x_test, _ in test_loader:\n",
    "            x_test = x_test.to(DEVICE)\n",
    "            test_loss += model.validation_step(x_test).item()\n",
    "        \n",
    "        avg_test_loss = test_loss / (len(test_loader) * batch_size)\n",
    "        scheduler.step(avg_test_loss)  # Update the learning rate based on the test loss\n",
    "        new_row = pd.DataFrame({'Dataset': [config['dataset']],\n",
    "                                'Model': [config['model_name']],\n",
    "                                'Seed': [config['seed']],\n",
    "                                'Latent Size': [latent_dim],\n",
    "                                'Loss': [avg_test_loss]})\n",
    "        loss_dataset = pd.concat([loss_dataset, new_row], ignore_index=True)\n",
    "        iterations_.set_description(f\"Test Loss: {avg_test_loss}\")    \n",
    "    \n",
    "    # Save the model\n",
    "    name = f\"{config['dataset']}_{config['model_name']}_{latent_dim}_{config['seed']}.pth\"\n",
    "    print(name)\n",
    "    path = config['path'] + name\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "loss_dataset.to_csv('models/checkpoints/SMALLAE/lossesFMIST.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "os.chdir('/Users/federicoferoggio/Documents/vs_code/latent-communication')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "from models.definitions.PCKTAE import PocketAutoencoder\n",
    "from utils.dataloaders.full_dataloaders import DataLoaderMNIST, DataLoaderFashionMNIST, DataLoaderCIFAR10, DataLoaderCIFAR100\n",
    "from utils.visualization import (\n",
    "    visualize_mapping_error,\n",
    "    visualize_latent_space_pca,\n",
    "    plot_latent_space,\n",
    "    highlight_cluster,\n",
    ")\n",
    "from utils.sampler import *\n",
    "from optimization.fit_mapping import create_mapping\n",
    "from utils.metrics import calculate_MSE_ssim_psnr\n",
    "from utils.model import load_model, get_transformations\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clear GPU memory\n",
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def define_dataloader(file, file2, use_test_set=False):\n",
    "    if file.strip(\"_\")[0] != file2.strip(\"_\")[0]:\n",
    "        logging.error(\"The datasets are different\")\n",
    "    # Define the dataloaders\n",
    "    name_dataset, name_model, size_of_the_latent, seed = file.strip(\".pth\").split(\"_\")\n",
    "    augumentation = get_transformations(name_model)\n",
    "    if name_dataset.lower() == \"mnist\":\n",
    "        dataloader = DataLoaderMNIST(transformation=augumentation, batch_size=64, seed=int(seed))\n",
    "    if name_dataset.lower() == \"fmnist\":\n",
    "        dataloader = DataLoaderFashionMNIST(transformation=augumentation,batch_size=64, seed=int(seed))\n",
    "    if name_dataset.lower() == \"cifar10\":\n",
    "        dataloader = DataLoaderCIFAR10(transformation=augumentation,batch_size=64, seed=int(seed))\n",
    "    if name_dataset.lower() == \"cifar100\":\n",
    "        dataloader = DataLoaderCIFAR100(transformation=augumentation,batch_size=64, seed=int(seed))\n",
    "    if use_test_set:\n",
    "        full_dataset_images, full_dataset_labels = dataloader.get_full_test_dataset()\n",
    "    else:\n",
    "        full_dataset_images, full_dataset_labels = dataloader.get_full_train_dataset()\n",
    "    return full_dataset_images, full_dataset_labels, len(np.unique(full_dataset_labels.numpy()))\n",
    "\n",
    "\n",
    "def calculate_and_save_mapping(model1, model2, sampling_strategy, sampled_images, parameters, file1, file2, transformations_database, num_samples, lamda, DEVICE):\n",
    "\n",
    "    name_dataset1, name_model1, size_of_the_latent1, seed1 = file1.strip(\".pth\").split(\"_\")\n",
    "    name_dataset2, name_model2, size_of_the_latent2, seed2 = file2.strip(\".pth\").split(\"_\")\n",
    "\n",
    "    # Set the model to evaluation and sends them to the DEVICE \n",
    "    model1.to(torch.float32).to(DEVICE).eval()\n",
    "    model2.to(torch.float32).to(DEVICE).eval()\n",
    "    # Get latent of the sampled images\n",
    "    latent_left_sampled_equally = model1.get_latent_space(sampled_images)\n",
    "    latent_right_sampled_equally = model2.get_latent_space(sampled_images)\n",
    "    latent_left_sampled_equally = latent_left_sampled_equally.to(torch.float32).cpu().detach().numpy()\n",
    "    latent_right_sampled_equally = latent_right_sampled_equally.to(torch.float32).cpu().detach().numpy()\n",
    "    # Create mapping and visualize\n",
    "    cfg = Config(**parameters)\n",
    "    mapping = create_mapping(cfg, latent_left_sampled_equally, latent_right_sampled_equally, do_print=False)\n",
    "    mapping.fit()\n",
    "    storage_path = f'results/transformations/mapping_files/{name_model2}/'\n",
    "    Path(storage_path).mkdir(parents=True, exist_ok=True)\n",
    "    filename = f\"{file1.strip('.pth')}>{file2.strip('.pth')}>{cfg.mapping}_{num_samples}_{lamda}_{sampling_strategy}\"\n",
    "    mapping.save_results(storage_path + filename)\n",
    "    transformations_database = pd.concat([transformations_database, pd.DataFrame({\"model1\": [file1], \"model2\": [file2], \"mapping\": [storage_path]})], ignore_index=True)\n",
    "    return transformations_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing FMNIST_PCKTAE_50_1.pth and FMNIST_PCKTAE_50_3.pth:   0%|          | 6/2160 [05:15<26:32:07, 44.35s/it]/Users/federicoferoggio/Documents/vs_code/latent-communication/.zeroshot/lib/python3.9/site-packages/cvxpy/problems/problem.py:1407: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Processing FMNIST_PCKTAE_50_1.pth and FMNIST_PCKTAE_50_2.pth:   2%|▏         | 39/2160 [52:15<49:47:42, 84.52s/it] /Users/federicoferoggio/Documents/vs_code/latent-communication/.zeroshot/lib/python3.9/site-packages/cvxpy/problems/problem.py:1407: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Processing FMNIST_PCKTAE_50_1.pth and FMNIST_PCKTAE_30_1.pth:   7%|▋         | 144/2160 [3:07:32<43:45:30, 78.14s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure:interrupted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "SolverError",
     "evalue": "Solver 'SCS' failed. Try another solver, or solve with verbose=True for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSolverError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m images_sampled_best_classes, labels_sampled_convex_hull \u001b[38;5;241m=\u001b[39m sample_convex_hulls_images(num_samples, images, labels, model1)\n\u001b[1;32m     46\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (file1, file2))\n\u001b[0;32m---> 47\u001b[0m df_save_mappings \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_and_save_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mequally\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages_sampled_equally\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_save_mappings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m df_save_mappings \u001b[38;5;241m=\u001b[39m calculate_and_save_mapping(model1, model2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutliers\u001b[39m\u001b[38;5;124m\"\u001b[39m, images_sampled_max_distance, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n\u001b[1;32m     49\u001b[0m df_save_mappings \u001b[38;5;241m=\u001b[39m calculate_and_save_mapping(model1, model2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworst_classes\u001b[39m\u001b[38;5;124m\"\u001b[39m, images_sampled_worst_classes, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
      "Cell \u001b[0;32mIn[4], line 42\u001b[0m, in \u001b[0;36mcalculate_and_save_mapping\u001b[0;34m(model1, model2, sampling_strategy, sampled_images, parameters, file1, file2, transformations_database, num_samples, lamda, DEVICE)\u001b[0m\n\u001b[1;32m     40\u001b[0m cfg \u001b[38;5;241m=\u001b[39m Config(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameters)\n\u001b[1;32m     41\u001b[0m mapping \u001b[38;5;241m=\u001b[39m create_mapping(cfg, latent_left_sampled_equally, latent_right_sampled_equally, do_print\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 42\u001b[0m \u001b[43mmapping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m storage_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/transformations/mapping_files/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname_model2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     44\u001b[0m Path(storage_path)\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/vs_code/latent-communication/optimization/base_optimizer.py:50\u001b[0m, in \u001b[0;36mBaseOptimizer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_print:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolving the problem\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/vs_code/latent-communication/.zeroshot/lib/python3.9/site-packages/cvxpy/problems/problem.py:503\u001b[0m, in \u001b[0;36mProblem.solve\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    502\u001b[0m     solve_func \u001b[38;5;241m=\u001b[39m Problem\u001b[38;5;241m.\u001b[39m_solve\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msolve_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/vs_code/latent-communication/.zeroshot/lib/python3.9/site-packages/cvxpy/problems/problem.py:1090\u001b[0m, in \u001b[0;36mProblem._solve\u001b[0;34m(self, solver, warm_start, verbose, gp, qcp, requires_grad, enforce_dpp, ignore_dpp, canon_backend, **kwargs)\u001b[0m\n\u001b[1;32m   1088\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solve_time \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n\u001b[0;32m-> 1090\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolving_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;28mprint\u001b[39m(_FOOTER)\n",
      "File \u001b[0;32m~/Documents/vs_code/latent-communication/.zeroshot/lib/python3.9/site-packages/cvxpy/problems/problem.py:1415\u001b[0m, in \u001b[0;36mProblem.unpack_results\u001b[0;34m(self, solution, chain, inverse_data)\u001b[0m\n\u001b[1;32m   1413\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(INF_OR_UNB_MESSAGE)\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solution\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m s\u001b[38;5;241m.\u001b[39mERROR:\n\u001b[0;32m-> 1415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mSolverError(\n\u001b[1;32m   1416\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolver \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m failed. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m chain\u001b[38;5;241m.\u001b[39msolver\u001b[38;5;241m.\u001b[39mname() \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m   1417\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry another solver, or solve with verbose=True for more \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1418\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minformation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munpack(solution)\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solver_stats \u001b[38;5;241m=\u001b[39m SolverStats\u001b[38;5;241m.\u001b[39mfrom_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solution\u001b[38;5;241m.\u001b[39mattr,\n\u001b[1;32m   1422\u001b[0m                                  chain\u001b[38;5;241m.\u001b[39msolver\u001b[38;5;241m.\u001b[39mname())\n",
      "\u001b[0;31mSolverError\u001b[0m: Solver 'SCS' failed. Try another solver, or solve with verbose=True for more information."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_save_mappings = pd.read_csv(\"results/transformations/mapping_files/transfomations_index.csv\")\n",
    "except:\n",
    "    df_save_mappings = pd.DataFrame(columns=[\"model1\", \"model2\", \"mapping\"])\n",
    "\n",
    "## Here is the part that you have to modify however you want\n",
    "## Define directories where you want to ieratively create the mapping, and then write down the parameters you want to use\n",
    "os.makedirs(\"../results/transformations/mapping_files/\", exist_ok=True)\n",
    "\n",
    "folder1 = \"models/checkpoints/SMALLAE/FMNIST/\"\n",
    "folder2 = \"models/checkpoints/SMALLAE/FMNIST/\"\n",
    "number_samples = [10,50,100,200,300]\n",
    "mapping_list = [\"Linear\", \"Affine\"]\n",
    "lamda_list = [0,0.01, 0.001]\n",
    "use_test_set = False\n",
    "filter1 = '_' #write here if you want that the processed files contain this string (example \"_50_\" to only process the files with latent size 50)\n",
    "filter2 = '_' #write here if you want that the processed files contain this string (example \"_50_\" to only process the files with latent size 50)\n",
    "\n",
    "\n",
    "## this autiomatically creates all teh possible setups with the paramenters and the files you speicified, and sets up the correct dataset\n",
    "files1 = [f for f in os.listdir(folder1) if f.endswith(\".pth\") and filter1 in f]\n",
    "files2 = [f for f in os.listdir(folder2) if f.endswith(\".pth\") and filter2 in f]\n",
    "list_of_files = [(f1, f2) for f1, f2 in itertools.product(files1, files2) if f1 != f2]\n",
    "combinations_parameters = list(itertools.product(number_samples, mapping_list, lamda_list))\n",
    "pbar = tqdm(list(itertools.product(list_of_files, combinations_parameters)))\n",
    "images, labels, n_classes = define_dataloader(files1[0], files2[0], use_test_set)\n",
    "images = images.type(torch.float32)\n",
    "labels = labels.type(torch.float32)\n",
    "\n",
    "# Loop through combinations\n",
    "for (file1, file2), (num_samples, mapping, lamda) in pbar:\n",
    "    parameters = {\"num_samples\": num_samples, \"mapping\": mapping, \"lamda\": lamda} #This is done to go around some hydra stuff (<3 kai)\n",
    "    name_dataset1, name_model1, size_of_the_latent1, seed1 = file1.strip(\".pth\").split(\"_\")\n",
    "    name_dataset2, name_model2, size_of_the_latent2, seed2 = file2.strip(\".pth\").split(\"_\")\n",
    "\n",
    "    model1 = load_model(model_name=name_model1, name_dataset=name_dataset1, latent_size=int(size_of_the_latent1), seed=int(seed1), model_path = folder1 + file1)\n",
    "    model2 = load_model(model_name=name_model2, name_dataset=name_dataset2, latent_size=int(size_of_the_latent2), seed=int(seed2), model_path = folder1 + file2)\n",
    "    pbar.set_description(\"Sampling equally per class\")\n",
    "    images_sampled_equally, labels_sampled_equally = sample_equally_per_class_images(num_samples, images, labels)\n",
    "    pbar.set_description(\"Sampling removing outliers\")\n",
    "    images_sampled_max_distance, labels_sampled_drop_outliers = sample_removing_outliers(num_samples, images, labels, model2)\n",
    "    pbar.set_description(\"Sampling worst classes\")\n",
    "    images_sampled_worst_classes, labels_sampled_worst_classes = sample_with_half_worst_classes_images(num_samples, images, labels, model2)\n",
    "    pbar.set_description(\"Sampling convex hull\")\n",
    "    images_sampled_best_classes, labels_sampled_convex_hull = sample_convex_hulls_images(num_samples, images, labels, model1)\n",
    "    pbar.set_description(\"Processing %s and %s\" % (file1, file2))\n",
    "    df_save_mappings = calculate_and_save_mapping(model1, model2, \"equally\", images_sampled_equally, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    df_save_mappings = calculate_and_save_mapping(model1, model2, \"outliers\", images_sampled_max_distance, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    df_save_mappings = calculate_and_save_mapping(model1, model2, \"worst_classes\", images_sampled_worst_classes, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    df_save_mappings = calculate_and_save_mapping(model1, model2, \"convex_hull\", images_sampled_best_classes, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    pbar.set_description(\"Processed %s and %s\" % (file1, file2))\n",
    "df_save_mappings.to_csv(\"../results/transformations/mapping_files/transfomations_index.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_save_mappings = pd.read_csv(\"results/transformations/mapping_files/transfomations_index.csv\")\n",
    "except:\n",
    "    df_save_mappings = pd.DataFrame(columns=[\"model1\", \"model2\", \"mapping\"])\n",
    "\n",
    "## Here is the part that you have to modify however you want\n",
    "## Define directories where you want to ieratively create the mapping, and then write down the parameters you want to use\n",
    "os.makedirs(\"../results/transformations/mapping_files/\", exist_ok=True)\n",
    "\n",
    "folder1 = \"models/checkpoints/SMALLAE/MNIST/\"\n",
    "folder2 = \"models/checkpoints/SMALLAE/MNIST/\"\n",
    "number_samples = [10,50,100,200,300]\n",
    "mapping_list = [\"Linear\", \"Affine\"]\n",
    "lamda_list = [0,0.01, 0.001]\n",
    "use_test_set = False\n",
    "filter1 = '_' #write here if you want that the processed files contain this string (example \"_50_\" to only process the files with latent size 50)\n",
    "filter2 = '_' #write here if you want that the processed files contain this string (example \"_50_\" to only process the files with latent size 50)\n",
    "\n",
    "\n",
    "## this autiomatically creates all teh possible setups with the paramenters and the files you speicified, and sets up the correct dataset\n",
    "files1 = [f for f in os.listdir(folder1) if f.endswith(\".pth\") and filter1 in f]\n",
    "files2 = [f for f in os.listdir(folder2) if f.endswith(\".pth\") and filter2 in f]\n",
    "list_of_files = [(f1, f2) for f1, f2 in itertools.product(files1, files2) if f1 != f2]\n",
    "combinations_parameters = list(itertools.product(number_samples, mapping_list, lamda_list))\n",
    "pbar = tqdm(list(itertools.product(list_of_files, combinations_parameters)))\n",
    "images, labels, n_classes = define_dataloader(files1[0], files2[0], use_test_set)\n",
    "images = images.type(torch.float32)\n",
    "labels = labels.type(torch.float32)\n",
    "\n",
    "# Loop through combinations\n",
    "for (file1, file2), (num_samples, mapping, lamda) in pbar:\n",
    "    parameters = {\"num_samples\": num_samples, \"mapping\": mapping, \"lamda\": lamda} #This is done to go around some hydra stuff (<3 kai)\n",
    "    name_dataset1, name_model1, size_of_the_latent1, seed1 = file1.strip(\".pth\").split(\"_\")\n",
    "    name_dataset2, name_model2, size_of_the_latent2, seed2 = file2.strip(\".pth\").split(\"_\")\n",
    "\n",
    "    model1 = load_model(model_name=name_model1, name_dataset=name_dataset1, latent_size=int(size_of_the_latent1), seed=int(seed1), model_path = folder1 + file1)\n",
    "    model2 = load_model(model_name=name_model2, name_dataset=name_dataset2, latent_size=int(size_of_the_latent2), seed=int(seed2), model_path = folder1 + file2)\n",
    "    pbar.set_description(\"Sampling equally per class\")\n",
    "    images_sampled_equally, labels_sampled_equally = sample_equally_per_class_images(num_samples, images, labels)\n",
    "    pbar.set_description(\"Sampling removing outliers\")\n",
    "    images_sampled_max_distance, labels_sampled_drop_outliers = sample_removing_outliers(num_samples, images, labels, model2)\n",
    "    pbar.set_description(\"Sampling worst classes\")\n",
    "    images_sampled_worst_classes, labels_sampled_worst_classes = sample_with_half_worst_classes_images(num_samples, images, labels, model2)\n",
    "    pbar.set_description(\"Sampling convex hull\")\n",
    "    images_sampled_best_classes, labels_sampled_convex_hull = sample_convex_hulls_images(num_samples, images, labels, model1)\n",
    "    pbar.set_description(\"Processing %s and %s\" % (file1, file2))\n",
    "    df_save_mappings = calculate_and_save_mapping(model1, model2, \"equally\", images_sampled_equally, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    df_save_mappings = calculate_and_save_mapping(model1, model2, \"outliers\", images_sampled_max_distance, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    df_save_mappings = calculate_and_save_mapping(model1, model2, \"worst_classes\", images_sampled_worst_classes, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    df_save_mappings = calculate_and_save_mapping(model1, model2, \"convex_hull\", images_sampled_best_classes, parameters, file1, file2, df_save_mappings, num_samples, lamda, DEVICE)\n",
    "    pbar.set_description(\"Processed %s and %s\" % (file1, file2))\n",
    "df_save_mappings.to_csv(\"../results/transformations/mapping_files/transfomations_index.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".zeroshot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
