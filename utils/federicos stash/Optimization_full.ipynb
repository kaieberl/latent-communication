{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mariotuci/Desktop/Google-Drive/Master/SoSe-24/Project Studies/Project/Code/latent-communication/utils/federicos stash\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import hydra\n",
    "from tqdm import tqdm\n",
    "from utils.dataloaders.dataloader_mnist_single import DataLoaderMNIST\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from models.definitions.PocketAutoencoder import PocketAutoencoder\n",
    "\n",
    "from utils.model import load_model, get_transformations\n",
    "from utils.sampler import simple_sampler, simple_sampler_v1\n",
    "from utils.visualization import visualize_results\n",
    "\n",
    "from optimization.optimizer import LinearFitting\n",
    "from optimization.optimizer import AffineFitting\n",
    "\n",
    "from optimization.fit_mapping import get_latents\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "augmentations = [transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))]\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('mps')\n",
    "model1 = model1 = PocketAutoencoder()\n",
    "model1.load_state_dict(torch.load('../../models/checkpoints/SMALLAE/MNIST/MNIST_SMLLAE_0.01_32_1_3.pth'))\n",
    "model1.to(DEVICE)\n",
    "latentvector, data = simple_sampler_v1(100,model1,augmentations,DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 49)\n"
     ]
    }
   ],
   "source": [
    "print(latentvector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [05:28<00:00,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "order_check = []\n",
    "\n",
    "pth_files = [file for file in os.listdir('models/checkpoints/SMALLAE/MNIST/') if os.path.isfile(os.path.join('models/checkpoints/SMALLAE/MNIST/', file)) and file.endswith('.pth')]\n",
    "\n",
    "for file in tqdm(pth_files):\n",
    "    model_order = []\n",
    "    latent_space_dict = {}\n",
    "    model1 = PocketAutoencoder()\n",
    "    model1.load_state_dict(torch.load(f'models/checkpoints/SMALLAE/MNIST/{file}'))\n",
    "    model1.to(DEVICE)\n",
    "\n",
    "    model1.eval()\n",
    "    DataLoaders = DataLoaderMNIST\n",
    "    indices = range(60000)  # Assuming you want to use the first 40,000 images\n",
    "    data_loader = DataLoaderMNIST(128, augmentations, indices=indices)\n",
    "    test_loader = data_loader.get_test_loader()\n",
    "\n",
    "    # Get all images from test_loader and convert them to latent space\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            latent_space = model1.get_latent_space(images)\n",
    "\n",
    "        # Convert tensor to numpy array\n",
    "        latent_space_np = latent_space.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "        \n",
    "        # Store in dictionary\n",
    "        for idx in range(batch_idx*128, len(images)):\n",
    "            latent_space_dict[batch_idx * 128 + idx] = (latent_space_np[idx], labels_np[idx])\n",
    "            model_order.append(labels_np[idx])\n",
    "    order_check.append(model_order)\n",
    "    torch.save(latent_space_dict, 'models/checkpoints/SMALLAE/MNIST/LATENTS/' + str(file).replace('.pth', '_latent_space.pth'))\n",
    "\n",
    "## Check they are in the same order\n",
    "for i in range(len(order_check)-1):\n",
    "    if order_check[i] != order_check[i+1]:\n",
    "        print('Order is not the same')\n",
    "        break\n",
    "\n",
    "print(len(order_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mapping(cfg, latents1, latents2):\n",
    "    if cfg.mapping == 'Linear':\n",
    "        from optimization.optimizer import LinearFitting\n",
    "        mapping = LinearFitting(latents1, latents2, lamda=cfg.lamda)\n",
    "    elif cfg.mapping == 'Affine':\n",
    "        from optimization.optimizer import AffineFitting\n",
    "        mapping = AffineFitting(latents1, latents2, lamda=cfg.lamda)\n",
    "    elif cfg.mapping == 'NeuralNetwork':\n",
    "        from optimization.optimizer import NeuralNetworkFitting\n",
    "        mapping = NeuralNetworkFitting(latents1, latents2, hidden_dim=cfg.hidden_size, lamda=cfg.lamda, learning_rate=cfg.learning_rate, epochs=cfg.epochs)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid experiment name\")\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_SMLLAE_0.001_128_5_4.pth\n",
      "Defining the problem\n",
      "Solving the problem\n",
      "Results saved at  results/transformations/SMALLAE/Linear_MNIST_SMLLAE__MNIST_SMLLAE_10\n",
      "Defining the problem\n",
      "Solving the problem\n",
      "Results saved at  results/transformations/SMALLAE/Linear_MNIST_SMLLAE__MNIST_SMLLAE_0_10\n",
      "Defining the problem\n",
      "Solving the problem\n",
      "Results saved at  results/transformations/SMALLAE/Linear_MNIST_SMLLAE__MNIST_SMLLAE_10\n",
      "Defining the problem\n",
      "Solving the problem\n",
      "Results saved at  results/transformations/SMALLAE/Linear_MNIST_SMLLAE__MNIST_SMLLAE_0_10\n",
      "Defining the problem\n",
      "Solving the problem\n",
      "Failure:interrupted\n"
     ]
    },
    {
     "ename": "SolverError",
     "evalue": "Solver 'SCS' failed. Try another solver, or solve with verbose=True for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSolverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/mariotuci/Desktop/Google-Drive/Master/SoSe-24/Project Studies/Project/Code/latent-communication/utils/federicos stash/Optimization_full.ipynb Zelle 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mariotuci/Desktop/Google-Drive/Master/SoSe-24/Project%20Studies/Project/Code/latent-communication/utils/federicos%20stash/Optimization_full.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m cfg \u001b[39m=\u001b[39m Config(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameters)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mariotuci/Desktop/Google-Drive/Master/SoSe-24/Project%20Studies/Project/Code/latent-communication/utils/federicos%20stash/Optimization_full.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m mapping \u001b[39m=\u001b[39m create_mapping(cfg, latent1, latent2)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mariotuci/Desktop/Google-Drive/Master/SoSe-24/Project%20Studies/Project/Code/latent-communication/utils/federicos%20stash/Optimization_full.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m mapping\u001b[39m.\u001b[39;49mfit()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mariotuci/Desktop/Google-Drive/Master/SoSe-24/Project%20Studies/Project/Code/latent-communication/utils/federicos%20stash/Optimization_full.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m storage_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mresults/transformations/SMALLAE/\u001b[39m\u001b[39m{\u001b[39;00mcfg\u001b[39m.\u001b[39mmapping\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mfile1[:\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m_latent_space.pth\u001b[39m\u001b[39m\"\u001b[39m)]\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mfile2[:\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m_latent_space.pth\u001b[39m\u001b[39m\"\u001b[39m)]\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mcfg\u001b[39m.\u001b[39mnum_samples\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mariotuci/Desktop/Google-Drive/Master/SoSe-24/Project%20Studies/Project/Code/latent-communication/utils/federicos%20stash/Optimization_full.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m Path(storage_path)\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mmkdir(parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Google-Drive/Master/SoSe-24/Project Studies/Project/Code/latent-communication/optimization/base_optimizer.py:47\u001b[0m, in \u001b[0;36mBaseOptimizer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefine_problem()\n\u001b[1;32m     46\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSolving the problem\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproblem\u001b[39m.\u001b[39;49msolve()\n",
      "File \u001b[0;32m~/miniconda/envs/relreps/lib/python3.8/site-packages/cvxpy/problems/problem.py:503\u001b[0m, in \u001b[0;36mProblem.solve\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    502\u001b[0m     solve_func \u001b[39m=\u001b[39m Problem\u001b[39m.\u001b[39m_solve\n\u001b[0;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m solve_func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda/envs/relreps/lib/python3.8/site-packages/cvxpy/problems/problem.py:1090\u001b[0m, in \u001b[0;36mProblem._solve\u001b[0;34m(self, solver, warm_start, verbose, gp, qcp, requires_grad, enforce_dpp, ignore_dpp, canon_backend, **kwargs)\u001b[0m\n\u001b[1;32m   1088\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   1089\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_solve_time \u001b[39m=\u001b[39m end \u001b[39m-\u001b[39m start\n\u001b[0;32m-> 1090\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munpack_results(solution, solving_chain, inverse_data)\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m   1092\u001b[0m     \u001b[39mprint\u001b[39m(_FOOTER)\n",
      "File \u001b[0;32m~/miniconda/envs/relreps/lib/python3.8/site-packages/cvxpy/problems/problem.py:1415\u001b[0m, in \u001b[0;36mProblem.unpack_results\u001b[0;34m(self, solution, chain, inverse_data)\u001b[0m\n\u001b[1;32m   1413\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(INF_OR_UNB_MESSAGE)\n\u001b[1;32m   1414\u001b[0m \u001b[39mif\u001b[39;00m solution\u001b[39m.\u001b[39mstatus \u001b[39min\u001b[39;00m s\u001b[39m.\u001b[39mERROR:\n\u001b[0;32m-> 1415\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mSolverError(\n\u001b[1;32m   1416\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSolver \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m failed. \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m chain\u001b[39m.\u001b[39msolver\u001b[39m.\u001b[39mname() \u001b[39m+\u001b[39m\n\u001b[1;32m   1417\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTry another solver, or solve with verbose=True for more \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1418\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39minformation.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1420\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munpack(solution)\n\u001b[1;32m   1421\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_solver_stats \u001b[39m=\u001b[39m SolverStats\u001b[39m.\u001b[39mfrom_dict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_solution\u001b[39m.\u001b[39mattr,\n\u001b[1;32m   1422\u001b[0m                                  chain\u001b[39m.\u001b[39msolver\u001b[39m.\u001b[39mname())\n",
      "\u001b[0;31mSolverError\u001b[0m: Solver 'SCS' failed. Try another solver, or solve with verbose=True for more information."
     ]
    }
   ],
   "source": [
    "\n",
    "for file1 in os.listdir('../../models/checkpoints/SMALLAE/MNIST/'):\n",
    "    print(file1)\n",
    "    if file1.endswith('.pth'):\n",
    "        \n",
    "        #latents1 = torch.load('../../models/checkpoints/SMALLAE/MNIST/LATENTS/' + file1)\n",
    "        for file2 in os.listdir('../../models/checkpoints/SMALLAE/MNIST/'):\n",
    "            if file1 != file2 and file2.endswith('.pth'):\n",
    "                \n",
    "                model1 = PocketAutoencoder()\n",
    "                model2 = PocketAutoencoder()\n",
    "                model1.load_state_dict(torch.load('../../models/checkpoints/SMALLAE/MNIST/' + file1))\n",
    "                model2.load_state_dict(torch.load('../../models/checkpoints/SMALLAE/MNIST/' + file2))\n",
    "                #latents2 = torch.load('models/checkpoints/SMALLAE/MNIST/LATENTS/' + file2)\n",
    "\n",
    "                latent1, data = simple_sampler_v1(100,model1,augmentations,DEVICE)\n",
    "                latent2, data = simple_sampler_v1(100,model2,augmentations,DEVICE)\n",
    "                \n",
    "                parameters = {\n",
    "                    \"num_samples\": 10,\n",
    "                    \"mapping\": \"Linear\",\n",
    "                    \"lamda\": 0.01,\n",
    "                }\n",
    "                #latent1_pl = torch.stack([torch.tensor(value[0]) for value in latents1.values()])\n",
    "                #latent2_pl = torch.stack([torch.tensor(value[0]) for value in latents2.values()])\n",
    "                cfg = Config(**parameters)\n",
    "              \n",
    "                mapping = create_mapping(cfg, latent1, latent2)\n",
    "                mapping.fit()\n",
    "                storage_path = f'results/transformations/SMALLAE/{cfg.mapping}_{file1[:-len(\"_latent_space.pth\")]}_{file2[:-len(\"_latent_space.pth\")]}_{cfg.num_samples}'\n",
    "                Path(storage_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "                mapping.save_results(storage_path)\n",
    "                latents1_trafo = mapping.transform(latent1)\n",
    "\n",
    "                # for n in range(10):\n",
    "                #     desired_class = n  # Specify the class you want to filter\n",
    "                #     filtered_samples = []\n",
    "\n",
    "                #     # Filter samples from the test loader based on the desired class\n",
    "                #     for data, label in test_loader:\n",
    "                #         indices = torch.nonzero(label == desired_class, as_tuple=False)\n",
    "                #         if indices.numel() > 0:\n",
    "                #             for idx in indices:\n",
    "                #                 filtered_samples.append((data[idx], label[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".zeroshot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
