{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "os.chdir(\"/Users/federicoferoggio/Documents/vs_code/latent-communication\")\n",
    "\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "from models.definitions.PCKTAE import PocketAutoencoder\n",
    "from utils.dataloaders.full_dataloaders import DataLoaderMNIST\n",
    "from utils.visualization import (\n",
    "    visualize_mapping_error,\n",
    "    visualize_latent_space_pca,\n",
    "    plot_latent_space,\n",
    "    highlight_cluster,\n",
    ")\n",
    "from utils.sampler import *\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "augmentations = [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mapping(cfg, latents1, latents2):\n",
    "    if cfg.mapping == \"Linear\":\n",
    "        from optimization.optimizer import LinearFitting\n",
    "\n",
    "        mapping = LinearFitting(latents1, latents2, lamda=cfg.lamda)\n",
    "    elif cfg.mapping == \"Affine\":\n",
    "        from optimization.optimizer import AffineFitting\n",
    "\n",
    "        mapping = AffineFitting(latents1, latents2, lamda=cfg.lamda)\n",
    "    elif cfg.mapping == \"NeuralNetwork\":\n",
    "        from optimization.optimizer import NeuralNetworkFitting\n",
    "\n",
    "        mapping = NeuralNetworkFitting(\n",
    "            latents1,\n",
    "            latents2,\n",
    "            hidden_dim=cfg.hidden_size,\n",
    "            lamda=cfg.lamda,\n",
    "            learning_rate=cfg.learning_rate,\n",
    "            epochs=cfg.epochs,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Invalid experiment name\")\n",
    "    return mapping\n",
    "\n",
    "def calculate__MSE_ssim_psnr(original, reconstructed, data_range=1.0):\n",
    "    original_np = original.cpu().numpy().squeeze()\n",
    "    mse_value = np.mean((original_np - reconstructed) ** 2)\n",
    "    if original_np.shape != reconstructed.shape:\n",
    "        raise ValueError(f\"Shape mismatch: original shape {original_np.shape}, reconstructed shape {reconstructed.shape}\")\n",
    "\n",
    "    ssim_value = ssim(original_np, reconstructed, data_range=data_range)\n",
    "    psnr_value = psnr(original_np, reconstructed, data_range=data_range)\n",
    "    return mse_value, ssim_value, psnr_value\n",
    "\n",
    "def visualize_modified_latent_space_pca(\n",
    "    latents_trans,\n",
    "    latents_2,\n",
    "    labels,\n",
    "    fig_path=None,\n",
    "    anchors=None,\n",
    "    pca=None,\n",
    "    size=10,\n",
    "    bg_alpha=1,\n",
    "    alpha=1,\n",
    "    title=\"2D PCA of Latent Space\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualizes the 2D latent space obtained from PCA.\n",
    "\n",
    "    Args:\n",
    "        latents_trans: A tensor of shape (N, dim) representing the first set of latent points.\n",
    "        latents_2: A tensor of shape (N, dim) representing the second set of latent points.\n",
    "        labels: A tensor of shape (N,) representing the labels for each latent point.\n",
    "        fig_path: Optional; Path to save the figure.\n",
    "        anchors: Optional; A tensor of shape (M, dim) representing anchor points in the latent space.\n",
    "        pca: Optional; A PCA object to use for transforming the latent space.\n",
    "        size: Optional; Size of the points in the plot.\n",
    "        bg_alpha: Optional; Alpha value for the background points.\n",
    "        alpha: Optional; Alpha value for the highlighted points.\n",
    "    \"\"\"\n",
    "    # Convert lists to tensors if needed\n",
    "    if isinstance(latents_trans, list):\n",
    "        latents_trans = torch.tensor(latents_trans)\n",
    "    if isinstance(latents_2, list):\n",
    "        latents_2 = torch.tensor(latents_2)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    # Concatenate latent spaces\n",
    "    latents = torch.cat([latents_trans, latents_2], dim=0)\n",
    "    print(latents.shape)\n",
    "\n",
    "    if pca is None:\n",
    "        pca = PCA(n_components=2)\n",
    "        latents_2d = pca.fit_transform(latents)\n",
    "    else:\n",
    "        latents_2d = pca.transform(latents)\n",
    "\n",
    "    # Normalize latents\n",
    "    minimum = latents_2d.min(axis=0)\n",
    "    maximum = latents_2d.max(axis=0)\n",
    "    latents_2d -= minimum\n",
    "    latents_2d /= maximum\n",
    "\n",
    "    # Separate the two datasets\n",
    "    latents_trans_2d = latents_2d[: len(latents_trans)]\n",
    "    latents_2_2d = latents_2d[len(latents_trans) :]\n",
    "\n",
    "    # Create DataFrames for easy plotting\n",
    "    latent_df_trans = pd.DataFrame(latents_trans_2d, columns=[\"x\", \"y\"])\n",
    "    latent_df_trans[\"target\"] = labels\n",
    "\n",
    "    latent_df_2 = pd.DataFrame(latents_2_2d, columns=[\"x\", \"y\"])\n",
    "    latent_df_2[\"target\"] = labels\n",
    "\n",
    "    # Plot the 2D latent space\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    cmap = plt.get_cmap(\"tab10\")\n",
    "    norm = plt.Normalize(\n",
    "        latent_df_trans[\"target\"].min(), latent_df_trans[\"target\"].max()\n",
    "    )\n",
    "\n",
    "    ax = plot_latent_space(\n",
    "        ax,\n",
    "        latent_df_trans,\n",
    "        targets=np.unique(labels),\n",
    "        size=size,\n",
    "        cmap=cmap,\n",
    "        norm=norm,\n",
    "        bg_alpha=bg_alpha,\n",
    "        alpha=alpha,\n",
    "        marker=\"2\",\n",
    "    )\n",
    "    ax = plot_latent_space(\n",
    "        ax,\n",
    "        latent_df_2,\n",
    "        targets=np.unique(labels),\n",
    "        size=size,\n",
    "        cmap=cmap,\n",
    "        norm=norm,\n",
    "        bg_alpha=bg_alpha,\n",
    "        alpha=alpha,\n",
    "        marker=\"1\",\n",
    "    )\n",
    "\n",
    "    if anchors is not None:\n",
    "        # plot anchors with star marker\n",
    "        anchors_2d = pca.transform(anchors.cpu().detach().numpy())\n",
    "        anchors_2d -= minimum\n",
    "        anchors_2d /= maximum\n",
    "        ax.scatter(anchors_2d[:, 0], anchors_2d[:, 1], marker=\"*\", s=50, c=\"black\")\n",
    "\n",
    "    plt.title(title)\n",
    "    if fig_path is not None:\n",
    "        plt.savefig(fig_path)\n",
    "    plt.show()\n",
    "\n",
    "# Function to clear GPU memory\n",
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def plot_and_calculate_all(model1, model2, images, labels, sampling_strategy, sampled_images, parameters, file1, file2, df, num_samples, lamda, losses_per_class):\n",
    "    \n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    # Get latent\n",
    "    latent_left = model1.get_latent_space(images).detach().cpu().numpy()\n",
    "    latent_right = model2.get_latent_space(images).detach().cpu().numpy()\n",
    "    latent_left_sampled_equally = torch.tensor(model1.get_latent_space(sampled_images).detach().cpu().numpy())\n",
    "    latent_right_sampled_equally = torch.tensor(model2.get_latent_space(sampled_images).detach().cpu().numpy())\n",
    "    # Create mapping and visualize\n",
    "    cfg = Config(**parameters)\n",
    "    mapping = create_mapping(cfg, latent_left_sampled_equally, latent_right_sampled_equally)\n",
    "    mapping.fit()\n",
    "    storage_path = f'results/transformations/SMALLAE/{cfg.mapping}_{file1[:-len(\".pth\")]}_->_{file2[:-len(\".pth\")]}_{num_samples}_{lamda}/{sampling_strategy}/'\n",
    "    Path(storage_path).mkdir(parents=True, exist_ok=True)\n",
    "    mapping.save_results(storage_path + \"mapping\")\n",
    "    df = pd.concat([df, pd.DataFrame({\"model1\": [file1], \"model2\": [file2], \"mapping\": [storage_path + \"mapping\"]})], ignore_index=True)\n",
    "    transformed_latent_space = mapping.transform(latent_left)\n",
    "    _, latents1_2d = visualize_latent_space_pca(latents=latent_left, labels=labels, fig_path= storage_path + \"latent_left_sampled_equally.png\", anchors=latent_left_sampled_equally, title=\"Model 1 Equal Points\", alpha=0.7, show_fig=False)\n",
    "    pca, latents2_2d = visualize_latent_space_pca(latents=latent_right, labels=labels, fig_path=storage_path + \"latent_right_sampled_equally.png\", anchors=latent_right_sampled_equally, title=\"Model 2 Equal Points\", alpha=0.7, show_fig=False)\n",
    "    _, latents1_trafo_2d = visualize_latent_space_pca(transformed_latent_space, labels, storage_path + \"latents1_transformed_sampled_equally.png\", anchors=mapping.transform(latent_left_sampled_equally), pca=pca, title=f\"Transformation with an {cfg.mapping} Mapping, lambda={cfg.lamda}, num_samples={cfg.num_samples} Equal Points\", alpha=0.7, show_fig=False)\n",
    "    errors = np.linalg.norm(transformed_latent_space - latent_right, axis=1)\n",
    "    visualize_mapping_error(latents1_2d, errors, storage_path + f\"mapping_error_{cfg.mapping}_{sampling_strategy}_.png\", show_fig=False)\n",
    "    total_mse_error, total_ssim_error, total_psnr_error = 0, 0, 0\n",
    "\n",
    "    for i in range(10):\n",
    "        images_sel = images[labels == i]\n",
    "\n",
    "        latents1 = model1.encode(images_sel)\n",
    "        recomposed = model2.decode(mapping.transform(latents1).float())\n",
    "\n",
    "\n",
    "        errors_per_pixel_all = np.abs(images_sel - recomposed.detach().numpy())\n",
    "        errors_per_pixel = errors_per_pixel_all.mean(axis=0)\n",
    "        errors_per_pixel = errors_per_pixel.mean(axis=0)\n",
    "#        errors_per_pixel = (errors_per_pixel - errors_per_pixel.min()) / (errors_per_pixel.max() - errors_per_pixel.min())\n",
    "\n",
    "        ## Plot matrix as heatmap\n",
    "        plt.figure()\n",
    "        sns.heatmap(errors_per_pixel.reshape(28,28), cmap='Reds')\n",
    "        Path(storage_path + '/mean_errors_for_class/').mkdir(parents=True, exist_ok=True)\n",
    "        plt.title(f\"Mean error per pixel for digit {i}\")\n",
    "        plt.savefig(storage_path + '/mean_errors_for_class/' + f\"error_per_pixel_digit_{i}.png\")\n",
    "        plt.close()\n",
    "        mse, ssim, psnr = 0, 0, 0\n",
    "        for x in images_sel:\n",
    "            x = x.unsqueeze(0)\n",
    "            x_reconstructed = model2.decode(mapping.transform(model1.encode(x).float()).float()).detach().numpy()[0][0]\n",
    "            mse_temp, ssim_temp, psnr_temp = calculate__MSE_ssim_psnr(x, x_reconstructed)\n",
    "            mse += mse_temp\n",
    "            ssim += ssim_temp\n",
    "            psnr += psnr_temp\n",
    "        sample_len = len(images_sel)\n",
    "        if sample_len > 0:\n",
    "            mse_value = mse / sample_len\n",
    "            ssim_value = ssim / sample_len\n",
    "            psnr_value = psnr / sample_len\n",
    "        else:\n",
    "            mse_value = (0)\n",
    "            ssim_value = 0\n",
    "            psnr_value = 0\n",
    "        total_mse_error += mse_value\n",
    "        total_ssim_error += ssim_value\n",
    "        total_psnr_error += psnr_value\n",
    "        losses_per_class = pd.concat([losses_per_class,pd.DataFrame({\"Transformation\": [storage_path], \"Class\": [i], \"MSE\": [mse_value], \"SSIM\": [ssim_value], \"PSNR\": [psnr_value]})], ignore_index=True)\n",
    "    total_mse_error, total_ssim_error, total_psnr_error = total_mse_error / len(images), total_ssim_error / len(images), total_psnr_error / len(images)\n",
    "    losses_per_class = pd.concat([losses_per_class,pd.DataFrame({\"Transformation\": [storage_path], \"Class\": [\"Total\"], \"MSE\": [total_mse_error], \"SSIM\": [total_ssim_error], \"PSNR\": [total_psnr_error]})], ignore_index=True)\n",
    "\n",
    "    clear_memory()\n",
    "    return df, losses_per_class\n",
    "\n",
    "def get_latent_variances(model1, model2, images, labels, sampling_strategy, sampled_images, parameters, file1, file2, df, num_samples, lamda, n_classes):\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    # Get latent\n",
    "    latent_left = model1.get_latent_space(images).detach().cpu().numpy()\n",
    "    latent_right = model2.get_latent_space(images).detach().cpu().numpy()\n",
    "    latent_left_sampled_equally = torch.tensor(model1.get_latent_space(sampled_images).detach().cpu().numpy())\n",
    "    latent_right_sampled_equally = torch.tensor(model2.get_latent_space(sampled_images).detach().cpu().numpy())\n",
    "    # Create mapping and visualize\n",
    "    cfg = Config(**parameters)\n",
    "    mapping = create_mapping(cfg, latent_left_sampled_equally, latent_right_sampled_equally)\n",
    "    mapping.fit()\n",
    "    storage_path = f'results/transformations/SMALLAE/{cfg.mapping}_{file1[:-len(\".pth\")]}_->_{file2[:-len(\".pth\")]}_{num_samples}_{lamda}/{sampling_strategy}/'\n",
    "    Path(storage_path).mkdir(parents=True, exist_ok=True)\n",
    "    mapping.save_results(storage_path + \"mapping\")\n",
    "    df = pd.concat([df, pd.DataFrame({\"model1\": [file1], \"model2\": [file2], \"mapping\": [storage_path + \"mapping\"]})], ignore_index=True)\n",
    "    transformed_latent_space = mapping.transform(latent_left)\n",
    "\n",
    "    # Calculate errors per class\n",
    "    errors_original = []\n",
    "    errors_reconstructed = []\n",
    "    for i in range(n_classes):  # Assuming 10 classes (0-9)\n",
    "        class_indices = (labels == i).nonzero(as_tuple=True)[0]\n",
    "        class_images = images[class_indices]\n",
    "        class_transformed_latents = transformed_latent_space[class_indices]\n",
    "        class_latent_right = latent_right[class_indices]\n",
    "\n",
    "        decoded_transformed = model2.decode(torch.tensor(class_transformed_latents).to(images.device)).detach().cpu().numpy()\n",
    "        decoded_latent_right = model2.decode(torch.tensor(class_latent_right).to(images.device)).detach().cpu().numpy()\n",
    "\n",
    "        error_compared_to_original_images = np.linalg.norm(decoded_transformed - class_images.cpu().numpy(), axis=(1, 2, 3))\n",
    "        error_compared_to_reconstructed_images = np.linalg.norm(decoded_transformed - decoded_latent_right, axis=(1, 2, 3))\n",
    "        \n",
    "        errors_original.append(error_compared_to_original_images)\n",
    "        errors_reconstructed.append(error_compared_to_reconstructed_images)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(n_classes):\n",
    "        sns.kdeplot(errors_original[i], label=f'Class {i}')\n",
    "    plt.title('Error Distribution Compared to Original Images by Class')\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(storage_path + \"error_distribution.png\")\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(n_classes):\n",
    "        sns.kdeplot(errors_reconstructed[i], label=f'Class {i}')\n",
    "    plt.title('Error Distribution Compared to Reconstructed Images by Class')\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Density')    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    #save the figure\n",
    "    plt.savefig(storage_path + \"error_distribution.png\")\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "model = PocketAutoencoder()\n",
    "os.chdir('/Users/federicoferoggio/Documents/vs_code/latent-communication')\n",
    "num_samples = [196, 98, 49]\n",
    "mapping = ['Linear', 'Affine']\n",
    "lamda = [0, 0.01, 0.1]\n",
    "combinations = [num_samples, mapping, lamda]\n",
    "combinations = list(itertools.product(*combinations))\n",
    "\n",
    "for file1 in tqdm(os.listdir('models/checkpoints/SMALLAE/MNIST/LATENTS/')):\n",
    "    if file1.endswith('.pth') and \"_0.01_128_20\" in file1:\n",
    "        latents1 = torch.load('models/checkpoints/SMALLAE/MNIST/LATENTS/' + file1)\n",
    "        for file2 in os.listdir('models/checkpoints/SMALLAE/MNIST/LATENTS/'):\n",
    "            if file1 != file2 and (file2.endswith('.pth') and \"_0.01_128_20\" in file2):\n",
    "                latents2 = torch.load('models/checkpoints/SMALLAE/MNIST/LATENTS/' + file2)\n",
    "\n",
    "                for num_samples, mapping, lamda in combinations:\n",
    "                    parameters = {\n",
    "                        \"num_samples\": num_samples,\n",
    "                        \"mapping\": mapping,\n",
    "                        \"lamda\": lamda,\n",
    "                    }\n",
    "\n",
    "                    latent1_pl = []\n",
    "                    latent2_pl = []\n",
    "                    labels = []\n",
    "                    for key in latents1.keys():\n",
    "                        latent1_pl.append(latents1[key][0])\n",
    "                        latent2_pl.append(latents2[key][0])\n",
    "                        labels.append(latents1[key][1])\n",
    "\n",
    "                    latent1_pl = torch.tensor(latent1_pl)\n",
    "                    latent2_pl = torch.tensor(latent2_pl)\n",
    "                    # Generate random indices once\n",
    "                    num_total_points = latent1_pl.size(0)\n",
    "                    random_indices = torch.randperm(num_total_points)[:parameters[\"num_samples\"]]\n",
    "\n",
    "                    # Sample the same points from both tensors\n",
    "                    lats1_sampled, labels_sampled = sample_equally_per_class(parameters[\"num_samples\"] , latent1_pl, labels, transformations=augmentations, seed=0, using_latents=True)\n",
    "                    lats2_sampled, labels_sampled_2 = sample_equally_per_class(parameters[\"num_samples\"] , latent2_pl, labels, transformations=augmentations, seed=0, using_latents=True)\n",
    "                    assert torch.all(labels_sampled == labels_sampled_2)\n",
    "\n",
    "                    cfg = Config(**parameters)\n",
    "                    mapping = create_mapping(cfg, lats1_sampled, lats2_sampled)\n",
    "                    print(lats1_sampled.size())\n",
    "                    mapping.fit()\n",
    "                    storage_path = f'results/transformations/SMALLAE/{cfg.mapping}_{file1[:-len(\"_latent_space.pth\")]}_{file2[:-len(\"_latent_space.pth\")]}_{cfg.num_samples}/{cfg.mapping}_{file1[:-len(\"_latent_space.pth\")]}_{file2[:-len(\"_latent_space.pth\")]}_{cfg.num_samples}/'\n",
    "                    Path(storage_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "                    storage_path_name = storage_path + 'mapping.pth'\n",
    "                    mapping.save_results(storage_path_name)\n",
    "                    latents1_trafo = mapping.transform(latent1_pl)\n",
    "                    _, latents1_2d = visualize_latent_space_pca(latent1_pl, labels, storage_path + \"latent_1.png\", anchors=lats1_sampled, title=\"Model 1\", alpha= 0.7, show_fig=False)\n",
    "                    pca, latents2_2d = visualize_latent_space_pca(latent2_pl, labels, storage_path + \"latent_2.png\", anchors=lats2_sampled, title=\"Model 2\", alpha= 0.7, show_fig=False)\n",
    "                    _, latents1_trafo_2d = visualize_latent_space_pca(latents1_trafo, labels, storage_path + \"latents1_transformed.png\", anchors=mapping.transform(lats1_sampled), pca=pca,title=\"Transformation with an \" + cfg.mapping + \" Mapping, lambda=\" + str(cfg.lamda) + \", num_samples=\" + str(cfg.num_samples), alpha= 0.7, show_fig=False)\n",
    "#                    visualize_modified_latent_space_pca(latents1_trafo,latent2_pl, labels, storage_path + \"latent_transformed.png\", anchors=mapping.transform(lats1_sampled), title=\"Transformation with an \" + cfg.mapping + \" Mapping, lambda=\" + str(cfg.lamda) + \", num_samples=\" + str(cfg.num_samples))                   \n",
    "                    errors = np.linalg.norm(latents1_trafo - latent2_pl, axis=1)\n",
    "                    visualize_mapping_error(latents1_2d, errors, storage_path + f\"mapping_error_{cfg.mapping}_.png\", show_fig=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define pandas dataframe to store paths of models and mapping\n",
    "df = pd.DataFrame(columns=[\"model1\", \"model2\", \"mapping\"])\n",
    "losses_per_class = pd.DataFrame(columns=[\"Transformation\", \"Class\", \"MSE\", \"SSIM\", \"PSNR\"])\n",
    "\n",
    "\n",
    "# Load data\n",
    "data_loader = DataLoaderMNIST(64, transformation=augmentations)\n",
    "images, labels = data_loader.get_full_train_dataset()\n",
    "n_of_classes = len(np.unique(labels))\n",
    "# Generate combinations of parameters\n",
    "pbar = tqdm([10,50,100,200,300])\n",
    "mapping_list = [\"Linear\", \"Affine\"]\n",
    "lamda_list = [0,0.1, 0.01]\n",
    "combinations = list(itertools.product(mapping_list, lamda_list))\n",
    "\n",
    "# Change working directory\n",
    "os.chdir(\"/Users/federicoferoggio/Documents/vs_code/latent-communication\")\n",
    "operating_path = \"models/checkpoints/SMALLAE/MNIST/\"\n",
    "\n",
    "\n",
    "# Loop through combinations\n",
    "for num_samples in pbar:\n",
    "    for mapping, lamda in combinations:\n",
    "        parameters = {\"num_samples\": num_samples, \"mapping\": mapping, \"lamda\": lamda}\n",
    "        for file1 in os.listdir(operating_path):\n",
    "            if file1.endswith(\".pth\"):\n",
    "                for file2 in os.listdir(operating_path):\n",
    "                    if file1 != file2:\n",
    "                        model1 = PocketAutoencoder(path=file1)\n",
    "                        model2 = PocketAutoencoder(path=file2)\n",
    "                        model1.load_state_dict(torch.load(operating_path+ file1))\n",
    "                        model2.load_state_dict(torch.load(operating_path+ file2))\n",
    "                        pbar.set_description(\"Sampling equally per class\")\n",
    "                        images_sampled_equally, labels_sampled_equally = sample_equally_per_class_images(num_samples, images, labels)\n",
    "                        pbar.set_description(\"Sampling removing outliers\")\n",
    "                        images_sampled_max_distance, labels_sampled_drop_outliers = sample_removing_outliers(num_samples, images, labels, model2)\n",
    "                        pbar.set_description(\"Sampling worst classes\")\n",
    "                        images_sampled_worst_classes, labels_sampled_worst_classes = sample_with_half_worst_classes_images(num_samples, images, labels, model2)\n",
    "                        pbar.set_description(\"Sampling convex hull\")\n",
    "                        images_sampled_best_classes, labels_sampled_convex_hull = sample_convex_hulls_images(num_samples, images, labels, model1)\n",
    "                        pbar.set_description(\"Processing %s and %s\" % (file1, file2))\n",
    "                        \n",
    "                        df = get_latent_variances(model1, model2, images, labels, \"equally\", images_sampled_equally, parameters, file1, file2, df, num_samples, lamda, n_of_classes)\n",
    "                        df = get_latent_variances(model1, model2, images, labels, \"outliers\", images_sampled_max_distance, parameters, file1, file2, df, num_samples, lamda, n_of_classes)\n",
    "                        df = get_latent_variances(model1, model2, images, labels, \"worst_classes\", images_sampled_worst_classes, parameters, file1, file2, df, num_samples, lamda, n_of_classes)\n",
    "                        df = get_latent_variances(model1, model2, images, labels, \"convex_hull\", images_sampled_best_classes, parameters, file1, file2, df, num_samples, lamda, n_of_classes)\n",
    "                        pbar.set_description(\"Processed %s and %s\" % (file1, file2))\n",
    "df.to_csv(operating_path + \"transformations.csv\", index=False)\n",
    "losses_per_class.to_csv(operating_path + \"losses_per_class.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".zeroshot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
