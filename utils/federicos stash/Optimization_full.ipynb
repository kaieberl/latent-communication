{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "os.chdir('/Users/federicoferoggio/Documents/vs_code/latent-communication')\n",
    "\n",
    "import torch\n",
    "import hydra\n",
    "from utils.dataloaders.dataloader_mnist_single import DataLoaderMNIST\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from models.definitions.PocketAutoencoder import PocketAutoencoder\n",
    "\n",
    "from utils.model import load_model, get_transformations\n",
    "from utils.sampler import simple_sampler\n",
    "from utils.visualization import visualize_results\n",
    "\n",
    "from optimization.optimizer import LinearFitting\n",
    "from optimization.optimizer import AffineFitting\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "augmentations = [transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))]\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_check = []\n",
    "\n",
    "pth_files = [file for file in os.listdir('models/checkpoints/SMALLAE/MNIST/') if os.path.isfile(os.path.join('models/checkpoints/SMALLAE/MNIST/', file)) and file.endswith('.pth')]\n",
    "\n",
    "for file in pth_files:\n",
    "    model_order = []\n",
    "    latent_space_dict = {}\n",
    "    model1 = PocketAutoencoder()\n",
    "    model1.load_state_dict(torch.load(f'models/checkpoints/SMALLAE/MNIST/{file}'))\n",
    "    model1.to(DEVICE)\n",
    "    model1.eval()\n",
    "    \n",
    "    DataLoaders = DataLoaderMNIST\n",
    "    indices = range(40000)  # Assuming you want to use the first 40,000 images\n",
    "    data_loader = DataLoaderMNIST(128, augmentations, indices=indices)\n",
    "    test_loader = data_loader.get_test_loader()\n",
    "\n",
    "    # Get all images from test_loader and convert them to latent space\n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images = images.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            latent_space = model1.get_latent_space(images)\n",
    "\n",
    "        # Convert tensor to numpy array\n",
    "        latent_space_np = latent_space.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "        \n",
    "        # Store in dictionary\n",
    "        for idx in range(len(images)):\n",
    "            latent_space_dict[batch_idx * 128 + idx] = (latent_space_np[idx], labels_np[idx])\n",
    "            model_order.append(labels_np[idx])\n",
    "    order_check.append(model_order)\n",
    "    torch.save(latent_space_dict, 'models/checkpoints/SMALLAE/MNIST/LATENTS/' + str(file).replace('.pth', '_latent_space.pth'))\n",
    "\n",
    "## Check they are in the same order\n",
    "for i in range(len(order_check)-1):\n",
    "    if order_check[i] != order_check[i+1]:\n",
    "        print('Order is not the same')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mapping(cfg, latents1, latents2):\n",
    "    if cfg.mapping == 'Linear':\n",
    "        from optimization.optimizer import LinearFitting\n",
    "        mapping = LinearFitting(latents1, latents2, lamda=cfg.lamda)\n",
    "    elif cfg.mapping == 'Affine':\n",
    "        from optimization.optimizer import AffineFitting\n",
    "        mapping = AffineFitting(latents1, latents2, lamda=cfg.lamda)\n",
    "    elif cfg.mapping == 'NeuralNetwork':\n",
    "        from optimization.optimizer import NeuralNetworkFitting\n",
    "        mapping = NeuralNetworkFitting(latents1, latents2, hidden_dim=cfg.hidden_size, lamda=cfg.lamda, learning_rate=cfg.learning_rate, epochs=cfg.epochs)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid experiment name\")\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining the problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federicoferoggio/Documents/vs_code/latent-communication/.zeroshot/lib/python3.9/site-packages/cvxpy/problems/problem.py:158: UserWarning: Objective contains too many subexpressions. Consider vectorizing your CVXPY code to speed up compilation.\n",
      "  warnings.warn(\"Objective contains too many subexpressions. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federicoferoggio/Documents/vs_code/latent-communication/.zeroshot/lib/python3.9/site-packages/cvxpy/problems/problem.py:164: UserWarning: Constraint #0 contains too many subexpressions. Consider vectorizing your CVXPY code to speed up compilation.\n",
      "  warnings.warn(f\"Constraint #{i} contains too many subexpressions. \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for file1 in os.listdir('models/checkpoints/SMALLAE/MNIST/LATENTS/'):\n",
    "    if file1.endswith('.pth'):\n",
    "        latents1 = torch.load('models/checkpoints/SMALLAE/MNIST/LATENTS/' + file1)\n",
    "        for file2 in os.listdir('models/checkpoints/SMALLAE/MNIST/LATENTS/'):\n",
    "            if file1 != file2 and file2.endswith('.pth'):\n",
    "                latents2 = torch.load('models/checkpoints/SMALLAE/MNIST/LATENTS/' + file2)\n",
    "\n",
    "                parameters = {\n",
    "                    \"num_samples\": 49,\n",
    "                    \"mapping\": \"Linear\",\n",
    "                    \"lamda\": 0.01,\n",
    "                }\n",
    "                latent1_pl = torch.stack([torch.tensor(value[0]) for value in latents1.values()])\n",
    "                latent2_pl = torch.stack([torch.tensor(value[0]) for value in latents2.values()])\n",
    "                cfg = Config(**parameters)\n",
    "                mapping = create_mapping(cfg, latent1_pl, latent2_pl)\n",
    "                mapping.fit()\n",
    "                storage_path = f'results/transformations/SMALLAE/{cfg.mapping}_{file1[:-len(\"_latent_space.pth\")]}_{file2[:-len(\"_latent_space.pth\")]}_{cfg.num_samples}'\n",
    "                Path(storage_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "                mapping.save_results(storage_path)\n",
    "                latents1_trafo = mapping.transform(latent1_pl)\n",
    "\n",
    "                # for n in range(10):\n",
    "                #     desired_class = n  # Specify the class you want to filter\n",
    "                #     filtered_samples = []\n",
    "\n",
    "                #     # Filter samples from the test loader based on the desired class\n",
    "                #     for data, label in test_loader:\n",
    "                #         indices = torch.nonzero(label == desired_class, as_tuple=False)\n",
    "                #         if indices.numel() > 0:\n",
    "                #             for idx in indices:\n",
    "                #                 filtered_samples.append((data[idx], label[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".zeroshot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
