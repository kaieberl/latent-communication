{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from utils.visualisation import *\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from helper.DataLoaderMNIST import DataLoader_MNIST\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from resnet.model_def import ResNet\n",
    "from VAE.model_def import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seed=4\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "## Get dataloader to plot\n",
    "# Transformations for resnet\n",
    "transformation_resnet = [transforms.ToTensor(),\n",
    "                    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "                    ]\n",
    "# Transdormations for vae\n",
    "transformations_vae= [transforms.ToTensor(), \n",
    "                                # Normalize between -1 and 1\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                                # Flatten the Image to a vector\n",
    "                                transforms.Lambda(lambda x: x.view(-1) )\n",
    "                                ]\n",
    "\n",
    "# Load the data\n",
    "batch_size=256\n",
    "data_loader = DataLoader_MNIST(batch_size, transformation_resnet, transformation_resnet)\n",
    "train_loader1, train_loader2 = data_loader.get_train_loader()\n",
    "number_batches_to_plot=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hillary/miniconda3/envs/opti/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hillary/miniconda3/envs/opti/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hillary/miniconda3/envs/opti/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "for seed1 in range(1,max_seed+1):\n",
    "    path_model1 = f'../resnet/models/model_seed{seed1}.pth'\n",
    "    #Load model1 and latent_space\n",
    "    model1 = ResNet(pretrained=False).to(DEVICE)# Load pretrained weights for model2\n",
    "    model1.load_state_dict(torch.load(path_model1,map_location = DEVICE))\n",
    "    latent_space_model1,all_labels_model1 = get_latent_space_data(model1, train_loader1, DEVICE,number_batches_to_plot)\n",
    "    #plotLatentTransformed(latent_space_model1,all_labels_model1, np.eye(latent_space_model1.shape[1]), pca_model1, f\"Model 1 ResNet Seed {seed1}\")\n",
    "\n",
    "    for seed2 in range(seed1+1,max_seed+1):\n",
    "        path_model2 = f'../resnet/models/model_seed{seed2}.pth'\n",
    "        path_map = f'ResNet-LinearTransform/Linear_resnet_{seed1}_resnet_{seed2}_100.npy'\n",
    "\n",
    "        # Load mapping\n",
    "        A = np.load(path_map)\n",
    "        # Load model2 and latent space\n",
    "        model2 = ResNet(pretrained=False).to(DEVICE)# Load pretrained weights for model2\n",
    "        model2.load_state_dict(torch.load(path_model2,map_location = DEVICE) )       \n",
    "        latent_space_model2,all_labels_model2 = get_latent_space_data(model2, train_loader2, DEVICE,number_batches_to_plot)\n",
    "        #pca_model2 = pca_def(latent_space_model2)\n",
    "        #plotLatentTransformed(latent_space_model2,all_labels_model2, np.eye(latent_space_model2.shape[1]), pca_model2, f\"Model 2 ResNet Seed {seed2}\")\n",
    "        #plotLatentTransformed(latent_space_model1,all_labels_model1, A, pca_model2, f\"ResNet Seed {seed1} to {seed2} Transformed\")\n",
    "        #pca_model1 = pca_def(latent_space_model1)\n",
    "\n",
    "        #Get average distance\n",
    "        avg_distance = avg_transformed_distances(latent_space_model1, latent_space_model2, A)\n",
    "        print(f\"Seed {seed1} to Seed {seed2} average distance: {avg_distance}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
