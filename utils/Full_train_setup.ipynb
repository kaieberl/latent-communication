{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federicoferoggio/Documents/vs_code/latent-communication/.zeroshot/lib/python3.9/site-packages/lightning/pytorch/core/module.py:436: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch 1 complete! \tAverage Loss:  0.001480917947407326\n",
      "\tEpoch 2 complete! \tAverage Loss:  0.001276107942637847\n",
      "\tEpoch 3 complete! \tAverage Loss:  0.0012483366930623875\n",
      "\tEpoch 4 complete! \tAverage Loss:  0.0012326492937496099\n",
      "\tEpoch 5 complete! \tAverage Loss:  0.001219926783374375\n",
      "\tTest Loss:  0.0011917626517647995\n",
      "Finish!!\n",
      "CIFAR10_AE_1_5.pth\n",
      "\tEpoch 1 complete! \tAverage Loss:  0.0015148517191576798\n",
      "\tEpoch 2 complete! \tAverage Loss:  0.0012783019489649198\n",
      "\tEpoch 3 complete! \tAverage Loss:  0.00124848061961734\n",
      "\tEpoch 4 complete! \tAverage Loss:  0.0012317393907009984\n",
      "\tEpoch 5 complete! \tAverage Loss:  0.0012197884393955968\n",
      "\tTest Loss:  0.0011929268506650306\n",
      "Finish!!\n",
      "CIFAR10_AE_2_5.pth\n",
      "\tEpoch 1 complete! \tAverage Loss:  0.0014651704015677123\n",
      "\tEpoch 2 complete! \tAverage Loss:  0.0012725981942656667\n",
      "\tEpoch 3 complete! \tAverage Loss:  0.001245795468063763\n",
      "\tEpoch 4 complete! \tAverage Loss:  0.0012316243553920018\n",
      "\tEpoch 5 complete! \tAverage Loss:  0.0012184836990450083\n",
      "\tTest Loss:  0.001190987971163343\n",
      "Finish!!\n",
      "CIFAR10_AE_3_5.pth\n",
      "\tEpoch 1 complete! \tAverage Loss:  0.0014651704015677123\n",
      "\tEpoch 2 complete! \tAverage Loss:  0.0012725981942656667\n",
      "\tEpoch 3 complete! \tAverage Loss:  0.001245795468063763\n",
      "\tEpoch 4 complete! \tAverage Loss:  0.0012316243553920018\n",
      "\tEpoch 5 complete! \tAverage Loss:  0.0012184836990450083\n",
      "\tEpoch 6 complete! \tAverage Loss:  0.0012098135664234953\n",
      "\tEpoch 7 complete! \tAverage Loss:  0.0012026345809859694\n",
      "\tEpoch 8 complete! \tAverage Loss:  0.0011971874467437834\n",
      "\tEpoch 9 complete! \tAverage Loss:  0.0011910082003616196\n",
      "\tEpoch 10 complete! \tAverage Loss:  0.0011875405190083796\n",
      "\tTest Loss:  0.00116496926757118\n",
      "Finish!!\n",
      "CIFAR10_AE_3_10.pth\n",
      "\tEpoch 1 complete! \tAverage Loss:  0.0014402553256925034\n",
      "\tTest Loss:  0.0012685296853674176\n",
      "Finish!!\n",
      "CIFAR10_AE_4_1.pth\n",
      "\tEpoch 1 complete! \tAverage Loss:  0.0014402553256925034\n",
      "\tEpoch 2 complete! \tAverage Loss:  0.0012661053690716357\n",
      "\tEpoch 3 complete! \tAverage Loss:  0.0012415148787643484\n",
      "\tEpoch 4 complete! \tAverage Loss:  0.001228529116724763\n",
      "\tEpoch 5 complete! \tAverage Loss:  0.0012156605140527573\n",
      "\tEpoch 6 complete! \tAverage Loss:  0.0012084269741921665\n",
      "\tEpoch 7 complete! \tAverage Loss:  0.001201071037763201\n",
      "\tEpoch 8 complete! \tAverage Loss:  0.0011947440926421463\n",
      "\tEpoch 9 complete! \tAverage Loss:  0.0011892862787084354\n",
      "\tEpoch 10 complete! \tAverage Loss:  0.0011857724802144577\n",
      "\tTest Loss:  0.0011653449213945696\n",
      "Finish!!\n",
      "CIFAR10_AE_4_10.pth\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\tEpoch 1 complete! \tAverage Loss:  0.0015915783188875069\n",
      "\tEpoch 2 complete! \tAverage Loss:  0.0013740490657537033\n",
      "\tEpoch 3 complete! \tAverage Loss:  0.0013456235322958367\n",
      "\tEpoch 4 complete! \tAverage Loss:  0.001327873082876758\n",
      "\tEpoch 5 complete! \tAverage Loss:  0.001314834935728775\n",
      "\tTest Loss:  0.0013063103874225782\n",
      "Finish!!\n",
      "CIFAR100_AE_1_5.pth\n",
      "\tEpoch 1 complete! \tAverage Loss:  0.001624215336199707\n",
      "\tEpoch 2 complete! \tAverage Loss:  0.001381510718013434\n",
      "\tEpoch 3 complete! \tAverage Loss:  0.0013495705113091203\n",
      "\tEpoch 4 complete! \tAverage Loss:  0.0013314832003115465\n",
      "\tEpoch 5 complete! \tAverage Loss:  0.0013199334296033435\n",
      "\tTest Loss:  0.0013128179847557522\n",
      "Finish!!\n",
      "CIFAR100_AE_2_5.pth\n",
      "\tEpoch 1 complete! \tAverage Loss:  0.0015813750920512374\n",
      "\tEpoch 2 complete! \tAverage Loss:  0.0013803668183815258\n",
      "\tEpoch 3 complete! \tAverage Loss:  0.0013499380335869158\n",
      "\tEpoch 4 complete! \tAverage Loss:  0.0013312813129199817\n",
      "\tEpoch 5 complete! \tAverage Loss:  0.0013197151526613423\n",
      "\tTest Loss:  0.0013164523694239839\n",
      "Finish!!\n",
      "CIFAR100_AE_3_5.pth\n",
      "\tEpoch 1 complete! \tAverage Loss:  0.0015813750920512374\n",
      "\tEpoch 2 complete! \tAverage Loss:  0.0013803668183815258\n",
      "\tEpoch 3 complete! \tAverage Loss:  0.0013499380335869158\n",
      "\tEpoch 4 complete! \tAverage Loss:  0.0013312813129199817\n",
      "\tEpoch 5 complete! \tAverage Loss:  0.0013197151526613423\n",
      "\tEpoch 6 complete! \tAverage Loss:  0.0013091662720612744\n",
      "\tEpoch 7 complete! \tAverage Loss:  0.001297872792214841\n",
      "\tEpoch 8 complete! \tAverage Loss:  0.001291573469829567\n",
      "\tEpoch 9 complete! \tAverage Loss:  0.0012871956880278219\n",
      "\tEpoch 10 complete! \tAverage Loss:  0.001283226562116076\n",
      "\tTest Loss:  0.001279211190493801\n",
      "Finish!!\n",
      "CIFAR100_AE_3_10.pth\n",
      "\tEpoch 1 complete! \tAverage Loss:  0.0015370174724360943\n",
      "\tTest Loss:  0.0013906116659246103\n",
      "Finish!!\n",
      "CIFAR100_AE_4_1.pth\n",
      "\tEpoch 1 complete! \tAverage Loss:  0.0015370174724360943\n",
      "\tEpoch 2 complete! \tAverage Loss:  0.0013653884500103152\n",
      "\tEpoch 3 complete! \tAverage Loss:  0.0013407300592011885\n",
      "\tEpoch 4 complete! \tAverage Loss:  0.0013259209396527208\n",
      "\tEpoch 5 complete! \tAverage Loss:  0.0013115389351173283\n",
      "\tEpoch 6 complete! \tAverage Loss:  0.0013005788017616934\n",
      "\tEpoch 7 complete! \tAverage Loss:  0.0012933057384527363\n",
      "\tEpoch 8 complete! \tAverage Loss:  0.0012892082207324102\n",
      "\tEpoch 9 complete! \tAverage Loss:  0.0012853636407553007\n",
      "\tEpoch 10 complete! \tAverage Loss:  0.0012809338617969848\n",
      "\tTest Loss:  0.0012813123308499403\n",
      "Finish!!\n",
      "CIFAR100_AE_4_10.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/Users/federicoferoggio/Documents/vs_code/latent-communication')\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import Adam\n",
    "from utils.dataloader_mnist_single import DataLoaderMNIST\n",
    "from utils.dataloader_fnist_single import DataLoaderFNIST\n",
    "from utils.dataloader_cifrar100_single import DataLoaderCIFAR100\n",
    "from utils.dataloader_cifrar10_single import DataLoaderCIFAR10\n",
    "from models.definitions.ae import LightningAutoencoder\n",
    "from models.definitions.ae_more_channels import LightningAutoencoderV2\n",
    "\n",
    "\n",
    "\n",
    "datasets_list = ['CIFAR10', 'CIFAR100']\n",
    "seeds = [1, 2, 3, 3, 4 ,4]\n",
    "paths = ['models/checkpoints/AE/CIFAR10/', 'models/checkpoints/AE/CIFAR100/']\n",
    "dataloader_l = [DataLoaderCIFAR10, DataLoaderCIFAR100]\n",
    "epochs = [5, 5, 5, 10, 1, 10]\n",
    "DEVICE = torch.device(\"mps\")\n",
    "augmentations = [transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))]\n",
    "\n",
    "for n, data in enumerate(datasets_list):\n",
    "    dataloader_current = dataloader_l[n]\n",
    "    batch_size = 128\n",
    "    DataLoaders = dataloader_l[n]\n",
    "    dataloader = DataLoaders(batch_size=batch_size, transformation= augmentations)\n",
    "\n",
    "    test_loader = dataloader.get_test_loader()\n",
    "    train_loader = dataloader.get_train_loader()\n",
    "    for m, d in enumerate(seeds):\n",
    "        config = {\n",
    "            'model_name': 'AE',\n",
    "            'dataset': data,\n",
    "            # Variance and Mean for the weight initialization\n",
    "            'weight_var': 1,\n",
    "            'weight_mean': 0,\n",
    "            'seed': d,\n",
    "            # Model setup \n",
    "            'input_dim': 784,\n",
    "            'dims': [256, 128, 64, 32],\n",
    "            'distribution_dim': 16,\n",
    "            # Training setup\n",
    "            'batch_size': 128,\n",
    "            'num_epochs': epochs[m],\n",
    "            'learning_rate': 0.001,\n",
    "            'path': paths[n]\n",
    "        }\n",
    "        # Set the seed\n",
    "        torch.manual_seed(config['seed'])\n",
    "        model = LightningAutoencoderV2()\n",
    "        model.to(DEVICE)\n",
    "        optimizer = Adam(model.parameters(), lr=config['learning_rate'], weight_decay=1e-4)\n",
    "        for epoch in range(config['num_epochs']):\n",
    "            overall_loss = 0\n",
    "            model.train()  # set the model to training mode\n",
    "            for batch_idx, (x, _) in enumerate(train_loader):\n",
    "                x = x.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss = model.training_step(x)\n",
    "                \n",
    "                overall_loss += loss.item()\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            print(\"\\tEpoch\", epoch + 1, \"complete!\", \"\\tAverage Loss: \", overall_loss / (len(train_loader)*batch_size))\n",
    "                    \n",
    "        model.eval()  # set the model to evaluation mode\n",
    "        with torch.no_grad():  # disable gradient calculation\n",
    "            test_loss = 0\n",
    "            for x_test, _ in test_loader:  # assuming you have a separate test loader\n",
    "                x_test = x_test.to(DEVICE)\n",
    "                test_loss += model.validation_step(x_test).item()\n",
    "\n",
    "            print(\"\\tTest Loss: \", test_loss / ((len(test_loader)*batch_size)))\n",
    "                    \n",
    "        print(\"Finish!!\")\n",
    "\n",
    "        # Save the model\n",
    "        name = str(config['dataset'])+ '_' + str(config['model_name']) + '_' + str(config['seed']) + '_' + str(config['num_epochs']) + '.pth'\n",
    "        print(name)\n",
    "        # Model Path\n",
    "        path = config['path'] + name\n",
    "\n",
    "        torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/Users/federicoferoggio/Documents/vs_code/latent-communication/.zeroshot/lib/python3.9/site-packages/lightning/pytorch/core/module.py:436: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
    "\tEpoch 1 complete! \tAverage Loss:  0.007029166570239102\n",
    "\tEpoch 2 complete! \tAverage Loss:  0.006620410752337751\n",
    "\tEpoch 3 complete! \tAverage Loss:  0.006593725072152452\n",
    "\tEpoch 4 complete! \tAverage Loss:  0.0065810882639306695\n",
    "\tEpoch 5 complete! \tAverage Loss:  0.006572851465383509\n",
    "\tTest Loss:  0.006555338278177041\n",
    "Finish!!\n",
    "FMNIST_AE_1_5.pth\n",
    "\tEpoch 1 complete! \tAverage Loss:  0.006961854703938846\n",
    "\tEpoch 2 complete! \tAverage Loss:  0.00661639380616261\n",
    "\tEpoch 3 complete! \tAverage Loss:  0.006594270342655147\n",
    "\tEpoch 4 complete! \tAverage Loss:  0.006580616891590644\n",
    "\tEpoch 5 complete! \tAverage Loss:  0.006572537388263354\n",
    "\tTest Loss:  0.006551660998146745\n",
    "Finish!!\n",
    "FMNIST_AE_2_5.pth\n",
    "\tEpoch 1 complete! \tAverage Loss:  0.006978094329569004\n",
    "\tEpoch 2 complete! \tAverage Loss:  0.006619723167206878\n",
    "\tEpoch 3 complete! \tAverage Loss:  0.006596427908274474\n",
    "\tEpoch 4 complete! \tAverage Loss:  0.0065816252438752635\n",
    "\tEpoch 5 complete! \tAverage Loss:  0.006573408149055708\n",
    "\tTest Loss:  0.0065538919695853435\n",
    "Finish!!\n",
    "FMNIST_AE_3_5.pth\n",
    "\tEpoch 1 complete! \tAverage Loss:  0.006978094329569004\n",
    "\tEpoch 2 complete! \tAverage Loss:  0.006619723167206878\n",
    "\tEpoch 3 complete! \tAverage Loss:  0.006596427908274474\n",
    "\tEpoch 4 complete! \tAverage Loss:  0.0065816252438752635\n",
    "\tEpoch 5 complete! \tAverage Loss:  0.006573408149055708\n",
    "\tEpoch 6 complete! \tAverage Loss:  0.006567447325155171\n",
    "\tEpoch 7 complete! \tAverage Loss:  0.006563040653247632\n",
    "\tEpoch 8 complete! \tAverage Loss:  0.006559921372959863\n",
    "\tEpoch 9 complete! \tAverage Loss:  0.006557290498882151\n",
    "\tEpoch 10 complete! \tAverage Loss:  0.00655529145667675\n",
    "\tTest Loss:  0.006538598108565128\n",
    "Finish!!\n",
    "FMNIST_AE_3_10.pth\n",
    "\tEpoch 1 complete! \tAverage Loss:  0.007069153271353385\n",
    "\tTest Loss:  0.006633507913049263\n",
    "Finish!!\n",
    "FMNIST_AE_4_1.pth\n",
    "\tEpoch 1 complete! \tAverage Loss:  0.007069153271353385\n",
    "\tEpoch 2 complete! \tAverage Loss:  0.006618808575673526\n",
    "\tEpoch 3 complete! \tAverage Loss:  0.0065925988916760445\n",
    "\tEpoch 4 complete! \tAverage Loss:  0.006580502830390165\n",
    "\tEpoch 5 complete! \tAverage Loss:  0.0065728001135673475\n",
    "\tEpoch 6 complete! \tAverage Loss:  0.00656704473366806\n",
    "\tEpoch 7 complete! \tAverage Loss:  0.00656309546624769\n",
    "\tEpoch 8 complete! \tAverage Loss:  0.006560077121270809\n",
    "\tEpoch 9 complete! \tAverage Loss:  0.006557785113578412\n",
    "\tEpoch 10 complete! \tAverage Loss:  0.006555454884923852\n",
    "\tTest Loss:  0.006539197125814006\n",
    "Finish!!\n",
    "FMNIST_AE_4_10.pth\n",
    "\tEpoch 1 complete! \tAverage Loss:  0.0048762068156399194\n",
    "\tEpoch 2 complete! \tAverage Loss:  0.0046089222785760595\n",
    "\tEpoch 3 complete! \tAverage Loss:  0.004585484623599217\n",
    "\tEpoch 4 complete! \tAverage Loss:  0.004572693035125669\n",
    "\tEpoch 5 complete! \tAverage Loss:  0.004563915694176134\n",
    "\tTest Loss:  0.004547707960481131\n",
    "Finish!!\n",
    "MNIST_AE_1_5.pth\n",
    "\tEpoch 1 complete! \tAverage Loss:  0.004806873547449422\n",
    "\tEpoch 2 complete! \tAverage Loss:  0.004601690826862097\n",
    "\tEpoch 3 complete! \tAverage Loss:  0.004580576711499106\n",
    "\tEpoch 4 complete! \tAverage Loss:  0.004567994766914323\n",
    "\tEpoch 5 complete! \tAverage Loss:  0.004558863717991152\n",
    "\tTest Loss:  0.00454367640652234\n",
    "Finish!!\n",
    "MNIST_AE_2_5.pth\n",
    "\tEpoch 1 complete! \tAverage Loss:  0.0048170165369299045\n",
    "\tEpoch 2 complete! \tAverage Loss:  0.004602856104021896\n",
    "\tEpoch 3 complete! \tAverage Loss:  0.004580189375631781\n",
    "\tEpoch 4 complete! \tAverage Loss:  0.004568471197984112\n",
    "\tEpoch 5 complete! \tAverage Loss:  0.004559944934849101\n",
    "\tTest Loss:  0.004543465226181323\n",
    "Finish!!\n",
    "MNIST_AE_3_5.pth\n",
    "\tEpoch 1 complete! \tAverage Loss:  0.0048170165369299045\n",
    "\tEpoch 2 complete! \tAverage Loss:  0.004602856104021896\n",
    "\tEpoch 3 complete! \tAverage Loss:  0.004580189375631781\n",
    "\tEpoch 4 complete! \tAverage Loss:  0.004568471197984112\n",
    "\tEpoch 5 complete! \tAverage Loss:  0.004559944934849101\n",
    "\tEpoch 6 complete! \tAverage Loss:  0.004553412528100934\n",
    "\tEpoch 7 complete! \tAverage Loss:  0.004548212255178484\n",
    "\tEpoch 8 complete! \tAverage Loss:  0.004543802730723231\n",
    "\tEpoch 9 complete! \tAverage Loss:  0.004539757607572241\n",
    "\tEpoch 10 complete! \tAverage Loss:  0.0045367768778999855\n",
    "\tTest Loss:  0.004522914408788651\n",
    "Finish!!\n",
    "MNIST_AE_3_10.pth\n",
    "\tEpoch 1 complete! \tAverage Loss:  0.0048799010744290565\n",
    "\tTest Loss:  0.00461422679120604\n",
    "Finish!!\n",
    "MNIST_AE_4_1.pth\n",
    "\tEpoch 1 complete! \tAverage Loss:  0.0048799010744290565\n",
    "\tEpoch 2 complete! \tAverage Loss:  0.00460798678292172\n",
    "\tEpoch 3 complete! \tAverage Loss:  0.004584960452815109\n",
    "\tEpoch 4 complete! \tAverage Loss:  0.0045720770963028805\n",
    "\tEpoch 5 complete! \tAverage Loss:  0.004562147325083518\n",
    "\tEpoch 6 complete! \tAverage Loss:  0.0045554388268813015\n",
    "\tEpoch 7 complete! \tAverage Loss:  0.0045496448368104155\n",
    "\tEpoch 8 complete! \tAverage Loss:  0.004545229927960363\n",
    "\tEpoch 9 complete! \tAverage Loss:  0.004541579848413528\n",
    "\tEpoch 10 complete! \tAverage Loss:  0.004538391515223393\n",
    "\tTest Loss:  0.0045248305106747756\n",
    "Finish!!\n",
    "MNIST_AE_4_10.pth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".zeroshot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
